/**


\mainpage Lightsprint SDK
 Welcome to Lightsprint SDK.

 \subpage rr_dir_indir "Direct vs indirect; Realtime Radiosity position"

 \subpage scenarios "Usage scenarios"

 \subpage rr_integration "Integration with renderer"

 \subpage vision_storage "Data formats (vertex arrays, lightmaps)"

 \subpage rules "Conventions (units, scale, floats...)"

 \subpage platforms "Supported platforms"

 \subpage api "API reference"

 \image html all-rr.png




\page rr_dir_indir Direct vs indirect; Realtime Radiosity position
 In our real world, we see visible light coming mostly from special surfaces 
 (hot wolfram fibre in bulb, luminofor of fluorescent lamp)
 or from whole volumes of plasma (sun, fire).
 We call these surfaces and volumes <b>source of direct illumination</b>.

 Light from sources of direct illumination reaches other surfaces 
 where part of light is absorbed and part is reflected.
 Reflected part is what we see and what makes objects look lit by direct illumination.
 When we see the reflected part, we say that object has <b>direct illumination</b>.

 Reflected light from direct illumination reaches other surfaces, partially reflects,
 reaches other surfaces, partially reflects etc.
 When we see sum of these reflected parts, we say that object has <b>indirect illumination</b>.

 Illumination we see in real world is sum of direct and indirect illumination.

 Computer graphics tries to simulate this process in order to generate realistic images.
 This is however very time consuming process.
 So realtime computer graphics in 99% of cases resigns to real-world sources of direct 
 illumination and uses imaginary <b>"point", "spot" or "directional" lights</b>.
 These fictitious sources of direct illumination
 allow realtime computer graphics to calculate direct illumination very quickly.
 This process includes calculation of <b>shadows in direct illumination</b>.
 There are many realtime techniques for calculating shadows in direct illumination,
 most notably shadow mapping and volumetric (stencil) shadows.

 There is however still problem with indirect illumination, which remains
 hard to compute quickly.

 You are expected to <b>have renderer with direct illumination and shadows</b> in 
 direct illumination. This is very modest expectation, as there are
 many realtime renderers having it, both commercial and open source.

 <b>RealtimeRadiosity adds indirect illumination</b> into such renderer.

 Vision is also able to calculate complete illumination (direct+indirect)
 from real-world direct light sources - surfaces. However we don't prefer
 this use case as it's not suitable for interactive application.

 \image html all-ambient.png
 Today's games with moving lights approximate indirect illumination
 by constant ambient. Rarely, they render no indirect illumination
 at all (left column).

 \image html all-rr.png
 Lightsprint calculates physically correct indirect illumination
 (realtime radiosity) as a replacement for constant ambient.




\page scenarios Usage scenarios

 \section scenario2 Realtime radiosity integrated into editor. Game uses precalculated lightmaps / vertex arrays

  - Saves months of work to graphics artists and designers,
    previously spent in lightmap rebuilds or fake light placement.

  - Allows artists to find visually more attractive positions / settings for lights.

  - Saves months spent in adapting your data for external global illumination
    tools. Other tools don't support arbitrary materials and lights.

  - Simple path for incorporating realtime radiosity into future games.

 \section scenario1 Realtime radiosity integrated into game

  - Greatly improves realism and visual appeal.

  - Requires no level preprocessing, saves time previously spent on infinite levels builds.

  - Simplifies integration of mods and other user provided assets.

  - Supports arbitrary materials / shaders, even those writen by modders
    after game release.

  - Publicity, be first with realtime global illumination in game.

  - See <a href="http://dee.cz/rrb/RRBugs.rar">Realtime Radiosity Bugs</a>
    as an example. It's not a real game, but it shows innovative use 
    of realtime radiosity in game. It doesn't have to be just eye candy.
    
 \image html rrbugs_hint.jpg





\page rr_integration Integration with renderer

 You can <b>quickly start</b> playing with your data
 if you convert them to .3ds and load into HelloRealtimeRadiosity.
 (Only truecolor .tga textures are supported.)

 However for integration with your renderer, deeper understanding is necessary.

 Three steps to integrate Vision with your renderer are described in
 <a href="http://dee.cz/rri">Realtime Radiosity Integration article</a>.

 Final result is demonstrated in HelloRealtimeRadiosity example.

 <b>What was necessary to do to integrate realtime radiosity into 3d scene viewer:</b>
 - create rr::RRObject wrappers around 3d objects (2 hours)
 - change renderer so that it reads ambient from vertex stream provided by rr::RRRealtimeRadiosity (1 hour)
 - remove constant ambient (5 minutes)
 - implement abstract methods in rr::RRRealtimeRadiosity (2 days)
 - create rr::RRRealtimeRadiosity and call its methods on appropriate places (1 hour)

 You can see that the only nontrivial task was implementing abstract methods in rr::RRRealtimeRadiosity.
 More precisely rr::RRRealtimeRadiosity::detectDirectIllumination().
 
 <b>What needs to be detected:</b> simply said, average color of each face;
 how does it looks lit by your direct (not ambient) point, spot and directional lights
 and shadowed by your shadows.
 In fact, it is optional if you detect face irradiance, incoming flux,
 exitance or exiting flux.

 <b>Why is it important:</b> we have no other knowledge about your lights.
 You can use many light types with very complex lighting equations.
 You can arbitrarily change them. No problem. Just let us know what are the results -
 average colors produced by your shader.

 <b>How to implement it:</b> turn off ambient/radiosity, render all scene faces into texture,
 read it to the system memory and extract average colors for each face.
 This is the most simple and universal approach (works with any number of any lights),
 however you can think about alternatives. This depends highly on your renderer.

 It can be optimized by ignoring material diffuse textures.
 Detected average face colors then correspond to intensity of light reaching 
 face (irradiance) instead of intensity of light leaving face (exitance),
 so detected color is passed to setTriangleAdditionalMeasure with rr::RM_IRRADIANCE
 instead of rr::RM_EXITANCE.

 <b>How HelloRealtimeRadiosity implements it:</b> rendering faces into texture
 requires one renderer enhancement - 2d position override - ability to render
 triangles to specified 2d positions.

 This can be very easily implemented in shader on next generation GPUs with "primitive index".

 For current generation GPUs, implemention has two steps:
 - Triangle positions in texture are generated into new vertex stream.
   Just before end of vertex shader, original vertex position is replaced by
   new position readen from new vertex stream.
 - For purpose of detection, scene is rendered using non-indexed triangle list.
   This is necessary because if we want to render triangles with shared
   vertices to completely different positions in texture, we have to split 
   that vertices.
   In our case, this is handled by branch in renderScene():
   when shader is set, two paths for specifying vertex data follow,
   - m3ds.Draw is original indexed tristrip path
   - rendererCaching->render() is new non-indexed trilist path 
     written only for purpose of this detection




\page vision_storage Data formats
 Illumination levels are calculated for all surfaces in your scene.
 Multiple ways how to access these levels and how to store them exist.

 \section vertices Vertices, Vertex arrays
   You can read illumination levels in individual face vertices
   (rr::RRScene::getTriangleMeasure)
   or let RealtimeRadiosity generate complete vertex arrays for you
   (rr::RRRealtimeRadiosity::calculate).
   It is expected that illumination inside face will be linearly interpolated
   from values in vertices.
   \n This representation has several advantages:
   - Compact representation. It requires only few bytes per vertex.
     Default implementation stores illumination as 3 floats, but you
     can easily add arbitrary compression.
   - Fast rendering.
     No sampler resources are consumed.
     It can be arbitrarily postprocessed in vertex shader.
     You may have for example multiple layers of precalculated indirect illumination 
     and mix them in vertex shader according to changes in scene.

   On the other hand, there are also disadvantages of vertex illumination:
   - Details are missing in areas without vertices.
     For good results, you have to add vertices to places where you miss details.
   - Seams around T vertices and other degenerated geometries.
     You have to make your meshes clean, avoid degeneracies.
   - Long narrow triangles (needles) often create visible artifacts.
     This is often problem also for physical engine,
     so your 3d artisis probably know they should avoid them.

   Vertex arrays are stored by rr::RRIlluminationVertexBuffer
   interface.
   Implementation is provided 
   (rr::RRIlluminationVertexBuffer::createInSystemMemory)
   and it is used by default (by rr::RRRealtimeRadiosity::newVertexBuffer).

 \section textures Lightmaps
   You can read illumination levels in adaptively subdivided triangles
   (rr::RRScene::getSubtriangleMeasure)
   and create lightmaps out of them or let Realtime Radiosity
   do it for you (rr::RRRealtimeRadiosity::calculate).
   This representation is more expensive for processing, storage and rendering
   (any postprocessing must be done per pixel and it consumes sampler resources),
   but it avoids some disadvantages of vertex illumination
   (needle triangles cause problems to both vertex arrays and lightmaps).

   At the moment, adaptive subdivision is turned off by default, 
   and lightmaps contain no additional details compared to vertex arrays.
   This will be fixed soon. API won't change, you'll just get more 
   detailed lightmaps.

   Lightmaps are stored by rr::RRIlluminationPixelBuffer
   interface.
   No implementation is present in platform independent core libraries
   (default rr::RRRealtimeRadiosity::newPixelBuffer returns NULL),
   so lightmaps are not generated by default.
   However you can use OpenGL accelerated implementation from DemoEngine
   (rr::RRIlluminationPixelBufferInOpenGL)
   or implement your own.

 \section faces Faces
   You can read illumination levels in individual faces
   (rr::RRScene::getTriangleMeasure with vertex=3).
   This is good for example for AI trying to find dark place for hiding.
   Reading illumination level on face is slightly faster than reading
   it in vertex.
   


\page platforms Supported platforms

 \section plat_bin Platforms for binaries
 For binary libraries, supported platforms are
 - Win32 with Visual C++ 2005 multithreaded runtime library (use for example
   Microsoft's public vcredist_x86.exe to install it)
 - tested also under Windows XP x64, where it runs in 32bit
 - ask for more

 Supported CPUs are
 - x86 compatible with SSE
 - ask for more

 Binaries may work with multiple compilers, but only these are tested:
 - Visual C++ 2005
 - Visual C++ 2003

 \section plat_src Platforms for source code
 Our source code conforms to standard <b>ISO C++</b>, so you should be 
 able to use it on nearly any platform (consoles, linux etc).

 There are optional optimizations, that use SSE instructions on x86 CPUs,
 but they can be omitted on other platforms.


 
\page rules Conventions

 \section gunits Units (radiometry, photometry, screen)
   Although whole documentation talks in radiometry terms,
   it is possible to work in photometry units, screen colors 
   or any other units.
   In typical situations, it is most straightforward to work and think 
   in screen colors. Everything you need is to setup appropriate
   convertor, see rr::RRScene::setScaler().

 \section gscale Scale
   Lightsprint libraries support scaled objects.
   \n\n
   RRMesh and Collider support all scaled objects: positively or negatively, uniformly or non-uniformly scaled.
   \n\n
   RRObject and Vision support typical scaled objects: positively or negatively, uniformly scaled.
   \n Negative scale is supported with both possible interpretations
   for singlesided faces:
   Singlesided box visible from outside transformed with scale -1
   can stay visible form the outside or become visible only from inside,
   see rr::RRObject::createWorldSpaceObject().
 \section gowner Ownership
   Dynamically created objects (using new) are never adopted, ownership never changes.
   \n This means that parameters that need to be destructed are never destructed inside call,
   responsibility for object is never passed to someone else.
   When you create object (using create() etc.), be sure that you delete it when
   no longer needed.
 \section gref Reference counting
   There is no internal reference counting, so if you create collider out of mesh,
   you are not allowed to destroy mesh before destroying collider. This danger should be
   mentioned on all appropriate places.
 \section gfinite Finite numbers
   If not otherwise specified, all inputs must be finite numbers.
   With Inf or NaN on input, result of any operation is undefined.
 \section gflodoub Floats and doubles
   Library uses both floats and doubles.
   It is not allowed to break double arithmetics by modifying FPU states.
   If you use Direct3D, make sure you don't instruct it to force single precision for whole application
   which breaks double precision arithmetics in whole program and libraries.
 \section gnull NULL
   Although NULL is obsoleted by C++ and some discourage from using it,
   we continue using it to distinguish zeros for pointers and zeros for non-pointers.
   So eg. if you see var=0, be sure that var is NOT a pointer. On the other side,
   var=NULL makes sure that var IS a pointer.






\page api API

 \subpage rr "REALTIME RADIOSITY"
 - library, calculates realtime radiosity in dynamic scene

 \subpage illumination "ILLUMINATION"
 - library, storage for calculated illumination

 \subpage vision "VISION"
 - library, calculates radiosity in static scene

 \subpage collider "COLLIDER"
 - library, finds ray-mesh intersections

 \subpage mesh "MESH"
 - library, unifies access to triangle meshes

 \subpage math "MATH"
 - header, basic math

 Lightsprint libraries are simply layered.
 Each layer solves new unique problem using lower layers.
 Depending on your project, you can use all layers or just one.

 Mesh provides unified interface and manipulation for all 3d triangle meshes.
 \n Collider calculates ray x mesh intersections and depends on Mesh.
 \n Vision calculates radiosity in static scene and depends on Collider.
 \n Illumination manages calculated illumination in lightmaps or vertex buffers.
 \n RealtimeRadiosity calculates radiosity in dynamic scene and depends on Vision and Illumination.

 All core libraries (white boxes in scheme, RealtimeRadiosity, Illumination,
 Vision, Collider, Mesh) are purely numerical,
 they are OpenGL/DirectX independent.

 DemoEngine provides simple support for loading and rendering 3d scenes.
 It depends on OpenGL, GLU and RealtimeRadiosity. It has built-in GLEW.

 Sample HelloRealtimeRadiosity uses RealtimeRadiosity, OpenGL and GLUT
 for demonstrating realtime radiosity in scene with dynamic light.
 It uses DemoEngine for common tasks that can be used later by other samples.

 \image html libraries.png

 Other samples depend only on appropriate libraries, eg. HelloCollider on Collider.

 BunnyBenchmark measures Collider performance for comparison with other engines.





\page rr Realtime Radiosity
 Realtime Radiosity extends your renderer by adding realtime computed
 indirect illumination.

 Headers: RRRealtimeRadiosity.h

 - adds indirect illumination to dynamic scenes
 - integrates with existing engines
 - uses no precalculations -> illumination quality varies, "architect edition"
 - techniques based on partial precalculations will follow -> quality boost, "day/night editions"
 - you can ask RealtimeRadiosity for complete vertex buffers or lightmaps;
   for information on individual triangles (even adaptively subdivided), call underlying Vision library

 Sample HelloRealtimeRadiosity shows the result of integration,
 interactive .3ds scene viewer with radiosity immediately responding
 to light movements.





\page illumination Illumination
 Illumination provides you with storage suitable for illumination
 calculated by RealtimeRadiosity.

 Headers: RRIllumination.h

 - illumination storage in lightmap: rr::RRIlluminationPixelBuffer
 - illumination storage in vertex buffer: rr::RRIlluminationVertexBuffer
 - storage of multiple illumination channels: rr::RRObjectIllumination
 - allows for custom implementation -> smoothly integrates with other engines

 Sample HelloRealtimeRadiosity shows RRIllumination in action.




\page vision Vision
 In typical situation, you have your own renderer with direct illumination.
 Vision can enhance it by adding indirect illumination.

 In atypical sutuation, Vision can calculate global illumination
 without any relation to your renderer.

 Header: RRVision.h

 - calculates global illumination in static scene
 - progressive refinement with permanent access to results (you can start calculation and read results 1ms later, you will get raw approximation)
 - calculated illumination is available in vertices
 - works with your units (screen colors or radiometry or photometry units or anything else)
 - display independent, purely numerical API
 - you can ask Vision about individual triangles, even adaptively subdivided;
   for complete vertex buffers or lightmaps, see RealtimeRadiosity library

 Sample HelloVision shows you the most simple use case:
 -# Create rr::RRScene.
 -# Create rr::RRObject using your object and insert it into scene. Repeat for all objects.
 -# Calculate global illumination using rr::RRScene::illuminationImprove().
 -# Read results using rr::RRScene::getTriangleMeasure().

 For integration with renderer, you may want to use some techniques from higher-level
 library Realtime Radiosity.



\page collider Collider
 Finds ray-mesh intersections.

 Header: RRCollider.h

 - thread safe, you can calculate any number of intersections at the same time
 - you can select technique in range from maximal speed to zero memory allocated
 - up to 2^32 vertices and 2^30 triangles in mesh
 - builds helper-structures and stores them in cache on disk

 Sample HelloCollider shows the most simple usage scenario:
 -# Create rr::RRMesh using your vertex/index buffers.
 -# Create rr::RRCollider using your mesh.
 -# Create rr::RRRay using your ray.
 -# Call rr::RRCollider::intersect() to find intersections. Repeat for all rays.

 Sample BunnyBenchmark shows how to detect collisions on all available
 CPUs/cores at once.


\page mesh Mesh
 Powerful interface to 3d triangle mesh.

 Header: RRMesh.h

 - knows tristrips, trilists, indexed or not (rr::RRMesh::create, rr::RRMesh::createIndexed)
 - can optimize:
   - vertex stitching (rr::RRMesh::createOptimizedVertices)
   - removes degenerated triangles (rr::RRMesh::createOptimizedTriangles)
 - merges many small meshes into one big mesh without additional memory (rr::RRMesh::createMultiMesh)
 - saves/loads to disk (rr::RRMesh::save, rr::RRMesh::load)
 - extensible, you can add new channels like texture coords (rr::RRChanneledData)
 - allows for procedural meshes, requires no memory (implementing your rr::RRMesh takes few minutes)
 - up to 2^32-2 vertices and 2^32-2 triangles in mesh
 - thread safe, you can use mesh in any number of threads at the same time

 Sample HelloMesh shows the most simple usage scenario,
 mesh is created out of existing array of vertices.


\page math Math
 Basic math classes used by whole Lightsprint SDK.

 Header: RRMath.h

 - rr::RRReal holds one real number, which is float at the moment
 - rr::RRVec2 is vector of 2 real numbers
 - rr::RRVec3 is vector of 3 real numbers
 - rr::RRVec4 is vector of 4 real numbers

*/
