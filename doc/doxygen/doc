namespace rr
{

/**

\file doc
\brief Documentation only.


\mainpage Lightsprint SDK

 \image html intro.jpg

 \section root_welcome Welcome to Lightsprint Software Development Kit
 - \subpage main_introduction
 - \subpage main_news
 - \subpage main_scenarios
 - \subpage main_features
 - \subpage main_platforms
 - \subpage main_deployment
 - \subpage main_credits

 \section root_integrations Integrations
 - \subpage main_gamebryo30
 - \subpage main_gamebryo26
 - \subpage main_ue3

 \section root_artists_guide Artist's guide
 - \subpage main_artist_offline
 - \subpage main_artist_realtime

 \section root_programmers_guide Programmer's guide
 - \subpage main_building
 - \subpage main_integration
 - \subpage main_inputs
 - \subpage main_data_access
 - \subpage main_conventions "Conventions (units, scale, floats...)"
 - \subpage main_api

 \section root_samples Samples etc
 - \subpage main_samples
 - \subpage main_trouble




\page main_introduction Introduction

  Realistic illumination looks good and attracts more users.
  While direct illumination has been 'solved' by science and software developers of 20th century,
  global illumination still challenges both sides. \subpage details

  Lightsprint is first to come with physically correct 
  global illumination synthesis so fast, that it 
  is suitable not only for precalculations, but also for realtime rendering in dynamic scenes.

  Lightsprint SDK offers you single flexible API for both realtime global illumination rendering
  and non-realtime lighting precalculations.

 \image html lowpoly3.jpg
  <center>realtime global illumination in scene with dynamic light and dynamic objects</center>


\page details Details
 In our real world, we see visible light coming mostly from special surfaces 
 (hot wolfram fibre in bulb, luminofor of fluorescent lamp)
 or from whole volumes of plasma (sun, fire).
 We call these surfaces and volumes <b>source of direct illumination</b>.

 Light from sources of direct illumination reaches other surfaces 
 where part of light gets absorbed and part reflected.
 Reflected part is what we see and what makes objects look lit by direct illumination.
 When we see the reflected part, we say that object has <b>direct illumination</b>.

 Reflected light from direct illumination reaches other surfaces, partially reflects,
 reaches other surfaces, partially reflects etc.
 When we see sum of these reflected parts, we say that object has <b>indirect illumination</b>.

 Illumination we see in real world is sum of direct and indirect illumination.

 Computer graphics tries to simulate this process in order to generate realistic images.
 This is however very time consuming process.
 So realtime computer graphics in 99% of cases resigns to real-world sources of direct 
 illumination and uses imaginary <b>"point", "spot" or "directional" lights</b>.
 These fictitious sources of direct illumination
 allow realtime computer graphics to calculate direct illumination very quickly.
 This process includes calculation of <b>shadows in direct illumination</b>.
 There are many realtime techniques for calculating shadows in direct illumination,
 most notably shadow mapping, volumetric/stencil shadows and projected/texture based shadows.

 There is still problem with indirect illumination, which remains
 hard to be computed quickly.




\page main_scenarios Usage scenarios

 \section scenario2 Lightsprint in toolchain, precomputes GI, realtime GI previews

  - Saves months of work to graphics artists and designers,
    previously spent in lightmap rebuilds or fake light placement.

  - Realtime GI preview allows artists to find visually more attractive positions / settings for lights.

  - Saves months spent in adapting your data for external global illumination
    tools. Other tools don't support arbitrary materials and lights.

  - Fast path for incorporating realtime global illumination into future games.

 \section scenario1 Lightsprint in game or architectural visualization, renders realtime GI

  - Greatly improves realism and visual appeal.

  - Requires zero or minimal level preprocessing, saves time previously spent on infinite levels builds.

  - Simplifies integration of mods and other user provided assets.

  - Supports arbitrary materials / shaders, even those writen by modders
    after game release.

  - Publicity, be first with this level of realism in game.

  - See <a href="http://dee.cz/lightsmark">Lightsmark</a>
    as an example, it's a simple demo based on Lightsprint SDK.

  \image html samples/Lightsmark3.jpg



\page main_features Features

This is a brief list of Lightsprint features, see \ref main_data_access,
\ref main_api and \ref main_samples for more details.

Global illumination
- realtime global illumination / realtime radiosity / realtime raytracing
- realtime penumbra shadows, soft shadows
- realtime color bleeding
- dynamic lights
- dynamic objects
- dynamic skybox
- multithreaded, all cores/CPUs and GPU work at once
- supports work distributed in cluster of computers
- computed and rendered in HDR
- custom scale on inputs/outputs (HDR/sRGB/other)
- scene size not limited

\ref inputs_light_sources "Light source formats (inputs)"
- spot, point, directinal lights
- area light
- skybox (LDR, HDR texture)
- emissive materials (LDR, HDR texture)

Lighting computed (outputs)
- lightmap
- directional lightmap for radiosity normal mapping/RNM
- ambient map
- ambient occlusion, global ambient occlusion
- diffuse environment map
- specular environment map
- bent normal map
- vertex buffer with colors or bent normals
- illumination of triangle or vertex
- illumination at ray end
- any combination of direct/indirect/global illumination

Renderers
- integrates with external renderers
- includes OpenGL 2.0 shader based renderer

Scene formats
- Collada 1.4 (.DAE)
- Gamebryo (.GSA)
- 3DS Max (.3DS)
- Quake 3 (.BSP)
- OBJ (.OBJ)
- MGF (.MGF)
- Unreal Engine 3 (internal structures)
- framework for custom formats
- complete source code

Texture formats
- JPG, PNG, EXR, HDR, DDS, TGA, BMP, TIF, GIF...
- cube textures
- 96bit float textures

Materials
- supports all types of materials
- diffuse maps, specular maps
- emissive maps, transparency/opacity maps

Realtime/precomputed
- supports realtime illumination
- supports precomputed illumination
- supports mix of realtime and precomputed illumination

GPU/API access
- full control over GPU access, source code
- full control over filesystem access, source code
- full control over scene data loading, source code

Ray-Mesh collisions
- up to 200x faster than commercial physical engines
- small memory footprint, typically 10x smaller than commercial physical engines
- multithreaded
- up to 4294967295 vertices in mesh
- up to 1073741824 triangles in mesh
- triangle lists/strips/indexed/nonindexed
- floats, doubles, halfs, ints, shorts
- custom mesh data structures without data duplication
- uniform scaling, non uniform scaling
- singlesided tests, doublesided tests
- number of sides defined by material
- return one or gather all collisions
- custom action at collision
- returns intersection distance, 2D and 3D position
- returns normal, plane and face side that was hit
- high precision, higher than commercial physical engines
- high reliability, 7 years under heavy load





\page main_credits Third party libraries

 Lightsprint integrated into game engine doesn't need any third party library.

 Lightsprint without game engine needs functions for scene loading and GPU access,
 this is why several free open source libraries with permissive licenses are used.
 You are free to download their sources and modify them, use them in commercial applications
 without need to open your source code etc.
 All of these libraries serve as optional extensions, global illumination solver doesn't need them.
 
 Libraries used by LightsprintCore (global illumination solvers):
 - none

 Used by LightsprintGL (optional OpenGL support):
 - \subpage tpl_glu
 - \subpage tpl_glew
 - \subpage tpl_wx
 - \subpage tpl_mesa

 Used by LightsprintIO (optional file format support):
 - \subpage tpl_freeimage
 - \subpage tpl_fcollada
 - \subpage tpl_libxml2
 - \subpage tpl_fragments
 - \subpage tpl_gamebryo

 Used by samples (completely optional):
 - \subpage tpl_glut
 - \subpage tpl_bunny

 Installation of 3rd party components:
 - Windows: works out of the box
 - Linux: all dependencies can be resolved by
   - Ubuntu: <code>sudo apt-get install libglu1-mesa-dev libglew1.5-dev libglut3-dev libfreeimage-dev libxml2-dev</code>
   - Fedora: <code>pkcon install mesa-libGLU-devel glew-devel freeglut-devel freeimage-devel libxml2-devel</code>

\page tpl_glu GLU
  - Windows: should be already installed, part of PlatformSDK by Microsoft
  - Linux (including PS3): should be already installed, install using
    - Ubuntu: <code>sudo apt-get install libglu1-mesa-dev</code>
    - Fedora: <code>pkcon install mesa-libGLU-devel</code>
  - XBox360, PS3 with system software: not used

\page tpl_glew GLEW
  - www: <a href="http://glew.sourceforge.net/">GLEW</a>
  - Windows: precompiled version 1.5.0 is a part of SDK
  - Linux: install using
    - Ubuntu: <code>sudo apt-get install libglew1.5-dev</code>
    - Fedora: <code>pkcon install glew-devel</code>
    - Note that we <code>\#include <GL/glew.h></code>, but SDK contains <code>include/gl/glew.h</code>.
      This ensures that version we bundle for Windows won't be used on Linux.
      You can safely install and use different version in your Linux system.
  - PS3 Linux:
    - download and unpack the latest source code package
    - type <code>make</code>
    - type <code>sudo make install</code>
    - There is a known issue with simultaneously using GLEW and Mesa: GLEW happens to undefine
      macro <code>GLAPIENTRY</code> which leads to compile errors. As a workaround, open the file
      "/usr/include/GL/glew.h" and comment-out the statement <code>\#undef GLAPIENTRY</code> at line 10767
      (valid for version 1.5.0)
  - XBox360, PS3 System Software: not used

\page tpl_wx wxWidgets
  - www: <a href="http://wxwidgets.org//">wxWidgets</a>
  - optional, source code licensees can remove by deleting <code>\#define SUPPORT_SCENEVIEWER</code> in <code>include/Lightsprint/GL/SceneViewer.h</code>
  - Windows: wxWidgets 2.9.0 is used internally by LightsprintGL library, it's not visible from outside (no headers or dll files)
  - other platforms: not used

\page tpl_mesa Mesa 3D
  - www: <a href="http://mesa3d.org/">Mesa 3D</a>
  - Windows: not used
  - Linux: not used
  - PS3 Linux: required as a rendering front end for samples, since there are no
    hardware accelerated RSX drivers provided. Please follow these installation instructions:
    - download and unpack MesaLib and MesaGLUT packages (the latest version at the time of
      writing this document is 7.0.3).
    - type <code>make linux-ppc</code>
    - open the file "configs/default" and make sure the variable <code>INSTALL_DIR</code> is set to <code>usr/local</code>.
      This will ensure that Mesa will install to <code>/usr/local/lib</code> and will not interfere with the system default
      OpenGL library located at <code>usr/lib</code>.
    - type <code>sudo make install</code>
    - type <code>export LD_LIBRARY_PATH=/usr/local/lib</code> to make linker search for Mesa

\page tpl_freeimage FreeImage
  - www: <a href="http://freeimage.sourceforge.net/">FreeImage</a>
  - optional, remove by deleting <code>\#define SUPPORT_IMAGES</code> in <code>src/LightsprintIO/supported_formats.h</code> (for Linux, remove linking from makefile)
  - Windows: precompiled version 3.10.0 is a part of SDK
  - Linux (including PS3 Linux): install using
    - Ubuntu: <code>sudo apt-get install libfreeimage-dev</code>
    - Fedora: <code>pkcon install freeimage-devel</code>
    - Note that we <code>\#include <FreeImage.h></code>, but SDK contains <code>include/freeimage.h</code>.
      This ensures that version we bundle for Windows won't be used on Linux.
      You can safely install and use different version in your Linux system.
  - XBox360, PS3 with system software: not used
  - This software uses the FreeImage open source image library. FreeImage is used under the <a href="http://freeimage.sourceforge.net/freeimage-license.txt">FIPL, version 1.0</a>.

\page tpl_fcollada FCollada
  - www: <a href="http://www.feelingsoftware.com/content/view/62/76">FCollada</a>
  - optional, remove by deleting <code>\#define SUPPORT_COLLADA</code> in <code>src/LightsprintIO/supported_formats.h</code> (for Linux, remove references from makefile)
  - Windows, Linux (including PS3): precompiled version 3.05B (\subpage fcollada_patch "patched") is a part of Lightsprint SDK
  - XBox360, PS3 with the System Software: not used
  - Linux / PS3 Linux: If you wish to build the library on your own, please note that the version 3.05B
    (which is the latest one available at the time of writing this document) does not yet officially support Linux.
    It is likely that this will change in the near future. Until then, please follow these instructions:
    - Download and unpack the "FCollada_FREE_3.05B.zip" package from <a href="http://sourceforge.net/projects/colladamaya/">Sourceforge</a>.
    - Rename the directory <code>FCollada/LibXML</code> to <code>FCollada/libxml</code> in order to prevent case sensitivity problems in includes.
    - Define preprocessor token "LINUX" in your project/makefile settings. This is necessary since FCollada sources rely on it
      and some Linux distributions define just lowercase "linux" token.
    - Open the file <code>FCollada/FUtils/FUFileManager.cpp</code> and change "size" to "(unsigned int) size" at line 392.
    - On 64-bit platforms, open the file <code>FCollada/FUtils/FUStringBuilder.h</code> and replace "long" by "long long" at lines 139 and 140.
    - When building FCollada, use O2 optimization level for 64bit release version and O1 for 32bit to prevent linking issues with templates.
    - We provide a makefile located at "src/LightsprintIO/ImportCollada" for your convenience.
  - by Feeling Software, used under MIT license

\page fcollada_patch FCollada patch
  Precompiled FCollada 3.05B in Lightsprint SDK includes our bugfix:

  File: FCollada/FUtils/FUUniqueStringMap.cpp
  \code
	// this is orifinal fcollada 3.05b code,
	// it splits "a1" and "a01" to {"a",1}, failing in documents with a1 and a01 materials
	//while (len > 0 && prefix[len-1] >= '0' && prefix[len-1] <= '9')
	//{
	//	prefix.erase(len-1, len);
	//	--len;
	//}

	// this Lightsprint patch splits "a1" to {"a",1}, "a01" to {"a0",1}
	size_t fullLen = len;
	size_t goodLen = len;
	while (len > 0 && prefix[len-1] >= '0' && prefix[len-1] <= '9')
	{
		if (len == fullLen || prefix[len-1] != '0') goodLen = len-1;
		--len;
	}
	prefix.erase(goodLen, len);
  \endcode

  Test case. Patched Fcollada opens it without errors, original FCollada reports errors:
  \code
	<?xml version="1.0" encoding="utf-8"?>
	<COLLADA xmlns="http://www.collada.org/2005/11/COLLADASchema" version="1.4.1">
	  <library_effects>
	    <effect id="a01">
	    </effect>
	    <effect id="a1">
	    </effect>
	  </library_effects>
	  <library_materials>
	    <material id="a1-material" name="a1-material">
	      <instance_effect url="#a1"/>
	    </material>
	  </library_materials>
	</COLLADA>
  \endcode

	
\page tpl_libxml2 libxml2
  - www: <a href="http://xmlsoft.org/">libxml2</a>
  - optional, remove by disabling \ref tpl_fcollada
  - Windows: not used
  - Linux (including PS3 Linux): should be already installed, install using
    - Ubuntu: <code>sudo apt-get install libxml2-dev</code>
    - Fedora: <code>pkcon install libxml2-devel</code>
  - used under MIT license

\page tpl_fragments code fragments
  - .3ds .bsp and .mgf loaders contain 3rd party open source code
  - optional, remove loaders by deleting <code>\#define SUPPORT_3DS, \#define SUPPORT_QUAKE3, \#define SUPPORT_MGF</code> in <code>src/LightsprintIO/supported_formats.h</code>
  - for copyright information, see headers of individual files in src/LightsprintIO/Import*

\page tpl_gamebryo Gamebryo
  - www: <a href="http://emergent.net">Gamebryo</a>
  - Gamebryo is a commercial game engine offered by Emergent Game Technologies
  - for Gamebryo licensee, we include Gamebryo integration code developed in cooperation of Lightsprint and Emergent Game Technologies
  - optional, remove by deleting <code>\#define SUPPORT_GAMEBRYO</code> in <code>src/LightsprintIO/supported_formats.h</code>

\page tpl_glut glut
  - www: <a href="http://www.opengl.org/resources/libraries/glut/">GLUT</a>
  - Windows: precompiled version 3.7.6 <a href="http://dee.cz/glut">patched</a> is a part of SDK
  - Linux (including PS3): install using
    - Ubuntu: <code>sudo apt-get install libglut3-dev</code>
    - Fedora: <code>pkcon install freeglut-devel</code>
    - Note that we <code>\#include <GL/glut.h></code>, but SDK contains <code>include/gl/glut.h</code>.
      This ensures that version we bundle for Windows won't be used on Linux.
      You can safely install and use different version in your Linux system.
  - XBox360, PS3 with system software: not used

\page tpl_bunny Bunny Benchmark framework
  - Bunny Benchmark sample contains framework code and data provided by benchmark author
  - framework must be present in order to get comparable results
  - for copyright information, see headers of individual files in samples/BunnyBenchmark/*





\page main_deployment Deployment

  It can't be easier.

 \section deploy_setup Setup

  Lightsprint SDK does not need any setup, environment variables,
  registry entries etc.
  It works from any location in filesystem (local disk or network).

 \section deploy_programmers Deployment - game programmers

  Programmers need access to complete SDK.
  For programmers evaluating Lightsprint SDK,
  deployment consists of unpacking SDK archive to any location.
  After acquiring full license, the easiest deployment technique is
  to put Lightsprint SDK under your version control system,
  so that all programmers get it via regular source code update.

  Programmers integrate Lightsprint SDK into toolchain or engine for artists and players.

 \section deploy_artists Deployment - game artists

  Artists usually don't interact with Lightsprint files directly,
  they use Lightsprint integrated into game engine and tools.
  Integration needs access only to small subset of SDK's files.
  For example in case of Unreal Engine 3 integration,
  the only new files for artists are LightsprintCore.vs2005.dll
  and licence_number.
  Artists may also need documentation (doc/Lightsprint.chm) to
  check brief \ref root_artists_guide.
  Programmers should include relevant files into game's engine/toolchain,
  so that artists get integration next time they update,
  without any additional effort.

 \section deploy_players Deployment - game players

  Games with static lighting (lightmaps) precomputed by Lightsprint SDK
  don't need to redistribute any Lightsprint SDK files.

  Games with lighting computed in real-time by Lightsprint may
  depend on Lightsprint SDK redistributable files, similarly to game
  tools used by artists.
  Programmers should include relevant (and only relevant) files
  into game's distribution.




\page main_artist_offline Static GI

  Static lighting is a mainstream approach today.
  Superior lighting quality is reached at cost of fixing lights in static positions,
  global illumination is precomputed.

  Lightsprint SDK helps by building
  - lightmaps, directional lightmaps, bent normals and ambient occlusion
    for static objects
  - lightfields for dynamic objects

 \section artist_offline_buildlightmaps BuildLightmaps tool
  BuildLightmaps is a commandline tool ready for immediate use.
  \ref samples_offline "More about BuildLightmaps".
  \n Enter LightsprintSDK/samples/BuildLightmaps directory and see .bat files
  that demonstrate how to use it (comments inside).
  Run BuildLightmaps.bat for complete list of commandline arguments.
  \n BuildLightmaps comes with source code, so programmers can customize it.

 \section artist_offline_custom Custom tools
  If you prefer lightmap building integrated into your existing tools 
  (e.g. game editor),
  consult your programmers. Lightsprint functions are easily
  accessible for tool programmers, they were already integrated into
  several game editors.

 \section artist_offline_geometry Geometry
  Any triangle-based geometry is supported without restrictions.
  \n Scene size is virtually unlimited with 64bit code.
  With 32bit code, read how to relax \ref trouble_memory "scene size limits".
  \n In rare cases, artifacts may appear in proximity of huge triangles.
  Solution is to avoid or temporarily tessellate huge triangles.

 \section artist_offline_materials Materials
  All material types are supported.
  There's no need for any additional information,
  Lightsprint automatically converts your engine's native materials to
  Lightsprint materials used during calculation.

 \section artist_offline_lights Lights
  All light sources are supported - point, spot, directional, emissive materials,
  sky (flat color, LDR or HDR texture).



\page main_artist_realtime Realtime GI

  Realtime lighting using dynamic lights is a mainstream approach today,
  however its realism was always
  severely limited by lack of properly computed indirect light.
  \n Lightsprint solved realtime global illumination problem (see \ref samples_realtime "samples").
  \n Following hints help you get good performance and quality in your projects.

  For purpose of realtime GI calculation, we expect scene split in two parts, static and dynamic.

 \section artist_realtime_static Static scene
  Static scene is a scene skeleton, big objects that never move, e.g. walls.
  Number of triangles in static scene is the most important performance and memory footprint factor,
  so we recommend creating as lowpoly walls as possible, with eventual details
  baked into normal maps or parallax occlusion maps.

  Realtime GI consists of several components mixed together: per-pixel direct lighting,
  per-pixel indirect lighting and per-vertex indirect lighting.
  Because of per-vertex component, all static meshes must satisfy one simple rule
  required by all engines with per-vertex lighting:
  \n Two triangles are disjunct, share 1 vertex or share 1 edge and 2 vertices.
  \n So in other words, it is not allowed to
  - overlap triangles
  - intersect triangles
  - place edge in the middle of other triangle
  - place vertex in the middle of other edge

  \image html triangles.png

  See that all forbidden cases can be easily fixed.
  This operation can be automated.

  It is also recommended to avoid 'needles', triangles with needle-like shape,
  as artifacts may appear in their proximity.

 \section artist_realtime_dynamic Dynamic scene
  Dynamic scene is made of objects that freely move and of small objects.
  Number of triangles in dynamic scene has no impact on performance,
  so we recommend using as detailed models as suitable.

  Realtime GI is fully per-pixel, so restrictions related to per-vertex lighting
  don't apply to dynamic objects.

 \section artist_realtime_materials Materials
  All material types are supported.
  There's no need for any additional information,
  Lightsprint automatically converts your engine's native materials to
  Lightsprint materials used during calculation.
  Complex materials don't slow down GI calculation,
  so we recommend using as good looking materials as possible.

 \section artist_realtime_lights Lights
  All light sources are supported - point, spot, directional, emissive materials,
  sky (flat color, LDR or HDR texture) and they may arbitrarily change in realtime.





\page main_building Building

 \section building_windows Windows

  Lightsprint SDK includes solutions for all supported Visual C++ compilers,
  simply open solution and build.

 \section building_linux Linux

  Lightsprint SDK includes makefiles for Linux on all supported architectures.
  Simply run make in directory you want to make.

 \section building_source LightsprintGL from source code

  LightsprintGL source code licensee only:
  \n Before building LightsprintGL from source code,
  wxWidgets libraries must be available. See \subpage obtaining_wxwidgets.


\page obtaining_wxwidgets Obtaining wxWidgets

 wxWidgets is 3rd party GUI library.
 It's optional, and even if you use it, you don't have to redistribute any wxWidgets files with your application,
 you need it only when rebuilding LightsprintGL from source code.

 \section wx_windows Windows
   - Get wxWidgets 2.9 source code from wxWidgets.org (any official release or svn) (SDK is built from rev 61767).
   - Change wxUSE_GLCANVAS from 0 to 1 (in include/wx/msw/setup.h).
   - If you use one version of Visual Studio and target only win32,
     you can simply build appropriate solution, e.g. build/msw/wx_vc9.sln.
     If you target x64, the only additional step is to add x64 target to that solution.
   - If you use multiple Visual Studio versions and/or target both win32 and x64,
     all wxWidgets solutions would build to the same directory and overwite files.
     We provide script that builds all targets at once and keeps them separated, follow instructions:
     - Set environment variable WXWIDGETS_DIR to your wxWidgets root,
       e.g. C:\\wxWidgets. No spaces please.
     - Open \$(WXWIDGETS_DIR)\\include\\msvc\\wx\\setup.h and replace
       \code
	#ifdef WXUSINGDLL
		#define wxLIB_SUBDIR vc_dll
	#else // !DLL
		#define wxLIB_SUBDIR vc_lib
	#endif // DLL/!DLL
       \endcode
       by
       \code
	#if _MSC_VER<1400
		#define wxCOMPILER 2003
	#elif _MSC_VER<1500
		#define wxCOMPILER 2005
	#else
		#define wxCOMPILER 2008
	#endif

	#ifdef _M_X64
		#define wxBITS 64
	#else
		#define wxBITS 32
	#endif

	#ifdef WXUSINGDLL
		#define wxLIB_SUBDIR wxCONCAT5(vc,wxCOMPILER,_,wxBITS,_dll)
	#else // !DLL
		#define wxLIB_SUBDIR wxCONCAT5(vc,wxCOMPILER,_,wxBITS,_lib)
	#endif // DLL/!DLL
       \endcode
     - Run bin/build_wxWidgets.bat.
     - LightsprintGL DLL works now. For static LightsprintGL, add wx library path
       to <code>Tools / Options / Projects and Solutions / VC++ Directories / Library Files</code>.
	- \$(WXWIDGETS_DIR)\\lib\\vc2008_32_lib for vc2008 win32 target
	- \$(WXWIDGETS_DIR)\\lib\\vc2005_64_lib for vc2005 x64 target
	- etc

 \section wx_linux Linux
   - For now, wxWidgets is not used by Linux port.
   - When we start using it, obtaining it will be as simple as [example for Ubuntu]:
     \code
	sudo apt-get install libwxgtk2.9-dev
     \endcode



\page main_integration Integration

 \section integr_tool Precalculations / for toolchain
  - \ref main_gamebryo30 "Precalculations in Lightspeed"
  - \ref main_gamebryo26 "Precalculations in Gamebryo 2.6"
  - \ref main_ue3 "Precalculations in Unreal Engine 3"
  - \subpage integration_tool_1
  - \subpage integration_tool_2

 \section integr_rt Realtime / in game
  - \subpage integration_realtime_1
  - \subpage integration_realtime_3
  - \subpage integration_realtime_4




\page integration_tool_1 Precalculations in your scene loaded from disk

 You can immediately calculate lightmaps, ambient maps and bent normals
 if you convert your scenes to supported formats and use existing
 sample applications.

 <table width=100% border=0 cellpadding=3 cellspacing=0><tr align=left style="background-color:#dddddd"><td>
 Recommended approach:
 </td></tr></table>

  - Convert your scene to Collada format,
    and load it into CPULightmaps, BuildLightmaps, SceneViewer or Lightmaps sample.

 <table width=100% border=0 cellpadding=3 cellspacing=0><tr align=left style="background-color:#dddddd"><td>
 Scheme of application:
 </td></tr></table>

  - CPULightmaps sample 
    is built on top of purely numerical LightsprintCore and scene importers.
    BuildLightmaps, SceneViewer and Lightmaps samples use also OpenGL 2.0 based LightsprintGL.
    Left: CPULightmaps. Right: BuildLightmaps, SceneViewer, Lightmaps.
  <table border=0 width=95%><tr align=top><td>
  \image html Integration1c.png
  </td><td>
  \image html Integration1b.png
  </td></tr></table>

 <table width=100% border=0 cellpadding=3 cellspacing=0><tr align=left style="background-color:#dddddd"><td>
 Steps:
 </td></tr></table>

  - Convert scenes to Collada 1.4 (.DAE).
  - If you plan to compute maps rather than per-vertex values, include unwrap in second uv channel.
  - Change name of scene in sample .cpp, so it loads your scene. Or drop your scene on SceneViewer*.exe.

 <table width=100% border=0 cellpadding=3 cellspacing=0><tr align=left style="background-color:#dddddd"><td>
 Expected time spent:
 </td></tr></table>

  - 1 day


\page integration_tool_2 Precalculations in your scene accessed in memory

  If you prefer other data source to Collada,
  use your scene loader and write adapter for accessing your scene in memory.

 <table width=100% border=0 cellpadding=3 cellspacing=0><tr align=left style="background-color:#dddddd"><td>
 Recommended approach:
 </td></tr></table>

  - Modify SceneViewer sample to access scenes loaded to memory by your loader.

 <table width=100% border=0 cellpadding=3 cellspacing=0><tr align=left style="background-color:#dddddd"><td>
 Scheme of application:
 </td></tr></table>

  - Modified SceneViewer newly depends on your scene loading code.
  \image html Integration2.png

 <table width=100% border=0 cellpadding=3 cellspacing=0><tr align=left style="background-color:#dddddd"><td>
 Steps:
 </td></tr></table>

  - Open SceneViewer project
  - Copy RRObjectCollada.* to RRObjectCustom.* and add it to the project
  - Delete all FCollada \#includes from RRObjectCustom.h
  - Build reports errors on all references to FCollada,
    change code so it works with your engine's 3d model rather than with FCollada.
    Replace all references to FCollada with your custom format.
    For more details, see
    - comments in RRObjectCustom source code
    - <b> \subpage integration_step_2 </b>
    - <b> \subpage integration_step_3 </b>
    - interfaces of RRMesh and RRObject you implement
  - Done. SceneViewer renders scene in your native format.
    You can test both realtime and precalculated per-vertex and per-pixel lighting.
    You can use your new scene adapter in any sample.

 <table width=100% border=0 cellpadding=3 cellspacing=0><tr align=left style="background-color:#dddddd"><td>
 Expected time spent:
 </td></tr></table>

  - 1-4 days




\page integration_realtime_1 Realtime GI in Lightsprint renderer

 You can immediately render realtime global illumination in your 3d scenes
 if you convert them to supported format and load into existing sample application.
 You can also use \ref integration_tool_2 "your scene loader and adapter".

 <table width=100% border=0 cellpadding=3 cellspacing=0><tr align=left style="background-color:#dddddd"><td>
 Recommended approach:
 </td></tr></table>

  - Convert your scene to Collada format
    and load it into Lightmaps or RealtimeLights (or load .3ds to RealtimeRadiosity) sample.

 <table width=100% border=0 cellpadding=3 cellspacing=0><tr align=left style="background-color:#dddddd"><td>
 Scheme of application:
 </td></tr></table>

  - Lightmaps and RealtimeRadiosity samples are
    built on top of purely numerical LightsprintCore, OpenGL 2.0 based LightsprintGL and scene importers.
    Left: Lightmaps. Right: RealtimeRadiosity.
  <table border=0 width=95%><tr align=top><td>
  \image html Integration1b.png
  </td><td>
  \image html Integration1a.png
  </td></tr></table>

 <table width=100% border=0 cellpadding=3 cellspacing=0><tr align=left style="background-color:#dddddd"><td>
 Steps:
 </td></tr></table>

  - Make sure static scene is suitable for per-vertex lighting (more in \ref artist_realtime_static "artist's guide")
  - Convert scenes to Collada 1.4 (.DAE).
  - Change name of scene in Lightmaps.cpp, so it loads your scene.

 <table width=100% border=0 cellpadding=3 cellspacing=0><tr align=left style="background-color:#dddddd"><td>
 Expected time spent:
 </td></tr></table>

  - 1 day



\page integration_realtime_3 Realtime GI in your OpenGL renderer

  If you prefer other OpenGL renderer to LightsprintGL, switch to renderer of your choice.

 <table width=100% border=0 cellpadding=3 cellspacing=0><tr align=left style="background-color:#dddddd"><td>
 Recommended approach:
 </td></tr></table>

  - Modify RealtimeRadiosity sample to use your renderer.
    Or modify your application/engine to use code from RealtimeRadiosity sample
    that builds realtime GI buffers.

 <table width=100% border=0 cellpadding=3 cellspacing=0><tr align=left style="background-color:#dddddd"><td>
 Scheme of application:
 </td></tr></table>

  - Application uses LightsprintCore and LightsprintGL to calculate GI,
    while your engine does scene loading and rendering.
  \image html Integration3.png

 <table width=100% border=0 cellpadding=3 cellspacing=0><tr align=left style="background-color:#dddddd"><td>
 Steps:
 </td></tr></table>

  - Make sure your renderer supports realtime shadows other than stencil based, e.g. shadowmapping
    or projected shadows. If it doesn't, add them or contact us for further support.
  - <b> \subpage integration_step_4 </b>
  - <b> \subpage integration_step_5 </b>
  - Render our indirect illumination, see <b> \ref main_data_access </b>

 <table width=100% border=0 cellpadding=3 cellspacing=0><tr align=left style="background-color:#dddddd"><td>
 Expected time spent:
 </td></tr></table>

  - 1 week




\page integration_realtime_4 Realtime GI in any renderer

  If you want to use your renderer, but it is not OpenGL based,
  write custom GPU access routines as a replacement for LightsprintGL.

 <table width=100% border=0 cellpadding=3 cellspacing=0><tr align=left style="background-color:#dddddd"><td>
 Recommended starting point:
 </td></tr></table>

  - Modify your application/engine to use LightsprintCore.

 <table width=100% border=0 cellpadding=3 cellspacing=0><tr align=left style="background-color:#dddddd"><td>
 Scheme of application:
 </td></tr></table>

  - Different approaches: You can expose Lightsprint engine to your
    applications or hide it inside your engine.
  <table border=0 width=95%><tr align=top><td>
  \image html Integration4a.png
  </td><td>
  \image html Integration4b.png
  </td></tr></table>

 <table width=100% border=0 cellpadding=3 cellspacing=0><tr align=left style="background-color:#dddddd"><td>
 Steps:
 </td></tr></table>

  - <b> \subpage integration_step_6 </b>
  - render with computed data stored in RRBuffer lightmaps, environment maps and vertex buffers.
    See rr_gl::getTexture() as an example how texture buffers are adapted for use in OpenGL,
    it's basicly glTexImage2D(...,buffer->lock(BL_READ)) call. Alternatively, you can subclass
    RRBuffer so that it stores data directly in your renderable surface.

 <table width=100% border=0 cellpadding=3 cellspacing=0><tr align=left style="background-color:#dddddd"><td>
 Expected time spent:
 </td></tr></table>

  - 1-3 weeks






 
\page integration_step_2 Detect material properties

 Realtime global illumination is based on physically correct calculation of light transport.
 For such calculation it's necessary to know physical properties of surfaces.
 See RRMaterial for list of supported material properties of a surface.

 Fortunately you don't have to study advanced laws of physics for good results,
 you don't even need any additional information provided by artists who
 create materials or compose shaders. Everything can be detected automatically.

 In <b>special case</b> of RealtimeRadiosity example, materials contain diffuse texture
 without specular and transparency, so whole detection was reduced to calculating
 average color of diffuse texture and storing it into RRMaterial::diffuseReflectance.
 This took 1 hour.

 In <b>more general case</b> with known set of shaders,
 you can extend this approach and get all values by analyzing textures and other inputs
 used by shaders.
 This can take you few hours.
 Viability of this approach highly depends on your shaders and can't be decided here.
 If you are not sure, describe us your shaders and we will help you.

 In <b>fully general case</b>, you don't need any information about shaders.
 It works even if you let modders create new shaders, their properties will be autodetected.
 Everything you need is ability to render simple scene into small texture (16x16 pixels
 is typically enough)
 and calculate average color of rendered image. Follow these steps for each material

 -# Create an empty scene and place 1x1m rectangle covered by material in front of orthogonal camera
    in 1m distance, so that rectangle covers whole viewport, but nothing more.
    If material needs uv coordinates for textures, use whole texture space from 0,0 to 1,1 in rectangle.
 -# Clear to black and render rectangle.
    Store acquired average color as RRMaterial::diffuseEmittance.
 -# Clear to white and render rectangle.
    Store acquired average color minus emittance as RRMaterial::specularTransmittance.
 -# Add white point light without distance attenuation to the same position as camera.
    Clear to black and render rectangle.
    Store (acquired average color minus emittance)*1.0805 as RRMaterial::diffuseReflectance.
 -# If your engine's lights have separated diffuse and specular color, repeat previous step
    for RRMaterial::specularReflectance. Use white diffuse and black specular light
    in previous step, black diffuse and white specular light in this step.

 -  If you use materials with faked reflection maps (planar or cubic),
    make sure that reflection intensity drops to 0 in dark scene,
    or manually disable it before detection.
    If you apply faked reflection even in completely dark unlit scene, detection described above
    must think it's emissive material.
    Alternatively, if you don't have any emissive materials, you can simply set emissivity to 0.

 This automatic approach can be further extended to differentiate between
 diffuse and specular reflectance or even to detect complete BRDF.

 Of course you are allowed to use any other approach, e.g. let graphics artists
 enter all values by hand.



\page integration_step_3 Create object adapters

 Lightsprint transports light between object surfaces,
 so it needs to know everything
 about scene geometry and material properties.

 Lightsprint is designed to access your structures in arbitrary format,
 so you don't have to duplicate any data.
 This may save you huge amounts of memory, however,
 you must provide adapters that access your structures.

 Further saving is possible thanks to geometry instancing.
 Multiple objects with different materials and different illumination
 may share one mesh and collider.

 \section import_without_instancing Import without instancing

 For import without geometry instancing,
 see one of samples/Import3DS, samples/ImportQuake3, samples/ImportOBJ,
 samples/ImportMGF.
 It is everything necessary to load 3ds, Quake3, obj or mgf scene into 
 RRDynamicSolver.

 For sake of simplicity, adapters duplicate some data in memory
 and don't support geometry instancing.
 On the other hand, support for custom data is demonstrated
 on diffuse textures and uv coordinates.

 Both RRMesh and RRObject interfaces are implemented in one class,
 so one RRMesh can't be shared by multiple RRObject-s
 and instances are not supported.

 \section import_with_instancing Import with instancing

 For import with instancing, see samples/ImportCollada.
 (adapter for scenes loaded by freely available FCollada library)
 or src/LightsprintUE3 (adapter for import from Unreal Engine 3).

 Adapters don't duplicate any memory, all data are accessed directly
 in FCollada document.

 RRMesh and RRObject interfaces are implemented in two separated classes,
 and one RRMesh is shared by multiple RRObject-s, if scene contains instances.

 \section import_new New importer

 To import data in your format, pick one of existing importers
 and modify it to access your data.

 Alternatively, to write new importer from scratch, follow these steps:

 -  Create RRMesh for every static triangle mesh in your engine.
    \n\n
    You can immediately create them 
    from trilists, tristrips, indexed trilists, indexed tristrips
    using single call to RRMesh::create() or RRMesh::createIndexed().
    For other formats ask for our support or implement your own RRMesh,
    which is very simple.
    \n\n
    Note that these adapters don't duplicate your data
    and they support mesh optimizations and mesh aggregation,
    see RRMesh for details.
    \n\n
    Once you have RRMesh instance, create RRCollider using
    RRCollider::create().
    RRCollider::IT_LINEAR technique with minimal overhead is sufficient 
    for current version of RRDynamicSolver.
    \n\n
    Most convenient way to remember collider for later use is to
    attach it to your triangle mesh.
    You don't need to store pointer to RRMesh,
    it is available from collider using RRCollider::getMesh().
    \n\n
    RRDynamicSolver may use collider to calculate ray-mesh collisions,
    but it is available also to you via RRCollider::intersect().
    If you plan to use it and its performance is critical, use 
    other technique than RRCollider::IT_LINEAR.

 -  Implement your own RRObject and
    create its instance for every static object in your scene.
    \n\n
    By objects we understand identical meshes placed on different
    positions in scene, possibly using different materials (e.g. several
    cars with the same geometry, different position and possibly different color;
    they are different objects sharing one mesh).
    \n\n
    Default RRMesh::getTriangleMapping() returns realtime generated
    unwrap of low quality, for serious use of ambient maps, you should override
    RRMesh::getTriangleMapping() and provide your own unwrap.
    This is not necessary if you use vertex arrays and don't need lightmaps.
    \n\n
    Once you have RRObject instance, most convenient way to remember it
    for later use is to attach it to your object.





\page integration_step_4 Subclass RRDynamicSolver

 RRDynamicSolver is global illumination solver.
 For offline rendering, it is complete and it can be used immediately.
 For realtime rendering, subclass RRDynamicSolver and implement
 tasks specific for your renderer.

 \section step4_gl OpenGL

 rr_gl::RRDynamicSolverGL, subclass of RRDynamicSolver
 already implements GPU tasks using OpenGL.
 If you plan to use OpenGL realtime renderer (Lightsprint or any other),
 subclass RRDynamicSolverGL and implement one or more of these simple functions:

 - rr_gl::RRDynamicSolverGL::renderScene()
   \n Render your scene into shadowmap.

 - rr_gl::RRDynamicSolverGL::setupShader() [optional]
   \n Only for custom shader based lights.
   \n Set shader so that direct light+shadows+emissivity are rendered, but other
      material properties (diffuse texture etc) are ignored.

 See example implementation in RealtimeRadiosity sample.

 \section step4_dx Direct3D

 If you need global illumination in Direct3D renderer,
 it is possible to subclass directly RRDynamicSolver,
 and avoid any dependency on OpenGL.
 The only task in this scenario is described in \ref integration_step_6





\page integration_step_5 Use RRDynamicSolver subclass

 RRDynamicSolver class is your primary interface to Lightsprint engine.
 To add global illumination to your application,

 - Create instance of RRDynamicSolver or your subclass.
   (why subclass? described in \ref integration_step_4)

 - To start calculation,
   call RRDynamicSolver::setStaticObjects() with set of static objects participating in calculation.
   This call is expensive, design your application to avoid
   frequent changes of static scene.

 - Set lights, call RRDynamicSolver::setLights() with set of lights participating in calculation.
   Optionally call also RRDynamicSolver::setEnvironment() to add outdoor/sky lighting.
   These calls are cheap, you can change lights frequently.

 - 
 - Call RRDynamicSolver::calculate() often. If main loop of your
   application contains rendering of one frame, add one call to RRDynamicSolver::calculate().
   If you render scene only when it has changed,
   still call RRDynamicSolver::calculate() in every iteration of main loop,
   but if it returns IMPROVED, rerender scene.

 - If you use vertex/pixel buffers for rendering:
   \n When RRDynamicSolver::getSolutionVersion() changes,
   call RRDynamicSolver::updateLightmaps()
   to update illumination values stored in vertex/pixel buffers.

 - Call RRDynamicSolver::reportDirectIlluminationChange() whenever direct illumination changes.
   It is mainly when light moves or changes properties, but for higher precision,
   you may call it also when lit object moves and its shadow changes.

 - Call RRDynamicSolver::reportMaterialChange() whenever materials used in scene change.

 - Call RRDynamicSolver::reportInteraction() whenever user interacts or other reason for
   high responsiveness exists. Without reportInteraction calls, solver takes more CPU time
   and FPS decreases.

 - Call RRDynamicSolver::getIllumination() 
   to acquire static object's illumination, see \ref data_vertex_buffer and \ref data_pixel_buffer.

 - Call RRDynamicSolver::updateEnvironmentMap()
   to acquire static or dynamic object's illumination, see \ref data_environment_map.

 Nearly all of these calls are demonstrated in RealtimeRadiosity sample.





\page integration_step_6 Detect direct illumination

 For OpenGL based renderers, 
 LightsprintGL implements detection of direct illumination
 in rr_gl::RRDynamicSolverGL.

 For Direct3D and custom renderers, you need to reimplement
 detection of direct illumination.

 <b>What needs to be detected:</b> average color of each face;
 how does it look lit by your direct (not ambient) point, spot and directional lights
 and shadowed by your shadows.

 <b>What to do with detected values:</b> call RRDynamicSolver::setDirectIllumination().

 <b>Why is it important:</b> we have no other knowledge about your lights.
 You can use many light types with very complex lighting equations.
 You can arbitrarily change them. No problem. Just let us know what are the results -
 average colors produced by your shader.

 <b>How to implement it:</b> turn off ambient/radiosity, render all scene faces,
 read rendered image to system memory and extract average color for each face.
 This is the most simple and universal approach (works with any number of any lights),
 however you can think about alternatives. This depends highly on your renderer.

 \image html detect-dif.png
 Image shows arrangement of faces in matrix that makes extraction of average color/exitance simple.
 It wouldn't help to render faces in their original 3d positions, some would be probably
 hidden behind other faces. You can see that some faces are black, those are partially
 in shadow or completely unlit.
 You can also see that only 50% of texture space is used, triangles may be rearranged so that
 100% of space is used, however averaging face color would become more expensive.

 <b>Possible implementation in detail:</b> rendering faces into matrix
 requires one renderer enhancement - 2d position override - ability to render
 triangles to specified 2d positions while preserving their original look.

 For DX10 generation GPUs, solution is nearly as simple
 as adding two lines into geometry shader.
 Render as usual, using any combination of trilist/strip/indexed/nonindexed data,
 but at the end of geometry shader, override
 output vertex positions passed to rasterizer by new 2d triangle positions
 calculated right there from primitive id.

 For DX9 generation GPUs, implemention has two steps:
 - Triangle positions in matrix are generated by CPU into new vertex stream.
   At the end of vertex shader, vertex position passed to fragment shader is replaced by
   position read from additional vertex stream.
 - For purpose of detection, scene is rendered using non-indexed triangle list.
   This is necessary because if we want to render triangles with shared
   vertices to completely different positions in texture, we have to split 
   that vertices.

 <i>
 <b>Possible optimizations:</b>

 <b>Rendering irradiance:</b>
 For simple materials with diffuse texture only (such as in .3ds),
 process can be optimized by ignoring diffuse textures, thus rendering incoming light
 not multiplied by diffuse texture.
 Detected average face colors then correspond to intensity of light reaching 
 face (irradiance) instead of intensity of light leaving face (exitance),
 so detected color is passed to RRObjectAdditionalIllumination::setTriangleAdditionalMeasure
 as RM_IRRADIANCE, rather than RM_EXITANCE.

 \image html detect-nodif.png
 Image above shows optimized detection, faces are not modulated by material,
 so irradiance is detected. You can see mostly white faces, because scene is lit by white spotlight.
 Few orange pixels come from orange logo projected by spotlight.

 Optimized approach is not suitable for engines with texture atlases.
 If your material properties change very significantly over uv space,
 use original unoptimized approach for higher precision.

 <b>GPU averaging:</b>
 To decrease amount of data transferred from GPU to CPU and speed up
 whole process, it is recommended to calculate average triangle colors
 on GPU, using simple shader, write them into smaller texture
 and transfer this smaller textue to CPU.
 LightsprintGL does it using scaledown_filter.* shaders.

 \image html detect-scaled.png
 Image was scaled down by scaledown_filter.* shaders for purpose of
 faster primary illumination detection.
 It is resized back to original size only in this documentation.

 </i>




\page main_data_access Calculation and outputs

 \section calc_1 Lightsprint can calculate
  - \subpage data_illumination
  - \subpage data_ambient_occlusion
  - \subpage data_bent_normals

 \section calc_2 and store them in object's
  - \subpage data_vertex_buffer
  - \subpage data_pixel_buffer
  - \subpage data_environment_map

 \section calc_3 or quickly return single value for given
  - \subpage data_triangle
  - \subpage data_ray

 \section calc_0 Capabilities by speed
  - \subpage calc_realtime
    - \subpage calc_fireball
  - \subpage calc_offline

 Lightsprint is very flexible; for any object, it lets you create optimal
 structures that precisely match your quality/memory footprint requirements.
 For example, you can use pixel buffers only for objects that benefit from per-pixel details,
 use vertex buffers for the rest. You can mix formats even in single object,
 e.g. give it per-pixel lightmap with 8bit RGBA channels and sRGB space
 and per-vertex bent normals with floating point RGB channels and linear space.
 When (empty) buffers are created, single RRDynamicSolver::updateLightmaps()
 call fills them.

 Lightsprint automatically uses all processing power available in a single computer,
 it runs in multiple threads on all CPUs and CPU cores.

 \section calc_distributed Distributed calculation

 Lightsprint is ready for distribution of work in network / multiple computers,
 including computers without GPU. Expensive RRDynamicSolver::updateLightmaps() call
 (it is core of all lightmap, ambient occlusion map and bent normal map calculations)
 can be replaced by many small RRDynamicSolver::updateLightmap() calls
 and you are free to execute them in parallel on different computers.

 In more detail, you can run many clients that do
 \code
	RRDynamicSolver solver;
	solver.setStaticObjects(objects);
	solver.setLights(lights);
	solver.setEnvironment(environment);
	RRDynamicSolver::UpdateParameters params;
	params.quality = 1000;
	params.applyCurrentSolution = false;
	params.applyEnvironment = true;
	params.applyLights = true;
	solver.updateLightmaps(-1,-1,-1,&params,&params,NULL);
	params.applyCurrentSolution = true;
	params.measure_internal.direct = true;
	while(!done)
	{
		unsigned objectIndex = ...; //get object that was not updated yet
		RRBuffer* lightmap = RRBuffer::create(...);
		solver.updateLightmap(objectIndex,lightmap,NULL,NULL,&params);
		lightmap->save(filename);
		delete lightmap;
	}
 \endcode



\page data_illumination Illumination

 \section di1 Directional lightmaps / vertex colors

  While building lightmaps, Lightsprint gathers information about light directions.
  This information is optionally returned in two formats.

  1. Directional component is stored as 3 separated lightmaps or vertex buffers
  built as if surface normals are modified in 3 different directions.
  Result is compatible with Unreal Engine 3 directional lightmaps.
  3 lightmaps are sufficient for rendering, but together with standard non-directional
  lightmap (=fourth direction), all 4 lightmaps can be used for even higher precision.

  2. Directional component of lightmap or vertex buffer is stored separately 
  from irradiance component. See \ref data_bent_normals for
  details on directional component.

 \section di2 Global illumination lightmaps

  Global illumination lightmaps are precomputed with
  infinite light bounces, color bleeding and physically
  correct penumbra shadows from area lights.
  For mostly static scenes, precomputed GI lightmaps make very good sense.

  Global illumination usually contains sharp shadow edges,
  so it's not practical to store it per vertex in vertex buffer
  (result would be too blurry).

 \section di3 Ambient maps, per-vertex ambient

  Ambient maps and per-vertex ambient contain indirect component of illumination
  with infinite light bounces, color bleeding and indirect shadows;
  it's complete global illumination except for first light bounce.

  In scenarios with mixed static / dynamic objects, it's often
  advantageous to compute indirect illumination only
  and mix it with realtime rendered direct illumination
  with direct shadows.

  Per-pixel or per-vertex?
  \n
  Unlike global illumination, indirect illumination
  doesn't contain sharp shadow edges, so it's usually practical
  to store it per-vertex in vertex color buffer.
  Per-vertex ambient is slightly less precise in some situations,
  but it usually takes much less memory,
  so it's worth considering in memory restricted environments.
  In realtime scenarios, per-vertex ambient is preferred for
  higher speed over ambient maps.

  Ability to generate ambient maps or per vertex ambient is
  <b>fundamental for realtime global illumination</b>.
  To render realtime global illumination,
  start with renderer with direct illumination and shadows
  and add ambient map or per vertex ambient 
  computed by Lightsprint. Realtime per-vertex ambient is preferred
  for much higher speed.

 \section di4 Environment maps

  Environment maps store light incoming from all directions
  to single point in space. They are usually used to approximate
  light incoming to dynamic object.
  \n
  Environment maps may be processed so that single environment
  map lookup returns light incoming from single direction
  (specular environment map)
  or from whole hemisphere (diffuse environment map).

  See \ref data_environment_map for more details.

 \section di5 Other

  Outside most widely used global illumination lightmaps,
  per vertex ambient, ambient maps and environment maps,
  Lightsprint supports many other illumination types suitable for specific
  situations.
  Depending on parameters you pass to lighting calculation process,
  you can get direct only lighting, mix of independently
  enabled direct and indirect lighting from many light source types
  etc, with result stored in texture or vertex buffer, with optional
  directional component.
            
 \section di6 Data structures

  Lightsprint can store object's illumination in

  - <b> \ref data_vertex_buffer </b>

  - <b> \ref data_pixel_buffer </b>

  - <b> \ref data_environment_map </b>

 \section di7 Calculation

  Calculation of illumination is realtime or non-realtime process,
  depending on parameters set.
  Environment maps are always computed in realtime speeds.

  See data structures (links above) for more details on calculation.

 \section di8 Use in renderer

   See data structures (links above) for more details on use in renderer.



\page data_ambient_occlusion Ambient occlusion

 \section da1 [Direct] ambient occlusion

  Ambient occlusion on <a href="http://en.wikipedia.org/wiki/Ambient_occlusion">Wikipedia</a>

  [Direct] ambient occlusion is a function of a surface point and a surrounding geometry,
  with return value in 0..1 space,
  0 for surface point fully occluded by surrounding geometry
  and 1 for completely unoccluded point.

  [Direct] ambient occlusion is a result of direct illumination
  in a uniform white environment.

 \section da2 Global ambient occlusion

  Sometimes ambient occlusion is desired to include effect of
  multiple light bounces and color bleeding.
  Let's call it global ambient occlusion.
  \n
  Global ambient occlusion is a function with return value in 0..inf space,
  but with typical values inside 0..1 range.
  \n
  Lightsprint supports global AO equally well as direct AO,
  so all that we say about AO matters for both direct and global AO.

 \section da3 Directional ambient occlusion

  Information about direction of incoming light can be precomputed and used
  in the same way as in case of classical lightmaps.
  See \ref di1 for more details.

 \section da3 Data structures

  Lightsprint can store object's ambient occlusion and global ambient occlusion in

  - <b> \ref data_vertex_buffer </b>

  - <b> \ref data_pixel_buffer </b>

 \section da4 Calculation

  Calculation of ambient occlusion is non-realtime process.
  To calculate ambient occlusion,
  - Create RRDynamicSolver
  - Set geometry with RRDynamicSolver::setStaticObjects().
    Set single object here for single object ambient occlusion.
    If you set scene with multiple objects here, each object will be
    occluded by all other objects.
  - Set uniform white environment with RRDynamicSolver::setEnvironment(RRBuffer::createSky())
  - Call RRDynamicSolver::updateLightmaps() with
    \n paramsDirect.applyCurrentSolution=false
    \n paramsDirect.applyLights=false
    \n paramsDirect.applyEnvironment=true
    \n and paramsIndirect=NULL
    \n To calculate global ambient occlusion,
       set paramsIndirect equally to paramsDirect.

  See data structures (links above) for more details on calculation.

 \section da5 Use in renderer

   See data structures (links above) for more details on use in renderer.



\page data_bent_normals Bent normals

 \section db1 Bent normals

  Bent normals on <a href="http://en.wikipedia.org/wiki/Ambient_occlusion">Wikipedia</a>

  Bent normals store negation of incoming light direction,
  in world space.
  Light may come to surface point form many directions
  in different intensities, so bent normals average all directions,
  taking light intensity into account.
  \n
  Bent normals are normalized.

 \section db2 Data structures

  Lightsprint can store object's bent normals in

  - <b> \ref data_vertex_buffer </b>

  - <b> \ref data_pixel_buffer </b>

  Bent normals stored in pixel buffer
  are automatically transformed from -1..1 space to 0..1 space to support
  save to unsigned RGB textures.
  When reading bent normal from such texture,
  get original world space normal as bn*2-1.

 \section db3 Calculation

  Calculation of bent normals is non-realtime process.
  To calculate bent normals, use RRDynamicSolver::updateLightmaps()
  and set bent normal layer accordingly.

  Bent normals are intentionally stored in different layer than ilumination,
  so you can reuse single bent normal layer with multiple illumination layers
  to save memory or storage space (at cost of slightly reduced precision).

  See data structures (links above) for more details on calculation.

 \section db4 Use in renderer

  Bent normals are optional enhancement of precomputed illumination.
  They are used in rendering to make specular
  reflections and normal maps look more realistically,
  even with lighting precomputed in lightmaps.

  See data structures (links above) for more details on rendering.



\page data_vertex_buffer Vertex buffer

 Vertex buffer is designed for storage of per-vertex data for single object.

 \section d11 Suitable for
   <table>
    <tr><th></th>                                 <th>global or direct or indirect illumination</th> <th>ambient occlusion</th> <th>bent normals</th> </tr>
    <tr><th>static objects</th>                   <td>YES</td> <td>YES</td> <td>YES</td> </tr>
    <tr><th>dynamic objects</th>                  <td>NO </td> <td>YES</td> <td>YES</td> </tr>
    <tr><th>realtime calculated illumination</th> <td>YES</td> <td>NO </td> <td>NO </td> </tr>
    <tr><th>precalculated illumination</th>       <td>YES</td> <td>YES</td> <td>YES</td> </tr>
   </table>

 \section d12 Advantages
   - Compact representation. It requires only few bytes per vertex.
     Samples store illumination as 3 floats, but it can be switched to 4 bytes,
     arbitrary compression can be added.
   - Fast rendering.
     No sampler resources are consumed.
     It can be arbitrarily postprocessed in vertex shader.
     You can have multiple layers of precalculated indirect illumination 
     and mix them at no cost in vertex shader according to changes in scene.
   - There is no need to change your lightning equation,
     simply use our ambient data instead of constant ambient.
   - If you don't precompute bent normals, ambient lighting values
     don't depend on view angle, so rendering is very fast.
   - If you do precompute bent normals, normal maps work great even in shadows,
     knowing direction of incoming indirect light.

 \section d13 Disadvantages
   - Details are missing in areas without vertices.
     For good results, you have to add vertices to places where you miss details.
   - Seams around T vertices and other degenerated geometries.
     You have to make your meshes clean, avoid degeneracies.
   - Long narrow triangles (needles) often create visible artifacts.
     This is often problem also for physical engine,
     so your 3d artisis probably know they should avoid needles.

 \section d15 Interface
   - RRBuffer

 \section d14 Instances
   - stored in: RRDynamicSolver::getIllumination()->getLayer()
   - created by: you
   - updated by: RRDynamicSolver::updateLightmaps()
     or RRDynamicSolver::updateLightmap().

 \section d16 Rendering with
   - Stream data from vertex buffer into vertex shader, interpret them
     in shader appropriately as light level, ambient occlusion or bent normal.

 \section d17 Examples
   - Generic example:
     \n Creating vertex buffer.
     \code
	vertexBuffer = rr::RRBuffer::create(rr::BT_VERTEX_BUFFER,numVertices,1,1,rr::BF_RGBF,NULL);
     \endcode
   - OpenGL example:
     \n Rendering with per vertex ambient.
     \code
	rr::RRDynamicSolver* dynamicSolver;
	GLuint program;
	...
	// set program created from shaders below
	glUseProgram(program);
	// get vertex buffer with indirect illumination
	rr::RRBuffer* vertexBuffer = dynamicSolver->
		getIllumination(numberOfObject)->getLayer(0);
	// enable stream with color values
	glEnableClientState(GL_COLOR_ARRAY);
	// set pointer to color data for first vertex
	glColorPointer(3, GL_FLOAT, 0, vertexBuffer->lock(rr::BL_READ));
	// render primitives
	glDrawElements...
	// cleanup
	vertexBuffer->unlock();
	glDisableClientState(GL_COLOR_ARRAY);
     \endcode
     Using ambient value in GLSL vertex shader:
     \code
	varying vec3 ambientLight;
	void vertexShader()
	{
		...
		ambientLight = gl_Color;
	}
     \endcode
     Using ambient value in GLSL fragment shader:
     \code
	varying vec3 ambientLight;
	void fragmentShader()
	{
		...
		gl_FragColor = ... + materialColor * vec4(ambientLight.xyz,0.0);
	}
     \endcode
   - Direct3D 9 example:
     \n Rendering with per vertex ambient.
     \code
	IDirect3DDevice9* device;
	IDirect3DPixelShader9* vertexShader;
	IDirect3DPixelShader9* pixelShader;
	// adapt your vertex declaration, let your mesh read data from stream 0
	// and add e.g. COLOR1 read from stream 1
	IDirect3DVertexDeclaration9* vertexDeclaration;
	device->CreateVertexDeclaration(description, &vertexDeclaration);
	...
	// create d3d vertex buffer and fill it with vertexBuffer->lock() data
	rr::RRBuffer* vertexBuffer = dynamicSolver->
		getIllumination(numberOfObject)->getLayer(0);
	IDirect3DVertexBuffer9* d3dBuffer = ...;
	// to prevent data duplication and copying, implement RRBuffer
	//  that stores vertex data directly into d3d vertex buffer
	...
	// set rendering pipeline to use shaders below
	device->SetPixelShader(vertexShader);
	device->SetPixelShader(pixelShader);
	// activate previously created vertex declaration
	device->SetVertexDeclaration(vertexDeclaration);
	// set pointer to your mesh (vertices, possibly normals etc.) in stream 0
	device->SetStreamSource(0, ...);
	// set pointer to vertex illumination data in stream 1
	device->SetStreamSource(1, d3dBuffer, ...);
	// render primitives
	device->DrawPrimitive...
	// cleanup
	device->SetStreamSource(1, NULL, 0, 0);
	device->SetStreamSource(0, NULL, 0, 0);
     \endcode
     Using ambient value in HLSL vertex shader:
     \code
	void vertexShader(in float3 iAmbientLight: COLOR1,
		..., out float3 oAmbientLight: COLOR1)
	{
		...
		oAmbientLight = iAmbientLight;
	}
     \endcode
     Using ambient value in HLSL pixel shader:
     \code
	void pixelShader(in float3 iAmbientLight: COLOR1,
		..., out float4 oColor: COLOR)
	{
		...
		oColor = ... + materialColor * float4(iAmbientLight,0);
	}
     \endcode
   - Alternatively, applying colors from vertex buffer could be done in fixed pipeline,
     without shaders, but it is beyond scope of this documentation.
   - See Direct3D, OpenGL or your engine documentation for more details
     on streaming per vertex data to vertex shader and rendering with ambient light,
     ambient occlusion or bent normals.



\page data_pixel_buffer Pixel buffer

 Pixel buffer (2d texture) is designed for storage of per-pixel data 
 for single object (Light map, Ambient occlusion map, Bent normal map).

 \section d21 Suitable for
   <table>
    <tr><th></th>                                 <th>global or direct or indirect illumination</th> <th>ambient occlusion</th> <th>bent normals</th> </tr>
    <tr><th>static objects</th>                   <td>YES</td> <td>YES</td> <td>YES</td> </tr>
    <tr><th>dynamic objects</th>                  <td>NO </td> <td>YES</td> <td>YES</td> </tr>
    <tr><th>realtime calculated illumination</th> <td>NO </td> <td>NO </td> <td>NO </td> </tr>
    <tr><th>precalculated illumination</th>       <td>YES</td> <td>YES</td> <td>YES</td> </tr>
   </table>

 \section d22 Advantages
   - High precision and detail without additional vertices.
   - No need for good triangulation.
   - Very low resolution is sufficient (with good unwrap) for ambient maps
     (lightmaps with indirect illumination).
     Ambient maps contain mostly low frequencies, no sharp edges.
   - If you don't precompute bent normals, ambient lighting values
     don't depend on view angle, so rendering is very fast.
   - If you do precompute bent normals, normal maps work great even in shadows,
     knowing direction of incoming indirect light.

 \section d23 Disadvantages
   - You need additional uv channel with object's unwrap (for lightmap mapping).
     If you don't have it, ask your 3d artists
     to bake unwrap into meshes as an additional uv channel.
     Unwraps are often genrated automatically, using existing free or commercial tools.

 \section d25 Interface, implementations
   - RRBuffer

 \section d24 Instances
   - stored in: RRDynamicSolver::getIllumination()->getLayer()
     or your arbitrary location.
   - created by: you
   - updated by: RRDynamicSolver::updateLightmaps()
     or RRDynamicSolver::updateLightmap().

 \section d26 Rendering
   - Map pixel buffer to your object using your uv channel with object's unwrap,
     read per-pixel value from texture in pixel shader
     and interpret it appropriately as light level, ambient occlusion or bent normal.

 \section d27 Examples
   - Generic example:
     \n Providing access to unwrap in your implementation of rr::RRMesh interface.
     \code
	// access to uv channel with object's unwrap
	void YourImplementationOfRRMesh::getTriangleMapping(
		unsigned t, TriangleMapping& out) const
	{
		for(unsigned v=0;v<2;v++)
		{
			// copy uv baked with your mesh
			// for vertex v (v=0..2) in triangle t
			out.uv[v][0] = ...; // u coordinate
			out.uv[v][1] = ...; // v coordinate
		}
	}
     \endcode
     \n Creating lightmap.
     \code
	lightmap = rr::RRBuffer::create(rr::BT_2D_TEXTURE,256,256,1,rr::BF_RGBF,NULL);
     \endcode
   - OpenGL example:
     Rendering with lightmap.
     \code
	rr::RRDynamicSolver* dynamicSolver;
	GLuint program;
	...
	// set program created from shaders below
	glUseProgram(program);
	// bind lightmap to texture0
	glActiveTexture(GL_TEXTURE0);
	getTexture(dynamicSolver->getIllumination(numberOfObject)->
		getLayer(0))->bindTexture();
	// set sampler to use texture0
	glUniform1i(glGetUniformLocation(program,"lightmap"),0);
	// enable stream with texture coordinates
	glEnableClientState(GL_TEXTURE_COORD_ARRAY);
	// set pointer to texture coordinates
	glColorPointer(2, GL_FLOAT, 0, array with uv values of unwrap);
	// render primitives
	glDrawElements...
	// cleanup
	glDisableClientState(GL_TEXTURE_COORD_ARRAY);
     \endcode
     Using uv coordinates in GLSL vertex shader:
     \code
	varying vec2 lightmapCoord;
	void vertexShader()
	{
		...
		lightmapCoord = gl_TexCoord.xy;
	}
     \endcode
     Sampling and using illumination value in GLSL fragment shader:
     \code
	uniform sampler2D lightmap;
	varying vec2 lightmapCoord;
	void fragmentShader()
	{
		vec4 light = texture2D(lightmap, lightmapCoord);
		...
		gl_FragColor = ... + materialColor * light;
	}
     \endcode
   - Direct3D 9 example:
     Rendering with lightmap.
     \code
	IDirect3DDevice9* device;
	IDirect3DPixelShader9* vertexShader;
	IDirect3DPixelShader9* pixelShader;
	// create vertex declaration that includes lightmap uv channel as TEXCOORD0
	IDirect3DVertexDeclaration9* vertexDeclaration;
	device->CreateVertexDeclaration(description, &vertexDeclaration);
	rr::RRDynamicSolver* dynamicSolver;
	...
	// set rendering pipeline to use shaders below
	device->SetPixelShader(vertexShader);
	device->SetPixelShader(pixelShader);
	// set sampler to use lightmap
	rr::RRBuffer* lightmap = dynamicSolver->
		getIllumination(numberOfObject)->getLayer(0);
	...
	// set vertex declaration for your mesh data,
	//  including uv channel with unwrap
	device->SetVertexDeclaration(vertexDeclaration);
	// set pointer to your mesh in stream 0
	//  (vertices, uv channel, possibly normals etc.)
	device->SetStreamSource(0, ...);
	// render primitives
	device->DrawPrimitive...
	// cleanup
	device->SetStreamSource(0, NULL, 0, 0);
     \endcode
     Using uv coordinates in HLSL vertex shader:
     \code
	void vertexShader(in float2 iLightmapCoord: TEXCOORD0,
		..., out float2 oLightmapCoord: TEXCOORD0)
	{
		...
		oLightmapCoord = iLightmapCoord;
	}
     \endcode
     Sampling and using illumination value in HLSL pixel shader:
     \code
	sampler lightmap;
	void pixelShader(in float2 iLightmapCoord: TEXCOORD0,
		..., out float4 oColor: COLOR)
	{
		float4 light = tex2D(lightmap, iLightmapCoord);
		...
		oColor = ... + materialColor * light;
	}
     \endcode
   - Alternatively, texturing could be done in fixed pipeline,
     without shaders, but it is beyond scope of this documentation.
   - See Direct3D, OpenGL or your engine documentation for more details
     on texturing and rendering with lightmap.
  


\page data_environment_map Environment map

 Environment map (cube texture) is designed for global illumination of single object.

 \section d31 Suitable for
   - static objects: YES
   - dynamic objects: YES
   - realtime calculated illumination: YES
   - precalculated illumination: YES

 \section d32 Advantages
   - offers global illumination with both specular and diffuse reflections
   - object doesn't have to be part of static scene, no RRObject adapter is required
   - calculation is independent to object complexity, quick even for extremely complex objects

 \section d33 Disadvantages
   - precision decreases with size of object, suitable for characters and items, not for buildings
   - complexity of objects doesn't matter, but count of environment map updates does,
     so if you need large clouds/crowds of dynamic objects visible all at once,
     share one environment map for several close objects and update it only once
     to save time

 \section d35 Interface, implementations
   - RRBuffer

 \section d34 Instances
   - stored in: RRObjectIllumination::diffuseEnvMap and RRObjectIllumination::specularEnvMap or your arbitrary location
   - created by: you
   - updated by: RRDynamicSolver::updateEnvironmentMap()

 \section d36 Rendering
   - Many rendering techniques are based on faked precomputed environment maps.
     Here you get realtime computed environment maps, and you are free to use them
     for any purpose.
   - Request environment (cube) map to be generated in center of your object.
     Environment map may be later used by GPU to add global illumination 
     to diffuse and specular surfaces close to given point in space.
   - We propose you several techniques:
     \n
     For rough surface with mostly <b>diffuse</b> reflection,
     read value from diffuse environment map, using 'surface normal' as a coordinate.
     This single instruction gives you global illumination of pixel.
     Multiply it by material diffuse color to get final color.
     Size 4 of environment map is sufficient for close objects and 2 for distant ones.
     \n
     For smooth surface with <b>specular</b> reflection,
     read value from specular environment map, using
     'eye direction reflected by surface' as a coordinate.
     These few instructions give you global illumination of pixel.
     Don't modulate it by material color unless you want to render
     exotic materials, you already have final color.
     Size 16 of environment map simulates smooth surfaces, size 4 simulates rough
     surface.
     \n
     You can use <b>specular map</b> to select per pixel which one
     of two techniques to use or how to mix both together.
     \n
     You can use <b>normal map</b> to modulate surface normal.
     Both diffuse and specular surfaces respond well to normal maps.
     \n
     LightsprintGL implements all of these techniques.
   - Global illumination can be further improved if you use <b>ambient occlusion map</b>
     for your dynamic object. Multiply global illumination read from environment map
     by ambient occlusion read from ambient occlusion map to get more precise result.
     Ambient occlusion maps are computed for example by BuildLightmaps sample.

 \section d37 Examples
   - OpenGL example:
     \n Rendering with environment maps.
     \code
	rr::RRDynamicSolver* solver;
	rr::RRObjectIllumination* illumination;
	GLuint program;
	...
	// update environment maps
	solver->updateEnvironmentMap(illumination);
	// set program created from shader below
	glUseProgram(program);
	// bind diffuse environment map to texture0
	// it calls glBindTexture(GL_TEXTURE_2D,map);
	glActiveTexture(GL_TEXTURE0);
	rr_gl::getTexture(illumination->diffuseEnvMap)->bindTexture();
	// set sampler to use texture0
	glUniform1i(glGetUniformLocation(program,"diffuseEnvironmentMap"),0);
	// bind specular environment map to texture1
	glActiveTexture(GL_TEXTURE1);
	rr_gl::getTexture(illumination->specularEnvMap)->bindTexture();
	// set sampler to use texture1
	glUniform1i(glGetUniformLocation(program,"specularEnvironmentMap"),1);
	// render primitives
	glDrawElements...
     \endcode
     Applying environment maps in GLSL fragment shader:
     \code
	uniform samplerCube specularEnvironmentMap;
	uniform samplerCube diffuseEnvironmentMap;
	void fragmentShader()
	{
		// normal in world space, you may apply normal map here
		vec3 worldNormal = ...;
		// view vector in world space = position of fragment - position of camera
		vec3 worldView = ...;
		// reflected view vector in world space
		vec3 worldViewReflected = reflect(worldView,worldNormal);
		...
		gl_FragColor = ...
			// diffuse reflection
			+ materialDiffuseReflectance *
			  textureCube(diffuseEnvironmentMap, worldNormal)
			// specular reflection
			+ materialSpecularReflectance *
			  textureCube(specularEnvironmentMap, worldViewReflected);
	}
     \endcode
   - Direct3D 9 example:
     \n Rendering with environment maps.
     \code
	IDirect3DDevice9* device;
	IDirect3DPixelShader9* pixelShader;
	rr::RRDynamicSolver* solver;
	rr::RRObjectIllumination* illumination;
	...
	// update environment maps
	solver->updateEnvironmentMap(illumination);
	// set rendering pipeline to use shader below
	device->SetPixelShader(pixelShader);
	// set samplers to use environment maps
	...
	// render primitives
	device->DrawPrimitive...
     \endcode
     Applying environment maps in HLSL pixel shader:
     \code
	samplerCUBE specularEnvironmentMap;
	samplerCUBE diffuseEnvironmentMap;
	void pixelShader(..., out float4 oColor: COLOR)
	{
		// normal in world space, you may apply normal map here
		float3 worldNormal = ...;
		// view vector in world space = position of fragment - position of camera
		float3 worldView = ...;
		// reflected view vector in world space
		float3 worldViewReflected = reflect(worldView,worldNormal);
		...
		oColor = ...
			// diffuse reflection
			+ materialDiffuseReflectance *
			  texCUBE(diffuseEnvironmentMap, worldNormal)
			// specular reflection
			+ materialSpecularReflectance *
			  texCUBE(specularEnvironmentMap, worldViewReflected);
	}
     \endcode
   - See Direct3D, OpenGL or your engine documentation for more details
     on texturemapping and applying environment maps.




\page data_triangle Triangle or Vertex

 Triangle or Vertex illumination query is designed for AI
 and other subsystems that need very fast access to single value
 (e.g. AI trying to find dark corner for hiding).

 \section d41 Suitable for
   - static objects: YES
   - dynamic objects: NO
   - realtime calculated illumination: YES
   - precalculated illumination: YES

 \section d42 Advantages
   - If you need information only for small subset of scene,
     querying single triangle is much faster
     than generating complete lightmap or vertex color buffer for whole object
     and reading value from it.
   - Even if you have lightmap or vertex buffer generated,
     it could be easier to use this query than searching
     individual value in vertex buffer/lightmap.

 \section d43 Disadvantages
   - Not demonstrated in samples yet.

 \section d44 Query
   - Call RRDynamicSolver::getTriangleMeasure with vertex=0,1,2 for triangle vertices
   - Call RRDynamicSolver::getTriangleMeasure with vertex>2 for whole triangle area
   - Reading illumination level from triangle is slightly faster than reading
     it from vertex, but both are very fast.

 \section d45 Returned value
   - RRVec3 with single illumination value
   - see \ref gunits




\page data_ray Ray

 Query for illumination at the end of ray is designed for AI
 and other subsystems that need very fast access to single value
 (e.g. AI trying to find dark corner for hiding).

 \section d51 Suitable for
   - static objects: YES
   - dynamic objects: NO
   - realtime calculated illumination: YES
   - precalculated illumination: YES

 \section d52 Advantages
   - Fast access to single value.

 \section d53 Disadvantages
   - Not demonstrated in samples yet.

 \section d54 Query
   - Call RRDynamicSolver::getMultiObjectCustom()->getCollider()->intersect()
     to find static triangle at the end of ray.
   - See \ref data_triangle for access to triangle's illumination.

 \section d55 Returned value
   - RRVec3 with single illumination value
   - see \ref gunits




\page calc_fireball Fireball

 \section fb_features Features
  Fireball is realtime global illumination solver, it produces realistic indirect lighting in dynamic scenes,
  taking all \ref inputs_light_sources into account.
  It is recommended for use in games.

  If you don't start Fireball,
  \ref calc_realtime works without any precalculations (and \ref calc_offline work too).
  \n If you start Fireball, only realtime lighting works, but it is 
  - faster (1.2-5x higher fps in standard situations)
  - smaller (needs only 50% of memory for the same quality)
  - produces higher quality lighting
  - doesn't allocate/fragment memory
  - doesn't change performance over time
  - calculates realtime GI also from environment/skybox
  - calculates realtime GI also from dynamically changing emissive maps

 \section fb_precalc Precalculations
  Fireball uses precalculation phase in which static scene is analyzed and one file is saved.
  This is usually done by developer at development time, final game only loads the file.

 \section fb_calculation Calculation
  Fireball uses the same API as the rest of Lightsprint SDK.
  Usually no changes in code are needed to start using Fireball,
  except for one additional call, see:
  - RRDynamicSolver::buildFireball()
  - RRDynamicSolver::loadFireball()

  In case you change emissive maps dynamically (e.g. stream video into emissive map), call
  - RRDynamicSolver::setEmittance()

 \section fb_outputs Outputs
  Fireball calculates indirect illumination and stores it into 
  \ref data_vertex_buffer for static objects and
  \ref data_environment_map for dynamic objects.

 \section fb_sample Sample
  RealtimeRadiosity, RealtimeLights and SceneViewer samples build and use Fireball automatically.
  SceneViewer is good for performance/quality testing as it's possible to manipulate lights,
  skybox, change fireball quality etc. RealtimeRadiosity and RealtimeLights are simpler,
  but open for tweaking/customization, they have everything important in source code form.



\page calc_realtime Realtime lighting

 \section rt_features Features
  Lightsprint uses the same API for both realtime and \ref calc_offline.
  Naturally only subset of functions is fast enough to be used in realtime.
  \n Features designed for realtime use include:
  - calculate global illumination in dynamic scenes
    - freely manipulate objects
    - freely manipulate lights
    - freely manipulate environment/skybox (GI updated in realtime only with \ref calc_fireball)
  - update \ref data_vertex_buffer with indirect lighting for static objects
  - update \ref data_environment_map with indirect lighting for dynamic objects

 \section rt_precalc Optional precalculations
  Realtime rendering with global illumination is available immediately after
  new scene is loaded, no preprocessing/precalculations are needed.

  However, better results are possible with \ref calc_fireball.
  It uses precalculation phase in which static scene is analyzed.
  It takes some time, but then rendering is faster and quality higher.

 \section rt_sample Sample
  Realtime lighting is demonstrated in RealtimeRadiosity and RealtimeLights samples.
  You can comment out line that enables \ref calc_fireball to compare both realtime solvers.
  SceneViewer sample supports both solvers without any source changes, you can switch them in menu.


 
\page calc_offline Offline calculations

 \section of_features Features
  All Lightsprint SDK features documented in \ref main_data_access are available
  for offline calculations.

  Note that some offline featues are disabled if you load \ref calc_fireball for realtime lighting.

 \section of_speed Speed
  Estimate of time to build all lightmaps in scene (using RRDynamicSolver::updateLightmaps()) is

  <code>
  log( number of triangles in scene )
  <br> * ( quality + number of lights in scene + 10 )
  <br> * ( number of mapped pixels in per-pixel lightmaps + number of vertices in per-vertex lightmaps )
  </code>

  Building multiple layers of information at once (e.g. directional lightmaps and bent normals) has negligible overhead,
  count pixels in one layer only.

  Looking at formula, it's clear that quality is major performance factor, number of lights has only minor impact (it's usually much lower).
  If you can split scene in two parts and build them separately (light won't travel from one part to another),
  time complexity won't change much, but problem will be better parallelized, you will be able to build the parts on different computers.

  Note that this is only estimate, faster or slower paths are used in specific cases, depending on scene data.

 \section of_sample Samples
  Offline calculations are demonstrated in CPULightmaps and BuildLightmaps samples.
  CPULightmaps is purely console application,
  BuildLightmaps displays results in simple interactive viewer.



\page main_platforms Supported platforms

 Platforms
 - Windows (XP, Vista, 32bit, 64bit)
 - Linux (32bit, 64bit)
 - Playstation 3
 - Xbox 360
 - virtually any platform (static GI)

 GPUs on PC
 - NVIDIA GeForce 5xxx, 6xxx, 7xxx, 8xxx, 9xxx, 2xx
 - AMD (ATI) Radeon 9500-9800, Xxxx, X1xxx, HD2xxx, HD3xxx, HD4xxx
 - mobile versions of GPUs above (GeForce Go, Mobility Radeon)
 - subset of workstation versions (Quadro, FireGL)
 - for offline rendering, GPU is not needed

 3D APIs
 - OpenGL 2/3 (examples included)
 - Direct3D 9/10 (no examples yet)
 - for offline rendering, 3D API is not needed

 Compilers
 - Visual C++ 2008 with all security updates (32bit, 64bit)
 - Visual C++ 2005 SP1 with all security updates (32bit, 64bit)
 - Visual C++ 2003 SP1 with all security updates
 - gcc (32bit, 64bit)

 Library configurations
 - Release DLL/so
 - Debug DLL/so
 - Release static (source code license only)
 - Debug static (source code license only)





\page main_inputs Inputs

 Lightsprint supports three major types of inputs:

 \section inputs_files Files in standard formats (Collada, Gamebryo etc)
  - see list of file formats supported by \ref api_io

 \section inputs_3p_structures Third party data structures in memory (Unreal Engine 3, Gamebryo, FCollada etc)
  - \ref api_io source code consists of 3rd party loaders and our adapters, that adapt 3rd party data structures into Lightsprint data structures, without duplicating data
  - instead of linking whole \ref api_io, your project may directly use adapter source code <code>src/LightsprintIO/ImportXxx/RRObjectXxx.cpp+h</code>
  - Unreal Engine 3 structures in memory are adapted using <code>src/LightsprintUE3/RRObjectUE3.cpp+h</code> (see also \ref main_ue3 "UE3 intro")

 \section inputs_structures Lightsprint data structures in memory
  - \subpage inputs_light_sources
  - \subpage inputs_geometry
  - \subpage inputs_materials


\page inputs_light_sources Light sources

 Lightsprint supports multiple types of light sources.

 All light sources support
 - HDR, floating point intensities (inputs, outputs)
 - direct, indirect or global illumination with infinite light bounces (outputs)
 - directional information (output)

 \section llights RRLights
  - Point/spot/directional light source.
  - Data structure: RRLight
  - Data structure container: RRLights
  - Setup: RRDynamicSolver::setLights()
  - Supported in offline GI: yes
  - Supported in realtime GI: yes

  - Point, spot and directional lights are implemented in RRLight.
    You can create new type, see RRLight interface.
    However, light must be emited by single point; to simulate area light,
    use e.g. triangles with emissive material.

  <table border=0><tr align=top><td>
  \image html features/light-spot.jpg realtime GI from spot light
  </td><td>
  \image html features/light-point.jpg point light
  </td><td>
  \image html features/light-dir.jpg directional light
  </td></tr></table>

 \section lenv Environment / Sky
  - Area light source, emissive skybox or sphere surrounding whole scene.
  - Data structure: RRBuffer
  - Data structure container: none, only one environment in scene
  - Setup: RRDynamicSolver::setEnvironment()
  - Supported in offline GI: yes
  - Supported in realtime GI: yes (only in Fireball)

  <table border=0><tr align=top><td>
  \image html features/environment1.jpg realtime GI from environment
  </td><td>
  \image html features/environment2.jpg simply change texture
  </td></tr></table>

 \section lemissive Emissive materials
  - Area light source, triangles covered by materials that emit light.
  - Data structure: RRObject with emissive materials
  - Data structure container: RRObjects
  - Setup: RRDynamicSolver::setStaticObjects(), RRDynamicSolver::setEmittance()
  - Supported in offline GI: yes
  - Supported in realtime GI: yes

  <table border=0><tr align=top><td>
  \image html features/emis1.jpg realtime GI from emissive surfaces
  </td><td>
  \image html features/emis2.jpg simply change texture
  </td></tr></table>

 \section lrealtime Custom lights
  - Per-triangle direct irradiances set by RRDynamicSolver::setDirectIllumination()
  - Supported in offline GI: yes
  - Supported in realtime GI: yes


\page inputs_geometry Geometry

 \section ig_rrobjects RRObjects
  - RRObjects is a set of objects (RRObject)

 \section ig_rrobject RRObject
  - RRObject is a collider (RRCollider) with transformation matrix and materials

 \section ig_rrcollider RRCollider
  - RRCollider is a mesh (RRMesh) with an acceleration structure for ray-mesh intersections

 \section ig_rrmesh RRMesh
  - RRMesh is a set of triangles, vertices, normals, tangents, bitangents, texcoords


\page inputs_materials Materials

 \section im_rrmaterial RRMaterial
  - RRMaterial specifies material properties - diffuse, specular, emissive, opacity, refraction
  - information is represented by colors and optional textures
  - RRObject::getTriangleMaterial() returns average material properties of one triangle
  - RRObject::getPointMaterial() returns material properties of single point on object's surface
 



\page main_ue3 Unreal Engine 3

 Lightsprint SDK integrated with UnrealEd transparently makes
 "Lighting build" produce global illumination lightmaps.

 If you are UE3 licensee, please request integration files from Lightsprint.
 Then see src/LightsprintUE3/instructions.txt and follow several simple steps.

 \image html unreal.png   

 \ref trouble_memory "How to process even bigger scenes"



\page main_gamebryo26 Gamebryo 2.6

 Lightsprint SDK adds global illumination to Gamebryo 2.6.

 \section g26_prerequisites Prerequisites
  - Emergent's <code>Gamebryo 2.6</code> must be installed
  - Emergent's <code>Gamebryo Global Illumination Package 1.0.0</code> must be installed
  - Lightsprint SDK with Gamebryo 2.6 integration.
    To save your time, we send you Lightsprint SDK preconfigured for your engine.
    If we make mistake and your integration is missing, please let us know.

 \section g26_f Features
  - all Lightsprint samples (lightmap building, realtime radiosity etc) support Gamebryo .gsa scenes
  - lightmap building honours all Gamebryo 2.6 conventions, outputs are ready for immediate use in Gamebryo 2.6 games
  - full integration source code included

 \section g26_gs Getting started
  <table border=0><tr><td>
  - see off-line lightmap building
    - enter <code>samples/BuildLightmaps</code>
    - run <code>Gamebryo2.6_Build_Tutorial.bat</code> to build GI lightmaps for Gamebryo tutorial scene
    - run <code>Gamebryo2.6_SceneApp_Tutorial.bat</code> to view GI in Gamebryo SceneApp sample application
  </td><td>
  \image html BuildLightmaps_2.jpg
  </td></tr><tr><td>
  - see realtime global illumination
    - enter <code>samples/BuildLightmaps</code>
    - run <code>Gamebryo2.6_Realtime_Tutorial.bat</code>
    - move mouse with right button pressed to look
    - left click to switch to light
    - arrows or wsadqzxc to move camera or light
    - select from menu: Lights / Show properties
    - change light type from point to spot for stronger color bleeding effect
    - select from menu: Global illumination / Build light detail map / 1000 / 128x128, takes a minute, increases realtime GI quality
  </td><td>
  \image html Gamebryo-RT2.jpg
  </td></tr><tr><td>
  - see source code
    - open src/Lightsprint.vs2005.sln or src/Lightsprint.vs2008.sln
    - see for example lightmap building source code in BuildLightmaps project,
      feel free to customize it to match your needs

  - see \ref main_samples "other samples"

  - see Gamebryo Global Illumination Package 1.0.0 documentation for data flow examples and tutorial
  </td><td>
  \image html Gamebryo-RT1.jpg
  </td></tr></table>

 \section g30_misc Misc
  - \ref trouble_memory "How to process even bigger scenes"


\page main_gamebryo30 Lightspeed

 Lightsprint SDK adds global illumination to Lightspeed (Gamebryo 3.0).

 \section g30_prerequisites Prerequisites
  - Emergent's <code>Lightspeed (Gamebryo 3.0)</code> must be installed
  - Emergent's <code>Lightspeed Global Illumination Package <b>2.0.2 (!)</b></code> must be installed
    with "Patch Gamebryo LightSpeed 3.0" checked (it's checked by default)
  - Lightsprint SDK with Lightspeed integration.
    To save your time, we send you Lightsprint SDK preconfigured for your engine.
    If we make mistake and your integration is missing, please let us know.

 \section g30_f Features
  - lightmap baking integrated into Toolbench (lightmaps, directional lightmaps/RNM, per-vertex bake, HDR or LDR environment texture...)
  - all Lightsprint samples (lightmap building, realtime radiosity etc) support Gamebryo .gsa scenes (old Gamebryo format)
  - full integration source code included

 \section g30_limits Limitations of current version
  - terrain not supported (this is also GI Package 2.0.2 limitation)

 \section g30_bake Baking in Toolbench
    - Run <code>bin/install_toolbench_plugins.bat</code>.
    - Run Toolbench (default configuration VC90/Shipping).

   \subsection g30_sample - preconfigured examples
    - Open sample scene in Lightsprint SDK <code>data\\Lightspeed\\GameFrameworkSample.gsl</code>
    - Open WorldBuilder by doubleclicking .block file in game solution, pick Cathedral for bigger or CornellBox for smaller scene.
    - GI is already present. You can rebuild it by clicking menu Lightsprint / Bake lighting.
      \n Small window shows baking progress and lets you abort operation.
      \n Baking at default medium quality takes around 10s for CornellBox, 2min for Cathedral.
      \n Computed GI appears in WorldBuilder and it is also saved to disk immediately.
      <table border=0><tr><td>
      \image html Toolbench-Cornell.jpg
      </td><td>
      \image html Toolbench-Cathedral.jpg
      </td></tr></table border=0>
    - Click any LightsprintScene or LightsprintMesh entity to access bake settings, see below.
      If you change settings, bake again to see lightmaps change.

   \subsection g30_library - using Lightsprint Model Library
    - Using LightsprintScene and LightsprintMesh models instead of GIScene and PCLMesh
      will give you access to important bake settings.
      <table border=0><tr><td>
      \image html Toolbench-LightsprintScene.png
      </td><td>
      \image html Toolbench-LightsprintMesh.png
      </td></tr></table border=0>
    - LightsprintModelLibrary and GIModelLibrary must be copied to and then referenced from your solution. 
      It is already done in our samples.
      Game Solution Wizard offers to do it automatically for new projects.
      For old projects, manually copy <code>\$(EMERGENT_PATH)\\Media\\GIModelLibrary</code> and
      <code>%EMERGENT_PATH%\\sdk\\Win32\\Bin\\VC90\\Shipping\\Plugins\\Lightsprint.Toolbench.Plugin\\LightsprintModelLibrary</code>
      directories next to <code>StandardModelLibrary</code> in your asset web,
      then open your solution in Toolbench, doubleclick .block file in Game Solution panel, expand it,
      right click References under .block file, select Add Reference,
      enter <code>LightsprintModelLibrary</code> directory and select <code>LightsprintModelLibrary.emtproj</code>.
      Add reference to GIModelLibrary in the same way.

   \subsection g30_other_solutions - configuring your scenes
    - If your scene alredy contains GIScene entity, transmogrify it to LightsprintScene, otherwise create new LightsprintScene.
    - If some of your meshes need non-default settings, transmogrify them to LightsprintMesh-es.
    - Adjust settings in LightsprintScene and LightsprintMesh entities. Note that default quality is low, per-vertex.
    - Run Lightsprint / Bake lighting as usual.

   \subsection g30_mix - mixing realtime and precomputed illumination
    - Lightspeed supports rendering realtime direct and precomputed indirect illumination.
    - To bake indirect illumination only,
      set light properties UseForPrecomputedLighting, LightPCLObjectsAtRuntime and LightNonPCLObjectsAtRuntime to true.

 \section g30_gsa Legacy .gsa support
    - our tools from \ref main_gamebryo26 "Gamebryo 2.6 integration" still work under Lightspeed
    - this includes both offline and realtime GI
    - note that our legacy samples read scenes from Gamebryo 2.6 and GI Package 1.0.0 directories,
      those must be installed for samples to work
      <table border=0><tr><td>
      \image html BuildLightmaps_2.jpg
      </td><td>
      \image html Gamebryo-RT2.jpg
      </td></tr></table border=0>

 \section g30_source Source code
    - open <code>src/Lightsprint.vs2008.sln</code>
    - see <code>Lightsprint.Toolbench.Plugin</code> and <code>Lightsprint.Toolbench.Plugin.UI</code> projects,
      feel free to customize them or tell us what needs to be changed to match your needs
    - for standard VC90/Shipping Toolbench, build plugins in Shipping DLL Win32 configuration
    - if you build Debug DLL or Release DLL Win32 plugins, use them by running VC90 Debug / Release Toolbench
    - Gamebryo does not support 64bit code, so x64 configurations have plugin build disabled
    - let us know if you need projects for different compiler version

 \section g30_doc Documentation
    - see also <code>Lightspeed Global Illumination Package</code> documentation

 \section g30_depl Deployment
  - <code>bin/install_toolbench_plugins.bat</code> installs plugins and model library to Toolbench. It simply copies files from Lightsprint SDK.
  - If you modify and rebuild plugins, they are installed automatically.
  - Everything plugins need is in their Toolbench directories, Lightsprint SDK is not needed, so deployment to other computers is simple directory copy.
    Plugin directories are (in case of standard VC90 Shipping configuration)
    <code>\$(EMERGENT_PATH)\\sdk\\Win32\\Bin\\VC90\\Shipping\\Plugins\\Lightsprint.Toolbench.Plugin</code> and <code>\$(EMERGENT_PATH)\\sdk\\Win32\\Bin\\VC90\\Shipping\\Plugins\\Lightsprint.Toolbench.Plugin.UI</code>.

 \section g30_trouble Troubleshooting
  - \ref trouble_memory "How to process even bigger scenes"




\page main_conventions Conventions

 \section gobjects Terminology
   <b>Mesh</b> is a set of triangles and vertices with fixed positions in local space.
   \n\n
   <b>Object</b> is an instance of mesh, with position, rotation, scale
   and material properties.
   <b>Static object</b> never moves, rotates, deforms or changes material properties.
   <b>Dynamic object</b> freely changes these properties.
   \n\n
   <b>Scene</b> is a set of objects.
   \n\n
   <b>Lightmap</b> is a per-pixel buffer (texture) or a per-vertex buffer with irradiance values (incoming light),
   not modulated by material color.
   \n Lightmap could contain direct, indirect or global (both) illumination.
   \n Lightmap with indirect illumination is sometimes called <b>ambient map</b>.
   \n Textures are typically created in sRGB scale and 8bit per channel precision,
   vertex buffers are typically created in physical scale and float precision, but this is completely user defined,
   all combinations are supported.

 \section glinking Automatic library linking
   By default, including library header automatically links Lightsprint DLLs using \#pragma comment(lib,name).
   Debug library is linked to debug exe, Release library to release exe.
   \n \#define RR_STATIC / RR_GL_STATIC / RR_IO_STATIC selects static library instead of DLL.
   \n \#define RR_MANUAL_LINK / RR_GL_MANUAL_LINK  / RR_IO_MANUAL_LINK disables automatic library linking,
      so you can e.g. manually link release library with debug exe.
   \n (version with RR_ affects LightsprintCore, RR_GL_ affects LightsprintGL, RR_IO_ affects LightsprintIO)

 \section gunits Illumination units (radiometry, photometry, screen)
   Lightsprint computes all in HDR.
   Whole documentation talks in radiometry terms like irradiance,
   and Lightsprint internally works in radiometry units.
   All illumination measure inputs and outputs are 32bit float per component values.
   \n\n
   However, it is possible to communicate in screen colors
   or other units. Everything you need is to setup appropriate
   convertor, see RRDynamicSolver::setScaler(). Scaler internally converts values from native
   physical radiometry scale to your custom scale and vice versa.
   \n\n
   In typical situations, it is most straightforward to think and communicate
   in screen colors. This means you can set nearly all inputs in screen colors
   (scaled to 0-1 range) and read all outputs in screen colors.
   To setup this mode, call RRDynamicSolver::setScaler(RRScaler::createRgbScaler()).
   RealtimeRadiosity sample demonstrates it.

 \section gunits2 Geometry units
   All sizes and positions in space are expressed in generic units,
   Lightsprint doesn't need to know if it's meter, inch or parsec.
   However, some functions have default parameter values calibrated for
   human-sized scenes specified in meters (feature sizes roughly between
   0.01 and 100 units), so using meters may give you advantage in typical scenes.
   \n\n
   If it's possible, existing scene adapters adapt your scene from custom
   units to meters. (Source code of adapters is in samples/Import*)

 \section gscale Scale
   Lightsprint libraries support scaled objects.
   \n\n
   RRMesh and RRCollider support all scaled objects: positively or negatively, uniformly or non-uniformly scaled.
   \n\n
   RRObject and RRDynamicSolver support typical scaled objects:
   positively or negatively, uniformly scaled.
   \n Negative scale is supported with both possible interpretations
   for singlesided faces:
   Singlesided box visible from outside transformed with scale -1
   can stay visible form the outside or become visible only from inside,
   see RRObject::createWorldSpaceObject().

 \section gowner Ownership
   Dynamically created objects (using new, create() etc) are never adopted, ownership never changes.
   \n This means that parameters that need to be destructed are never destructed inside called function,
   responsibility for object is never passed to someone else.
   When you create object, always delete it yourself when no longer needed.

 \section gref Reference counting
   There is no internal reference counting, so if you create collider out of mesh,
   you are not allowed to destroy mesh before destroying collider. This danger should be
   mentioned on all appropriate places.

 \section gfinite Finite numbers
   If not otherwise specified, all inputs must be finite numbers.
   With Inf or NaN on input, result of any operation is undefined.
   (But still, we fixed all known errors caused by Inf/Nan
    and if you find and report us other Inf/NaN problem,
    we will fix it too.)

 \section gnull NULL
   Although NULL is obsoleted by C++ and some discourage from using it,
   we continue using it to distinguish zeros for pointers from zeros for non-pointers.
   So if you see x=0, x is NOT a pointer.
   If you see x=NULL, x IS a pointer.

 \section gmatrices Matrices
   Lightsprint uses 3x4 matrices for description of object transformation.
   See RRMatrix3x4 for explanation why we found it optimal.

 \section gup Up vector
   Although there is no limitation on orientation of 'up' vector,
   all samples work with 'up' in positive Y (0,1,0) and all scene adapters
   adapt scenes to 'up' in positive Y.
   Source code of adapters is in samples/Import*, so you can easily change up.






\page main_api API overview

 Lightsprint API consists of following libraries:

 - <b> \subpage api_core "LIGHTSPRINT CORE" </b> -
  Calculates global illumination in dynamic scenes.
  Includes fast ray-scene intersections.
  Is OpenGL/Direct3D independent, file format independent.

 - <b> \subpage api_gl "LIGHTSPRINT GL" </b> -
  Optional integration with OpenGL 2.0,
  realtime rendering with penumbra shadows.

 - <b> \subpage api_io "LIGHTSPRINT IO" </b> -
  Optional access to scenes and images stored on disk.

 structured into core layer and extensions:

 \image html libraries.png

 See \ref main_samples for more details on samples.






\page api_core Lightsprint Core

 \section core_overview Overview

 Lightsprint Core calculates global illumination in dynamic and static scenes.
 Subsystems include fast ray-scene intersections.
 It is OpenGL/Direct3D independent.

 \section core_api API

 Namespace: rr

 <hr>

 Header: Lightsprint/RRDynamicSolver.h

 - calculates global illumination in static or dynamic scenes, offline or realtime
 - gives you full control over speed/quality
 - calculated illumination is available in vertex buffers, lightmaps and environment maps
 - communicates completely in custom units, e.g. screen colors
 - purely CPU, extensions for realtime rendering on GPU implemented in rr_gl::RRDynamicSolverGL

 Samples RealtimeLights and RealtimeRadiosity show the result of integration,
 interactive Collada scene viewer with global illumination immediately responding
 to free movement of objects and lights.

 <hr>

 Headers: Lightsprint/RRScene.h

 - data structure (RRScene): 3d scene loaded from disk (objects, lights)

 <hr>

 Headers: Lightsprint/RRIllumination.h

 - data structure (RRObjectIllumination): object's illumination and more

 <hr>

 Header: Lightsprint/RRBuffer.h

 - data structure (RRBuffer): texture, cube map, vertex buffer

 <hr>

 Header: Lightsprint/RRObject.h

 - 3d object properties: geometry, materials, position etc

 <hr>

 Header: Lightsprint/RRCollider.h

 - finds ray-mesh intersections
 - thread safe, you can calculate any number of intersections at the same time
 - you can select technique in range from maximal speed to zero memory allocated
 - up to 2^32 vertices and 2^30 triangles in mesh
 - builds helper-structures and stores them in cache on disk

 Sample HelloCollider shows the most simple usage scenario:
 -# Create RRMesh using your vertex/index buffers.
 -# Create RRCollider using your mesh.
 -# Create RRRay using your ray.
 -# Call RRCollider::intersect() to find intersections. Repeat for all rays.

 Sample BunnyBenchmark shows how to detect collisions on all available
 CPUs/cores at once.

 <hr>

 Header: Lightsprint/RRMesh.h

 - interface to 3d triangle mesh
 - tristrips, trilists, indexed or not (RRMesh::create, RRMesh::createIndexed)
 - positions, normals, tangents, bitangents, texcoords
 - can optimize:
   - vertex welding (RRMesh::createOptimizedVertices)
   - removes degenerated triangles (RRMesh::createOptimizedTriangles)
 - merges many small meshes into one big mesh without additional memory (RRMesh::createMultiMesh)
 - allows for procedural meshes, requires no memory (implementing your RRMesh takes few minutes)
 - up to 2^32-2 vertices and 2^32-2 triangles in mesh
 - thread safe, you can use mesh in any number of threads at the same time

 Sample HelloMesh shows the most simple usage scenario,
 mesh is created out of existing array of vertices.

 <hr>

 Header: Lightsprint/RRMath.h

 - math classes used by whole Lightsprint SDK
 - RRReal holds one real number, which is single precision float
 - RRVec2 is vector of 2 real numbers
 - RRVec3 is vector of 3 real numbers
 - RRVec4 is vector of 4 real numbers

 <hr>

 Header: Lightsprint/RRDebug.h

 - debugging and reporting routines used by whole Lightsprint SDK
 - RRReporter processess all messages sent by Lightsprint SDK to you

 <hr>

 Header: Lightsprint/RRLight.h

 - RRLight interface for point/spot/dir lights

 <hr>

 Header: Lightsprint/RRVector.h

 - RRVector template, std::vector like container




\page api_gl LightsprintGL

 \section gl_overview Overview

 LightsprintGL implements realtime rendering on top of LightsprintCore.

 Features of LightsprintGL renderer
   - realtime global illumination
   - arbitrary number of realtime dynamic point, spot, directional lights
   - linear and area spotlights with realtime penumbra shadows
   - tone mapping
   - separately enabled/disabled light features:
     - color
     - projected texture
     - polynomial, exponential, none or physically correct distance attenuation models
     - shadows with variable softness, resolution, automatically cascaded in outdoor
   - separately enabled/disabled material features:
     - diffuse reflection: none, constant, per vertex, per pixel
     - specular reflection: none, constant, per vertex, per pixel
     - emission: none, constant, per pixel
     - transparency: none, constant, per pixel / blend or alpha keying
     - normal map
   - supports OpenGL 2.0 GPUs (GeForce 5xxx and higher, Radeon 9500 and higher etc)

 \section gl_api API

 Namespace: rr_gl

 <hr>
 Header: Lightsprint/GL/SceneViewer.h

 - rr_gl::sceneViewer() is a single function scene viewer, with movable lights, realtime GI,
   calculating static GI, 2d viewer of lightmaps and mappings, debugging outputs.
   RRDynamicSolver is usually black box. This viewer shows what's inside solver.

 <hr>
 Header: Lightsprint/GL/RRDynamicSolverGL.h

 - rr_gl::RRDynamicSolverGL extends RRDynamicSolver for realtime rendering in OpenGL 2.0

 <hr>
 Header: Lightsprint/GL/RendererOfScene.h

 - rr_gl::RendererOfScene is a renderer of 3d scene in RRDynamicSolver
 - renders environment, HDR
 - renders scene objects with precomputed or realtime computed illumination
 - detects what data are available (lightmaps, vertex colors)

 <hr>
 Header: Lightsprint/GL/RendererOfRRObject.h

 - rr_gl::RendererOfRRObject is a renderer of 3d objects with Lightsprint's RRObject interface
 - renders object with precomputed or realtime computed illumination

 <hr>
 Other headers (independent to LightsprintCore):

 - rr_gl::Texture is OpenGL texture, extension of RRBuffer needed for realtime rendering
 - rr_gl::Program is GLSL program
 - rr_gl::UberProgram is GLSL program with preprocessor parameters changeable at runtime
 - rr_gl::UberProgramSetup is set of parameters for our ubershaders UberShader.vs and UberShader.fs
 - rr_gl::Camera is frustum suitable for camera or spotlight
 - rr_gl::RealtimeLight is an extension of RRLight, structures needed for realtime GI rendering
 - rr_gl::Renderer is generic renderer interface



\page api_io LightsprintIO

 \section io_overview Overview

  LightsprintIO is an optional utility library that imports 3D scenes from a variety
  of file formats, namely:
  - <b>Gamebryo (.GSA)</b> - scene format of \ref main_gamebryo26 game engine
  - <b>Collada (.DAE)</b> - open, flexible and well supported format for digital asset exchange.
    Adapter loads geometry, materials and lights using FCollada library. See comments at the
    beginning of source file "src/LightsprintIO/ImportCollada/RRObjectCollada.cpp"
    for more details about features supported.
    General Collada development is documented at <a href="http://collada.org">[collada.org]</a>.
    Collada plugins for Max/Maya are available from several parties, see e.g. <a href="http://sourceforge.net/project/showfiles.php?group_id=136478">[sourceforge.net]</a>.
  - <b>3DS</b> - very old but popular format, despite the fact that its specification was never
    officially released. It supports only one set of texture coordinates, therefore it is
    not suitable for static lightmaps (which typically require another mapping channel).
    Adapter loads geometry and materials and uses open source 3DS loader. Known limitations:
    does not support lights, less common material properties and non-baked matrices.
  - <b>Quake 3 (.BSP)</b> - popular scene format used by Quake 3 engine. It supports only one set of
    texture coordinates so it is not suitable for scenarios where static lighting calculation
    into lightmaps is required (see 3DS). Adapter loads geometry and materials. Known limitations:
    does not support lights, script-based materials and curved surfaces.
  - <b>OBJ</b> - old, plain text based format popular mainly because of its simplicity. It is suitable
    for loading of single objects but not whole scenes, since it lacks support for lights.
    For details, see <a href="http://en.wikipedia.org/wiki/Obj">Wikipedia</a>. Known limitations:
    does not support materials and lights.
  - <b>MGF</b> - Materials and Geometry Format is an open but old and rarely used 3D format.
    For details, see <a href="http://radsite.lbl.gov/mgf/HOME.html">MGF homepage</a>.
    Adapter loads .MGF file using parts of the source code taken from mgflib (see the link above).
    Known limitations: only convex polygons are triangulated properly.
  - <b>source code</b> of individual adapters is located in their respective directories within
    <code>src/LightsprintIO</code>

  LightsprintIO loads and saves 2d images and loads cubemaps in a variety of formats:
  - <b>png</b> - widely used format with good lossles compression
  - <b>jpg</b> - the most widely used lossy format
  - <b>jp2</b> - jpeg 2000, lossy, even smaller files
  - <b>dds</b> - GPU friendly lossy format, games load it directly into GPU without decompression
  - <b>tga</b> - widely used, extremely simple format without compression
  - <b>hdr</b> - floating point precision
  - <b>exr</b> - floating point precision
  - <b>bmp, gif, pcx, tiff, ico, iff, jbig, pbm, pgm, ppm, xpm etc...</b> - other 
  - <b>source code</b> is in <code>src/LightsprintIO/ImportImages/ImportFreeImage.cpp</code>

  LightsprintIO loads and saves vertex buffers with per-vertex lighting:
  - <b>vbu</b> - the only Lightsprint proprietary format, extremely simple
  - <b>source code</b> is in <code>src/LightsprintIO/ImportImages/ImportFreeImage.cpp</code>

 \section io_api API

  Namespace: rr_io

  <hr>
  Header: Lightsprint/IO/ImportScene.h

  - rr_io::registerLoaders() registers all loaders implemented in this library,
    \n use RRScene and RRBuffer to load and save files



\page main_samples Samples

 \section samples_root By purpose

 - \subpage samples_realtime
 - \subpage samples_offline
 - \subpage samples_collider



\page samples_offline Off-line rendering

 Following projects use LightsprintCore library for off-line rendering.
 \n They are located in samples directory in the SDK, binaries in bin.
 \n Results are usually saved to data/export directory.

 <hr>
 <b>Lightspeed</b>
 - for Lightspeed samples, see \ref main_gamebryo30

 <hr>
 <b>BuildLightmaps</b>
  <table border=0 width=95%><tr align=top><td>
  \image html samples/BuildLightmaps_2.jpg builds standard and directional lightmaps
  </td><td>
  \image html samples/BuildLightmaps_1.jpg ambient occlusion, bent normals...
  </td></tr></table>
 - commandline tool
 - loads Collada / Gamebryo scenes
 - builds lightmaps / directional lightmaps / occlusion / bent normals
 - builds global / direct / indirect illumination, with infinite light bounces and color bleeding
 - builds per-pixel / per-vertex
 - saves jpg / png / hdr / tga / bmp / exr / jp2 / tif / pcx / etc
 - optional viewer of results

 <hr>
 <b>CPULightmaps</b>
  <table border=0 width=95%><tr align=top><td>
  \image html samples/CPULightmaps_1.jpg computed lightmap
  </td><td>
  \image html samples/CPULightmaps_2.jpg computed bent normal map
  </td></tr></table>
 - builds lightmaps like BuildLightmaps sample
 - very short source code, no options, no GUI


\page samples_collider Ray-mesh intersections

 Following projects use LightsprintCore library for ray-mesh collision calculations.
 \n They are located in samples directory in the SDK, binaries in bin.
 \n Results are displayed in text console.

 <hr>
 <b>BunnyBenchmark</b>
 - measures Collider performance for comparison with other engines
 - uses OpenMP to employ all available CPUs/cores
 - Collider results are up to 200x better than commercial physical engines

 <hr>
 <b>MultiMeshCollider</b>
 - ray-multimesh collision test, for static scenes with multiple meshes

 <hr>
 <b>HelloCollider</b>
 - the most simple case of ray-mesh collision test

 <hr>
 <b>HelloMesh</b>
 - the most simple case of mesh creation



\page samples_realtime Real-time rendering

 Following projects use LightsprintGL library for rendering
 and LightsprintCore for lighting calculations.
 \n They are located in samples directory in the SDK, binaries in bin.

 <hr>
 <b>Lightsmark</b>
  <table border=0 width=95%><tr align=top><td>
  \image html samples/Lightsmark2.jpg
  </td><td>
  \image html samples/Lightsmark3.jpg
  </td></tr></table>
 - realtime GI in scene from real game (World of Padman)
 - original scene without any modifications is loaded to show engine robustness
 - undocumented feature: enter interactive mode by spacebar, control everything yourself, F1=help
 - complete Lightsmark is not part of SDK,
   but you can <a href="http://dee.cz/lightsmark">download it here</a>,
   source code on request

 <hr>
 <b>MovingSun</b>
  <table border=0 width=95%><tr align=top><td>
  \image html samples/MovingSun_1.jpg dynamic Sun
  </td><td>
  \image html samples/MovingSun_2.jpg dynamic objects
  </td></tr></table>
 - GI, tone mapping, dynamic objects lit by dynamic Sun and skybox
 - loads collada scene, drag&drop to open custom scene
 - when opened for first time, runs precalculations

 <hr>
 <b>SceneViewer</b>
  <table border=0 width=95%><tr align=top><td>
  \image html samples/SceneViewer_1.jpg move lights, compare realtime/offline GI
  </td><td>
  \image html samples/SceneViewer_2.jpg made for testing, debugging
  </td></tr></table>
 - single function call: sceneViewer(), you can run it from your code to visualize data
 - realtime GI: freely move all lights, no precalculations
 - precomputed GI: test build/load/save lightmaps
 - debugging: add/remove lights, see rays shot from individual triangles or texels
 - loads collada, 3ds, quake3, obj, mgf scenes

 <hr>
 <b>RealtimeLights</b>
  <table border=0 width=95%><tr align=top><td>
  \image html samples/RealtimeLights_1.jpg freely move lights and objects
  </td><td>
  \image html samples/RealtimeLights_2.jpg occluded light, GI changes in realtime
  </td></tr></table>
 - realtime GI, color bleeding
 - all lights and objects movable
 - no precalculations -> for scene viewers, designers
 - loads collada scene including all lights, loads 3ds dynamic objects
 - uses internal renderer

 <hr>
 <b>RealtimeRadiosity</b>
  <table border=0 width=95%><tr align=top><td>
  \image html samples/RealtimeRadiosity_2.jpg freely move light, objects
  </td><td>
  \image html samples/RealtimeRadiosity_1.jpg global illumination changes in realtime
  </td></tr></table>
 - realtime GI, color bleeding, penumbra shadows
 - all lights and objects movable
 - optional precalculations -> for games
 - loads 3ds scene and 3ds dynamic objects, uses 1 custom area light rather than lights from file
 - shows that lighting works equally well for animated object
 - shows feeding external 3ds renderer with Lightsprint computed illumination

 <hr>
 <b>Lightmaps</b>
  <table border=0 width=95%><tr align=top><td>
  \image html samples/Lightmaps_1.jpg realtime GI = fully dynamic
  </td><td>
  \image html samples/Lightmaps_2.jpg lightmaps + lightfield = faster
  </td></tr></table>
 - demonstrates differences between realtime and precomputed lighting
 - starts with fully realtime GI (both lights and objects dynamic)
 - after pressing 'p', switches to lightmaps+lightfield (faster, but light is static)

 <hr>
 <b>PenumbraShadows</b>
  <table border=0 width=95%><tr align=top><td>
  \image html samples/PenumbraShadows_1.jpg penumbra shadows
  </td><td>
  \image html samples/PenumbraShadows_2.jpg penumbra shadows
  </td></tr></table>
 - renders realtime direct illumination in scene with dynamic objects and area light
 - penumbra shadows
 - simple, no global illumination, only constant ambient




\page main_trouble Troubleshooting

 Please report us problems you encounter. Your feedback is very important.

 - \subpage trouble_memory

 - \subpage trouble_exes_dont_run


\page trouble_memory Not enough memory?

  Use our 64bit code (fully supported by Lightsprint) whenever possible.
  With 64bit code, system memory is better utilized, you can process scenes of all sizes.

  If you must use 32bit code (because your engine is 32bit only, e.g. UE3, Gamebryo),
  address space is severely limited by operating system, application can't use whole memory, purchasing more RAM usually does not help.

  If you must use 32bit code, run it in 64bit operating system, this gives you 4GB of address space per-process.
  It is good enough for majority of tasks today.

  If you must use 32bit Windows, use /3GB parameter in boot.ini, this gives you 3GB of address space per-process.

  Using 32bit Windows without /3GB parameter is worst case scenario, process has only 2GB address space,
  so tasks like lightmap building can't process huge scenes.


\page trouble_exes_dont_run Windows executables don't run

  If Windows refuses tu run Lightsprint executables, reporting errors like
  - <code>The application failed to initialize properly (0xc0150002).</code>
  - <code>LDR: LdrpWalkImportDescriptor() failed to probe ... for its manifest, ntstatus 0xc0150002</code>

  make sure your system is up to date, install all service packs and security updates for Windows (and for Visual Studio, if installed).

*/

};
