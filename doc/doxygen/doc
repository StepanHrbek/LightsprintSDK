namespace rr
{

/**

\file doc
\brief Documentation only.


\mainpage Lightsprint SDK

 \image html intro.jpg

 \section root_welcome Welcome to Lightsprint Software Development Kit
 - \subpage main_introduction
 - \subpage main_ue3
 - \subpage main_news
 - \subpage main_scenarios
 - \subpage main_features
 - \subpage main_platforms
 - \subpage main_credits

 \section root_guide Programming guide
 - \subpage main_integration
 - \subpage main_inputs
 - \subpage main_data_access
 - \subpage main_conventions "Conventions (units, scale, floats...)"
 - \subpage main_api

 \section root_samples Samples and tutorials
 - \subpage main_samples
 - \subpage main_howto




\page main_introduction Introduction

  Realistic illumination looks good and attracts more users.
  While direct illumination has been 'solved' by science and software developers of 20th century,
  global illumination still challenges both sides. \subpage details

  Lightsprint is first to come with physically correct 
  global illumination synthesis so fast, that it 
  is suitable not only for precalculations, but also for realtime rendering in dynamic scenes.

  Lightsprint SDK offers you single flexible API for both realtime global illumination rendering
  and non-realtime lighting precalculations.

 \image html lowpoly3.jpg
  <center>realtime global illumination in scene with dynamic light and dynamic objects</center>


\page details Details
 In our real world, we see visible light coming mostly from special surfaces 
 (hot wolfram fibre in bulb, luminofor of fluorescent lamp)
 or from whole volumes of plasma (sun, fire).
 We call these surfaces and volumes <b>source of direct illumination</b>.

 Light from sources of direct illumination reaches other surfaces 
 where part of light gets absorbed and part reflected.
 Reflected part is what we see and what makes objects look lit by direct illumination.
 When we see the reflected part, we say that object has <b>direct illumination</b>.

 Reflected light from direct illumination reaches other surfaces, partially reflects,
 reaches other surfaces, partially reflects etc.
 When we see sum of these reflected parts, we say that object has <b>indirect illumination</b>.

 Illumination we see in real world is sum of direct and indirect illumination.

 Computer graphics tries to simulate this process in order to generate realistic images.
 This is however very time consuming process.
 So realtime computer graphics in 99% of cases resigns to real-world sources of direct 
 illumination and uses imaginary <b>"point", "spot" or "directional" lights</b>.
 These fictitious sources of direct illumination
 allow realtime computer graphics to calculate direct illumination very quickly.
 This process includes calculation of <b>shadows in direct illumination</b>.
 There are many realtime techniques for calculating shadows in direct illumination,
 most notably shadow mapping, volumetric/stencil shadows and projected/texture based shadows.

 There is still problem with indirect illumination, which remains
 hard to be computed quickly.




\page main_scenarios Usage scenarios

 \section scenario2 Lightsprint in toolchain, precomputes GI, realtime GI previews

  - Saves months of work to graphics artists and designers,
    previously spent in lightmap rebuilds or fake light placement.

  - Realtime GI preview allows artists to find visually more attractive positions / settings for lights.

  - Saves months spent in adapting your data for external global illumination
    tools. Other tools don't support arbitrary materials and lights.

  - Fast path for incorporating realtime global illumination into future games.

 \section scenario1 Lightsprint in game or architectural visualization, renders realtime GI

  - Greatly improves realism and visual appeal.

  - Requires zero or minimal level preprocessing, saves time previously spent on infinite levels builds.

  - Simplifies integration of mods and other user provided assets.

  - Supports arbitrary materials / shaders, even those writen by modders
    after game release.

  - Publicity, be first with this level of realism in game.

  - See <a href="http://dee.cz/lightsmark">Lightsmark 2007</a>
    as an example, it's a simple demo based on Lightsprint SDK.

  \image html samples/Lightsmark3.jpg



\page main_features Features

This is a brief list of Lightsprint features, see \ref main_data_access,
\ref main_api and \ref main_samples for more details.

Global illumination
- realtime global illumination
- realtime penumbra shadows, soft shadows
- realtime color bleeding
- dynamic lights
- dynamic objects
- multithreaded, all cores/CPUs and GPU work at once
- supports work distributed in cluster of computers
- computed and rendered in HDR
- custom scale on inputs/outputs (HDR/sRGB/other)
- scene size not limited
- mesh instancing
- mesh filters, optimizers
- adaptive subdivision

Light source formats (inputs)
- spot light
- point light
- directinal light
- skybox/cubemap
- skybox/programmable
- emissive material
- area light
- linear light
- custom programmable light

Lighting computed (outputs)
- lightmap, directional lightmap
- ambient map
- ambient occlusion, global ambient occlusion
- diffuse environment map
- specular environment map
- bent normal map
- vertex buffer with colors or bent normals
- illumination of triangle, including adaptively subdivided
- illumination of vertex, including adaptively subdivided
- illumination at ray end
- any combination of direct/indirect/global illumination

Renderers
- integrates with external renderers
- contains OpenGL 2.0 shader based renderer

Scene formats
- Collada 1.4 (.DAE)
- 3DS Max (.3DS)
- Quake 3 (.BSP)
- OBJ (.OBJ)
- MGF (.MGF)
- Unreal Engine 3 (internal structures)
- framework for custom formats
- complete source code

Texture formats
- JPG, PNG, DDS, GIF, TGA, BMP, TIF, HDR...
- including cube textures
- including 96bit float colors

Materials
- supports all types of materials
- diffuse maps, specular maps
- normal maps, emissive maps

Realtime/precomputed
- supports realtime illumination
- supports precomputed illumination
- supports mix of realtime and precomputed illumination

GPU/API access
- full control over GPU access, source code
- full control over filesystem access, source code
- full control over scene data loading, source code

Ray-Mesh collisions
- up to 200x faster than commercial physical engines
- small memory footprint, typically 10x smaller than commercial physical engines
- multithreaded
- up to 4294967295 vertices in mesh
- up to 1073741824 triangles in mesh
- triangle lists/strips/indexed/nonindexed
- floats, doubles, halfs, ints, shorts
- custom mesh data structures without data duplication
- uniform scaling, non uniform scaling
- singlesided tests, doublesided tests
- number of sides defined by material
- return one or gather all collisions
- custom action at collision
- returns intersection distance, 2D and 3D position
- returns normal, plane and face side that was hit
- high precision, higher than commercial physical engines
- high reliability, 7 years under heavy load





\page main_credits Third party libraries

Lightsprint integrated into game engine doesn't need any third party library.

Standalone Lightsprint SDK uses several free open source libraries with permissive licenses,
for scene loading and GPU access.
You are free to download their sources and rebuild, use them in commercial applications etc.
Use of these libraries is optional, global illumination solver works without them.

Libraries used by LightsprintCore (global illumination solver):
- <a href="http://boost.org">boost</a>
  - optional, remove by deleting \#define USE_BOOST_POOL in src/LightsprintCore/RRDynamicSolver/gather.h
  - only headers accessed when building LightsprintCore from sources (only when you license source code),
    no library needed (no .dll/.so)
  - Windows: download from <a href="http://boost.org">boost web</a> and unpack, no need to build
  - Linux (including PS3): install using e.g. <code>sudo apt-get install libboost-dev</code>
- <a href="http://mesa3d.org/">Mesa 3D</a>
  - Only required on PS3 Linux as a rendering front end for samples, since there are no
    hardware accelerated RSX drivers provided. Please follow these installation instructions:
    - download and unpack MesaLib and MesaGLUT packages (the latest version at the time of
      writing this document is 7.0.3).
    - type <code>make linux-ppc</code>
    - open the file "configs/default" and make sure the variable <code>INSTALL_DIR</code> is set to <code>usr/local</code>.
      This will ensure that Mesa will install to <code>/usr/local/lib</code> and will not interfere with the system default
      OpenGL library located at <code>usr/lib</code>.
    - type <code>sudo make install</code>
    - type <code>export LD_LIBRARY_PATH=/usr/local/lib</code> to make linker search for Mesa

Used by LightsprintGL (optional OpenGL support):
- GLU
  - Windows: should be already installed, part of PlatformSDK by Microsoft
  - Linux (including PS3): should be already installed, install using e.g. <code>sudo apt-get install libglu1-mesa-dev</code>
  - XBox360, PS3 with system software: not necessary
- <a href="http://glew.sourceforge.net/">GLEW</a>
  - Windows: precompiled version 1.5.0 is a part of SDK
  - Linux: install using <code>sudo apt-get install libglew1.5-dev</code> or similar package manager
    - Note that we <code>\#include <GL/glew.h></code>, but SDK contains <code>include/gl/glew.h</code>.
      This ensures that version we bundle for Windows won't be used on Linux.
      You can safely install and use different version in your Linux system.
  - PS3 Linux:
    - download and unpack the latest source code package
    - type <code>make</code>
    - type <code>sudo make install</code>
    - There is a known issue with simultaneously using GLEW and Mesa: GLEW happens to undefine
      macro <code>GLAPIENTRY</code> which leads to compile errors. As a workaround, open the file
      "/usr/include/GL/glew.h" and comment-out the statement <code>\#undef GLAPIENTRY</code> at line 10767
      (valid for version 1.5.0)
  - XBox360, PS3 System Software: not necessary
- <a href="http://www.opengl.org/resources/libraries/glut/">GLUT</a>
  - Windows: precompiled version 3.7.6 <a href="http://dee.cz/glut">patched</a> is a part of SDK
  - Linux (including PS3): install using e.g. <code>sudo apt-get install libglut3-dev</code>
    - Note that we <code>\#include <GL/glut.h></code>, but SDK contains <code>include/gl/glut.h</code>.
      This ensures that version we bundle for Windows won't be used on Linux.
      You can safely install and use different version in your Linux system.
  - XBox360, PS3 with system software: not necessary

Used by LightsprintIO (optional file format support):
- <a href="http://freeimage.sourceforge.net/">FreeImage</a>
  - This software uses the FreeImage open source image library. FreeImage is used under the FIPL, version 1.0.
  - optional, remove by deleting \#define USE_FREEIMAGE in src/LightsprintIO/ImportFreeImage.cpp (for Linux, remove linking from makefile)
  - Windows: precompiled version 3.10.0 is a part of SDK
  - Linux (including PS3 Linux): install using e.g. <code>sudo apt-get install libfreeimage-dev</code>
    - Note that we <code>\#include <FreeImage.h></code>, but SDK contains <code>include/freeimage.h</code>.
      This ensures that version we bundle for Windows won't be used on Linux.
      You can safely install and use different version in your Linux system.
  - XBox360, PS3 with system software: not necessary
- <a href="http://www.feelingsoftware.com/content/view/62/76">FCollada</a>
  - by Feeling Software, used under MIT license
  - optional, remove by deleting \#define USE_FCOLLADA in src/LightsprintIO/ImportCollada/RRObjectCollada.cpp (for Linux, remove references from makefile)
  - Windows, Linux (including PS3): precompiled version 3.05B is a part of Lightsprint SDK
  - XBox360, PS3 with the System Software: not necessary
  - Linux / PS3 Linux: If you wish to build the library on your own, please note that the version 3.05B
    (which is the latest one available at the time of writing this document) does not yet officially support Linux.
    It is likely that this will change in the near future. Until then, please follow these instructions:
    - Download and unpack the "FCollada_FREE_3.05B.zip" package from <a href="http://sourceforge.net/projects/colladamaya/">Sourceforge</a>.
    - Rename the directory "FCollada/LibXML" to "FCollada/libxml" in order to prevent case sensitivity problems in includes.
    - Define preprocessor token "LINUX" in your project/makefile settings. This is necessary since FCollada sources rely on it
      and some Linux distributions define just lowercase "linux" token.
    - Use O2 optimization level for release version to prevent linking issues with templates.
    - Open the file "FCollada/FUtils/FUFileManager.cpp" and change "size" to "(unsigned int) size" at line 392.
    - On 64-bit platforms, open the file "FCollada/FUtils/FUStringBuilder.h" and replace "long" by "long long" at lines 139 and 140.
    - We provide a makefile located at "src/LightsprintIO/ImportCollada" for your convenience.
- <a href="http://xmlsoft.org/">libxml2</a>
  - used under MIT license
  - Libxml2 library is required in Linux environment by FCollada. Although it is likely that
    this library will be already bundled with your system, you can install it manually using
    your Linux packaging tool, e.g. <code>sudo apt-get install libxml2-dev</code>

Remark:
- when installing dependencies on Debian based Linux (Ubuntu etc), it can be done by single command
  <code>sudo apt-get install libboost-dev libglu1-mesa-dev libglew1.5-dev libglut3-dev libfreeimage-dev libxml2-dev</code>


\page main_integration Integration

 \section integr_tool Precalculations / for toolchain
  - \ref main_ue3 "Precalculations in Unreal Editor"
  - \subpage integration_tool_1
  - \subpage integration_tool_2

 \section integr_rt Realtime / in game
  - \subpage integration_realtime_1
  - \subpage integration_realtime_3
  - \subpage integration_realtime_4




\page integration_tool_1 Precalculations in your scene loaded from disk

 You can immediately calculate lightmaps, ambient maps and bent normals
 if you convert your scenes to supported formats and use existing
 sample applications.

 <table width=100% border=0 cellpadding=3 cellspacing=0><tr align=left style="background-color:#dddddd"><td>
 Recommended approach:
 </td></tr></table>

  - Convert your scene to Collada format,
    and load it into CPULightmaps, AmbientOcclusion, SceneViewer or Lightmaps sample.

 <table width=100% border=0 cellpadding=3 cellspacing=0><tr align=left style="background-color:#dddddd"><td>
 Scheme of application:
 </td></tr></table>

  - CPULightmaps sample 
    is built on top of purely numerical LightsprintCore and scene importers.
    AmbientOcclusion, SceneViewer and Lightmaps samples use also OpenGL 2.0 based LightsprintGL.
    Left: CPULightmaps. Right: AmbientOcclusion, SceneViewer, Lightmaps.
  <table border=0 width=95%><tr align=top><td>
  \image html Integration1c.png
  </td><td>
  \image html Integration1b.png
  </td></tr></table>

 <table width=100% border=0 cellpadding=3 cellspacing=0><tr align=left style="background-color:#dddddd"><td>
 Steps:
 </td></tr></table>

  - <b> \subpage integration_step_1 </b> (important for all Lightsprint use cases, not only for this sample)
  - Convert scenes to Collada 1.4 (.DAE).
  - If you plan to compute maps rather than per-vertex values, include unwrap in second uv channel.
  - Change name of scene in sample .cpp, so it loads your scene. Or drop your scene on SceneViewer*.exe.

 <table width=100% border=0 cellpadding=3 cellspacing=0><tr align=left style="background-color:#dddddd"><td>
 Expected time spent:
 </td></tr></table>

  - 1 day


\page integration_tool_2 Precalculations in your scene accessed in memory

  If you prefer other data source to Collada,
  use your scene loader and write adapter for accessing your scene in memory.

 <table width=100% border=0 cellpadding=3 cellspacing=0><tr align=left style="background-color:#dddddd"><td>
 Recommended approach:
 </td></tr></table>

  - Modify SceneViewer sample to access scenes loaded to memory by your loader.

 <table width=100% border=0 cellpadding=3 cellspacing=0><tr align=left style="background-color:#dddddd"><td>
 Scheme of application:
 </td></tr></table>

  - Modified SceneViewer newly depends on your scene loading code.
  \image html Integration2.png

 <table width=100% border=0 cellpadding=3 cellspacing=0><tr align=left style="background-color:#dddddd"><td>
 Steps:
 </td></tr></table>

  - Open SceneViewer project
  - Copy RRObjectCollada.* to RRObjectCustom.* and add it to the project
  - Delete all FCollada \#includes from RRObjectCustom.h
  - Build reports errors on all references to FCollada,
    change code so it works with your engine's 3d model rather than with FCollada.
    Replace all references to FCollada with your custom format.
    For more details, see
    - comments in RRObjectCustom source code
    - <b> \subpage integration_step_2 </b>
    - <b> \subpage integration_step_3 </b>
    - interfaces of RRMesh and RRObject you implement
  - Done. SceneViewer renders scene in your native format.
    You can test both realtime and precalculated per-vertex and per-pixel lighting.
    You can use your new scene adapter in any sample.

 <table width=100% border=0 cellpadding=3 cellspacing=0><tr align=left style="background-color:#dddddd"><td>
 Expected time spent:
 </td></tr></table>

  - 1-4 days




\page integration_realtime_1 Realtime GI in Lightsprint renderer

 You can immediately render realtime global illumination in your 3d scenes
 if you convert them to supported format and load into existing sample application.
 You can also use \ref integration_tool_2 "your scene loader and adapter".

 <table width=100% border=0 cellpadding=3 cellspacing=0><tr align=left style="background-color:#dddddd"><td>
 Recommended approach:
 </td></tr></table>

  - Convert your scene to Collada format
    and load it into Lightmaps or RealtimeLights (or load .3ds to RealtimeRadiosity) sample.

 <table width=100% border=0 cellpadding=3 cellspacing=0><tr align=left style="background-color:#dddddd"><td>
 Scheme of application:
 </td></tr></table>

  - Lightmaps and RealtimeRadiosity samples are
    built on top of purely numerical LightsprintCore, OpenGL 2.0 based LightsprintGL and scene importers.
    Left: Lightmaps. Right: RealtimeRadiosity.
  <table border=0 width=95%><tr align=top><td>
  \image html Integration1b.png
  </td><td>
  \image html Integration1a.png
  </td></tr></table>

 <table width=100% border=0 cellpadding=3 cellspacing=0><tr align=left style="background-color:#dddddd"><td>
 Steps:
 </td></tr></table>

  - <b> \subpage integration_step_1 </b> (important for all Lightsprint use cases, not only for this sample)
  - Convert scenes to Collada 1.4 (.DAE).
  - Change name of scene in Lightmaps.cpp, so it loads your scene.

 <table width=100% border=0 cellpadding=3 cellspacing=0><tr align=left style="background-color:#dddddd"><td>
 Expected time spent:
 </td></tr></table>

  - 1 day



\page integration_realtime_3 Realtime GI in your OpenGL renderer

  If you prefer other OpenGL renderer to LightsprintGL, switch to renderer of your choice.

 <table width=100% border=0 cellpadding=3 cellspacing=0><tr align=left style="background-color:#dddddd"><td>
 Recommended approach:
 </td></tr></table>

  - Modify RealtimeRadiosity sample to use your renderer.
    Or modify your application/engine to use code from RealtimeRadiosity sample
    that builds realtime GI buffers.

 <table width=100% border=0 cellpadding=3 cellspacing=0><tr align=left style="background-color:#dddddd"><td>
 Scheme of application:
 </td></tr></table>

  - Application uses LightsprintCore and LightsprintGL to calculate GI,
    while your engine does scene loading and rendering.
  \image html Integration3.png

 <table width=100% border=0 cellpadding=3 cellspacing=0><tr align=left style="background-color:#dddddd"><td>
 Steps:
 </td></tr></table>

  - Make sure your renderer supports realtime shadows other than stencil based, e.g. shadowmapping
    or projected shadows. If it doesn't, add them or contact us for further support.
  - <b> \subpage integration_step_4 </b>
  - <b> \subpage integration_step_5 </b>
  - Render our indirect illumination, see <b> \ref main_data_access </b>

 <table width=100% border=0 cellpadding=3 cellspacing=0><tr align=left style="background-color:#dddddd"><td>
 Expected time spent:
 </td></tr></table>

  - 1 week




\page integration_realtime_4 Realtime GI in any renderer

  If you want to use your renderer, but it is not OpenGL based,
  write custom GPU access routines as a replacement for LightsprintGL.

 <table width=100% border=0 cellpadding=3 cellspacing=0><tr align=left style="background-color:#dddddd"><td>
 Recommended starting point:
 </td></tr></table>

  - Modify your application/engine to use LightsprintCore.

 <table width=100% border=0 cellpadding=3 cellspacing=0><tr align=left style="background-color:#dddddd"><td>
 Scheme of application:
 </td></tr></table>

  - Different approaches: You can expose Lightsprint engine to your
    applications or hide it inside your engine.
  <table border=0 width=95%><tr align=top><td>
  \image html Integration4a.png
  </td><td>
  \image html Integration4b.png
  </td></tr></table>

 <table width=100% border=0 cellpadding=3 cellspacing=0><tr align=left style="background-color:#dddddd"><td>
 Steps:
 </td></tr></table>

  - <b> \subpage integration_step_6 </b>
  - render with computed data stored in RRBuffer lightmaps, environment maps and vertex buffers.
    See rr_gl::getTexture() as an example how texture buffers are adapted for use in OpenGL,
    it's basicly glTexImage2D(...,buffer->lock(BL_READ)) call. Alternatively, you can subclass
    RRBuffer so that it stores data directly in your renderable surface.

 <table width=100% border=0 cellpadding=3 cellspacing=0><tr align=left style="background-color:#dddddd"><td>
 Expected time spent:
 </td></tr></table>

  - 1-3 weeks






\page integration_step_1 Validate static meshes

 This step is typically executed by 3d artists.

 Calculation produces better results
 when static 3d triangle meshes satisfy these conditions:

 \section cond_matching Cleanly connected triangles
 Two triangles are disjunct,
 share 1 vertex or share 1 edge and 2 vertices.

 So it is not allowed to
 - overlap triangles
 - intersect triangles
 - place edge in the middle of other triangle
 - place vertex in the middle of other edge

 \image html triangles.png

 See that all forbidden cases can be easily fixed.
 This operation can be automated.

 \section cond_no_needles No needles

 Angle sizes in triangles should be greater than 5 degrees.

 \section cond_no_hihpoly Prefer maps over high poly

 Polygon counts in dynamic objects have no influence on speed,
 but excessive polygon counts in static scene reduce performance.
 So for static scene,
 prefer normal maps or other tricks that reduce polygon count.






 
\page integration_step_2 Detect material properties

 Realtime global illumination is based on physically correct calculation of light transport.
 For such calculation it's necessary to know physical properties of surfaces.
 See RRMaterial for list of supported material properties of a surface.

 Fortunately you don't have to study advanced laws of physics for good results,
 you don't even need any additional information provided by artists who
 create materials or compose shaders. Everything can be detected automatically.

 In <b>special case</b> of RealtimeRadiosity example, materials contain diffuse texture
 without specular and transparency, so whole detection was reduced to calculating
 average color of diffuse texture and storing it into RRMaterial::diffuseReflectance.
 This took 1 hour.

 In <b>more general case</b> with known set of shaders,
 you can extend this approach and get all values by analyzing textures and other inputs
 used by shaders.
 This can take you few hours.
 Viability of this approach highly depends on your shaders and can't be decided here.
 If you are not sure, describe us your shaders and we will help you.

 In <b>fully general case</b>, you don't need any information about shaders.
 It works even if you let modders create new shaders, their properties will be autodetected.
 Everything you need is ability to render simple scene into small texture (16x16 pixels
 is typically enough)
 and calculate average color of rendered image. Follow these steps for each material

 -# Create empty scene and place 1x1m rectangle covered by material in front of camera
    in 0.5m distance (so it covers whole viewport, but nothing more).
    If it has uv coordinates for textures, use whole texture space from 0,0 to 1,1 in rectangle.
 -# Clear to black and render rectangle.
    Store acquired average color as RRMaterial::diffuseEmittance.
 -# Clear to white and render rectangle.
    Store acquired average color minus emittance as RRMaterial::specularTransmittance.
 -# Add white point light without distance attenuation to the same position as camera.
    Clear to black and render rectangle.
    Store acquired average color minus emittance as RRMaterial::diffuseReflectance.
 -# Call RRMaterial::validate() to clamp values to physically correct bounds.
    This is necessary to prevent damage from materials that e.g. reflect more light
    than they receive. Such behaviour is not possible in real world and may cause
    unexpected results in calculation such as infinitely high indirect illumination.

 -  If you use materials with faked reflection maps (planar or cubic),
    make sure that reflection intensity drops to 0 in dark scene,
    or manually disable it before detection.
    If you apply faked reflection even in completely dark unlit scene, detection described above
    must think it's emissive material.
    Alternatively, if you don't have any emissive materials, you can simply set emissivity to 0.

 This automatic approach can be further extended to differentiate between
 diffuse and specular reflectance or even to detect complete BRDF.

 Of course you are allowed to use any other approach, e.g. let graphics artists
 enter all values by hand.



\page integration_step_3 Create object adapters

 Lightsprint transports light between object surfaces,
 so it needs to know everything
 about scene geometry and material properties.

 Lightsprint is designed to access your structures in arbitrary format,
 so you don't have to duplicate any data.
 This may save you huge amounts of memory, however,
 you must provide adapters that access your structures.

 Further saving is possible thanks to geometry instancing.
 Multiple objects with different materials and different illumination
 may share one mesh and collider.

 \section import_without_instancing Import without instancing

 For import without geometry instancing,
 see one of samples/Import3DS, samples/ImportQuake3, samples/ImportOBJ,
 samples/ImportMGF.
 It is everything necessary to load 3ds, Quake3, obj or mgf scene into 
 RRDynamicSolver.

 For sake of simplicity, adapters duplicate some data in memory
 and don't support geometry instancing.
 On the other hand, support for custom data is demonstrated
 on diffuse textures and uv coordinates.

 Both RRMesh and RRObject interfaces are implemented in one class,
 so one RRMesh can't be shared by multiple RRObject-s
 and instances are not supported.

 \section import_with_instancing Import with instancing

 For import with instancing, see samples/ImportCollada.
 (adapter for scenes loaded by freely available FCollada library)
 or samples/ImportUE3 (adapter for import from Unreal Engine 3).

 Adapters don't duplicate any memory, all data are accessed directly
 in FCollada document.

 RRMesh and RRObject interfaces are implemented in two separated classes,
 and one RRMesh is shared by multiple RRObject-s, if scene contains instances.

 \section import_new New importer

 To import data in your format, pick one of existing importers
 and modify it to access your data.

 Alternatively, to write new importer from scratch, follow these steps:

 -  Create RRMesh for every static triangle mesh in your engine.
    \n\n
    You can immediately create them 
    from trilists, tristrips, indexed trilists, indexed tristrips
    using single call to RRMesh::create() or RRMesh::createIndexed().
    For other formats ask for our support or implement your own RRMesh,
    which is very simple.
    \n\n
    Note that these adapters don't duplicate your data
    and they support mesh optimizations and mesh aggregation,
    see RRMesh for details.
    \n\n
    Once you have RRMesh instance, create RRCollider using
    RRCollider::create().
    RRCollider::IT_LINEAR technique with minimal overhead is sufficient 
    for current version of RRDynamicSolver.
    \n\n
    Most convenient way to remember collider for later use is to
    attach it to your triangle mesh.
    You don't need to store pointer to RRMesh,
    it is available from collider using RRCollider::getMesh().
    \n\n
    RRDynamicSolver may use collider to calculate ray-mesh collisions,
    but it is available also to you via RRCollider::intersect().
    If you plan to use it and its performance is critical, use 
    other technique than RRCollider::IT_LINEAR.

 -  Implement your own RRObject and
    create its instance for every static object in your scene.
    \n\n
    By objects we understand identical meshes placed on different
    positions in scene, possibly using different materials (e.g. several
    cars with the same geometry, different position and possibly different color;
    they are different objects sharing one mesh).
    \n\n
    Default RRMesh::getTriangleMapping() returns realtime generated
    unwrap of low quality, for serious use of ambient maps, you should override
    RRMesh::getTriangleMapping() and provide your own unwrap.
    This is not necessary if you use vertex arrays and don't need lightmaps.
    \n\n
    Once you have RRObject instance, most convenient way to remember it
    for later use is to attach it to your object.





\page integration_step_4 Subclass RRDynamicSolver

 RRDynamicSolver is global illumination solver.
 For offline rendering, it is complete and it can be used immediately.
 For realtime rendering, subclass RRDynamicSolver and implement
 tasks specific for your renderer.

 \section step4_gl OpenGL

 rr_gl::RRDynamicSolverGL, subclass of RRDynamicSolver
 already implements GPU tasks using OpenGL.
 If you plan to use OpenGL realtime renderer (Lightsprint or any other),
 subclass RRDynamicSolverGL and implement one or more of these simple functions:

 - rr_gl::RRDynamicSolverGL::renderScene()
   \n Render your scene into shadowmap.

 - rr_gl::RRDynamicSolverGL::setupShader() [optional]
   \n Only for custom shader based lights.
   \n Set shader so that direct light+shadows+emissivity are rendered, but other
      material properties (diffuse texture etc) are ignored.

 See example implementation in RealtimeRadiosity sample.

 \section step4_dx Direct3D

 If you need global illumination in Direct3D renderer,
 it is possible to subclass directly RRDynamicSolver,
 and avoid any dependency on OpenGL.
 The only task in this scenario is described in \ref integration_step_6





\page integration_step_5 Use RRDynamicSolver subclass

 RRDynamicSolver class is your primary interface to Lightsprint engine.
 To add global illumination to your application,

 - Create instance of RRDynamicSolver or your subclass.
   (why subclass? described in \ref integration_step_4)

 - To start calculation,
   call RRDynamicSolver::setStaticObjects() with set of static objects participating in calculation.
   This call is expensive, design your application to avoid
   frequent changes of static scene.

 - Set lights, call RRDynamicSolver::setLights() with set of lights participating in calculation.
   Optionally call also RRDynamicSolver::setEnvironment() to add outdoor/sky lighting.
   These calls are cheap, you can change lights frequently.

 - 
 - Call RRDynamicSolver::calculate() often. If main loop of your
   application contains rendering of one frame, add one call to RRDynamicSolver::calculate().
   If you render scene only when it has changed,
   still call RRDynamicSolver::calculate() in every iteration of main loop,
   but if it returns IMPROVED, rerender scene.

 - If you use vertex/pixel buffers for rendering:
   \n When RRDynamicSolver::getSolutionVersion() changes,
   call RRDynamicSolver::updateLightmaps()
   to update illumination values stored in vertex/pixel buffers.

 - Call RRDynamicSolver::reportDirectIlluminationChange() whenever direct illumination changes.
   It is mainly when light moves or changes properties, but for higher precision,
   you may call it also when lit object moves and its shadow changes.

 - Call RRDynamicSolver::reportMaterialChange() whenever materials used in scene change.

 - Call RRDynamicSolver::reportInteraction() whenever user interacts or other reason for
   high responsiveness exists. Without reportInteraction calls, solver takes more CPU time
   and FPS decreases.

 - Call RRDynamicSolver::getIllumination() 
   to acquire static object's illumination, see \ref data_vertex_buffer and \ref data_pixel_buffer.

 - Call RRDynamicSolver::updateEnvironmentMap()
   to acquire static or dynamic object's illumination, see \ref data_environment_map.

 Nearly all of these calls are demonstrated in RealtimeRadiosity sample.





\page integration_step_6 Detect direct illumination

 For OpenGL based renderers, 
 LightsprintGL implements detection of direct illumination
 in rr_gl::RRDynamicSolverGL.

 For Direct3D and custom renderers, you need to reimplement
 detection of direct illumination.

 <b>What needs to be detected:</b> average color of each face;
 how does it look lit by your direct (not ambient) point, spot and directional lights
 and shadowed by your shadows.

 <b>What to do with detected values:</b> call RRDynamicSolver::setDirectIllumination().

 <b>Why is it important:</b> we have no other knowledge about your lights.
 You can use many light types with very complex lighting equations.
 You can arbitrarily change them. No problem. Just let us know what are the results -
 average colors produced by your shader.

 <b>How to implement it:</b> turn off ambient/radiosity, render all scene faces,
 read rendered image to system memory and extract average color for each face.
 This is the most simple and universal approach (works with any number of any lights),
 however you can think about alternatives. This depends highly on your renderer.

 \image html detect-dif.png
 Image shows arrangement of faces in matrix that makes extraction of average color/exitance simple.
 It wouldn't help to render faces in their original 3d positions, some would be probably
 hidden behind other faces. You can see that some faces are black, those are partially
 in shadow or completely unlit.
 You can also see that only 50% of texture space is used, triangles may be rearranged so that
 100% of space is used, however averaging face color would become more expensive.

 <b>Possible implementation in detail:</b> rendering faces into matrix
 requires one renderer enhancement - 2d position override - ability to render
 triangles to specified 2d positions while preserving their original look.

 For DX10 generation GPUs, solution is nearly as simple
 as adding two lines into geometry shader.
 Render as usual, using any combination of trilist/strip/indexed/nonindexed data,
 but at the end of geometry shader, override
 output vertex positions passed to rasterizer by new 2d triangle positions
 calculated right there from primitive id.

 For DX9 generation GPUs, implemention has two steps:
 - Triangle positions in matrix are generated by CPU into new vertex stream.
   At the end of vertex shader, vertex position passed to fragment shader is replaced by
   position read from additional vertex stream.
 - For purpose of detection, scene is rendered using non-indexed triangle list.
   This is necessary because if we want to render triangles with shared
   vertices to completely different positions in texture, we have to split 
   that vertices.

 <i>
 <b>Possible optimizations:</b>

 <b>Rendering irradiance:</b>
 For simple materials with diffuse texture only (such as in .3ds),
 process can be optimized by ignoring diffuse textures, thus rendering incoming light
 not multiplied by diffuse texture.
 Detected average face colors then correspond to intensity of light reaching 
 face (irradiance) instead of intensity of light leaving face (exitance),
 so detected color is passed to RRObjectAdditionalIllumination::setTriangleAdditionalMeasure
 as RM_IRRADIANCE, rather than RM_EXITANCE.

 \image html detect-nodif.png
 Image above shows optimized detection, faces are not modulated by material,
 so irradiance is detected. You can see mostly white faces, because scene is lit by white spotlight.
 Few orange pixels come from orange logo projected by spotlight.

 Optimized approach is not suitable for engines with texture atlases.
 If your material properties change very significantly over uv space,
 use original unoptimized approach for higher precision.

 <b>GPU averaging:</b>
 To decrease amount of data transferred from GPU to CPU and speed up
 whole process, it is recommended to calculate average triangle colors
 on GPU, using simple shader, write them into smaller texture
 and transfer this smaller textue to CPU.
 LightsprintGL does it using scaledown_filter.* shaders.

 \image html detect-scaled.png
 Image was scaled down by scaledown_filter.* shaders for purpose of
 faster primary illumination detection.
 It is resized back to original size only in this documentation.

 </i>




\page main_data_access Calculation and outputs

 \section calc_1 Lightsprint can calculate
  - \subpage data_illumination
  - \subpage data_ambient_occlusion
  - \subpage data_bent_normals

 \section calc_2 and store them in object's
  - \subpage data_vertex_buffer
  - \subpage data_pixel_buffer
  - \subpage data_environment_map

 \section calc_3 or quickly return single value for given
  - \subpage data_triangle
  - \subpage data_ray

 \section calc_0 Capabilities by speed
  - \subpage calc_realtime
    - \subpage calc_fireball
  - \subpage calc_offline

 Lightsprint is very flexible; for any object, it lets you create optimal
 structures that precisely match your quality/memory footprint requirements.
 For example, you can use pixel buffers only for objects that benefit from per-pixel details,
 use vertex buffers for the rest. You can mix formats even in single object,
 e.g. give it per-pixel lightmap with 8bit RGBA channels and sRGB space
 and per-vertex bent normals with floating point RGB channels and linear space.
 When (empty) buffers are created, single RRDynamicSolver::updateLightmaps()
 call fills them.

 Lightsprint automatically uses all processing power available in a single computer,
 it runs in multiple threads on all CPUs and CPU cores.

 \section calc_distributed Distributed calculation

 Lightsprint is ready for distribution of work in network / multiple computers,
 including computers without GPU. Expensive RRDynamicSolver::updateLightmaps() call
 (it is core of all lightmap, ambient occlusion map and bent normal map calculations)
 can be replaced by many small RRDynamicSolver::updateLightmap() calls
 and you are free to execute them in parallel on different computers.

 In more detail, you can run many clients that do
 \code
	RRDynamicSolver solver;
	solver.setStaticObjects(objects);
	solver.setLights(lights);
	solver.setEnvironment(environment);
	RRDynamicSolver::UpdateParameters params;
	params.quality = 1000;
	params.applyCurrentSolution = false;
	params.applyEnvironment = true;
	params.applyLights = true;
	solver.updateLightmaps(-1,-1,-1,&params,&params,NULL);
	params.applyCurrentSolution = true;
	params.measure_internal.direct = true;
	while(!done)
	{
		unsigned objectIndex = ...; //get object that was not updated yet
		RRBuffer* lightmap = RRBuffer::create(...);
		solver.updateLightmap(objectIndex,lightmap,NULL,NULL,&params);
		lightmap->save(filename);
		delete lightmap;
	}
 \endcode



\page data_illumination Illumination

 \section di1 Directional lightmaps / vertex colors

  While building lightmaps, Lightsprint gathers information about light directions.
  This information is optionally returned in two formats.

  1. Directional component is stored as 3 separated lightmaps or vertex buffers
  built as if surface normals are modified in 3 different directions.
  Result is compatible with Unreal Engine 3 directional lightmaps.
  3 lightmaps are sufficient for rendering, but together with standard non-directional
  lightmap (=fourth direction), all 4 lightmaps can be used for even higher precision.

  2. Directional component of lightmap or vertex buffer is stored separately 
  from irradiance component. See \ref data_bent_normals for
  details on directional component.

 \section di2 Global illumination lightmaps

  Global illumination lightmaps are precomputed with
  infinite light bounces, color bleeding and physically
  correct penumbra shadows from area lights.
  For mostly static scenes, precomputed GI lightmaps make very good sense.

  Global illumination usually contains sharp shadow edges,
  so it's not practical to store it per vertex in vertex buffer
  (result would be too blurry).

 \section di3 Ambient maps, per-vertex ambient

  Ambient maps and per-vertex ambient contain indirect component of illumination
  with infinite light bounces, color bleeding and indirect shadows;
  it's complete global illumination except for first light bounce.

  In scenarios with mixed static / dynamic objects, it's often
  advantageous to compute indirect illumination only
  and mix it with realtime rendered direct illumination
  with direct shadows.

  Per-pixel or per-vertex?
  \n
  Unlike global illumination, indirect illumination
  doesn't contain sharp shadow edges, so it's usually practical
  to store it per-vertex in vertex color buffer.
  Per-vertex ambient is slightly less precise in some situations,
  but it usually takes much less memory,
  so it's worth considering in memory restricted environments.
  In realtime scenarios, per-vertex ambient is preferred for
  higher speed over ambient maps.

  Ability to generate ambient maps or per vertex ambient is
  <b>fundamental for realtime global illumination</b>.
  To render realtime global illumination,
  start with renderer with direct illumination and shadows
  and add ambient map or per vertex ambient 
  computed by Lightsprint. Realtime per-vertex ambient is preferred
  for much higher speed.

 \section di4 Environment maps

  Environment maps store light incoming from all directions
  to single point in space. They are usually used to approximate
  light incoming to dynamic object.
  \n
  Environment maps may be processed so that single environment
  map lookup returns light incoming from single direction
  (specular environment map)
  or from whole hemisphere (diffuse environment map).

  See \ref data_environment_map for more details.

 \section di5 Other

  Outside most widely used global illumination lightmaps,
  per vertex ambient, ambient maps and environment maps,
  Lightsprint supports many other illumination types suitable for specific
  situations.
  Depending on parameters you pass to lighting calculation process,
  you can get direct only lighting, mix of independently
  enabled direct and indirect lighting from many light source types
  etc, with result stored in texture or vertex buffer, with optional
  directional component.
            
 \section di6 Data structures

  Lightsprint can store object's illumination in

  - <b> \ref data_vertex_buffer </b>

  - <b> \ref data_pixel_buffer </b>

  - <b> \ref data_environment_map </b>

 \section di7 Calculation

  Calculation of illumination is realtime or non-realtime process,
  depending on parameters set.
  Environment maps are always computed in realtime speeds.

  See data structures (links above) for more details on calculation.

 \section di8 Use in renderer

   See data structures (links above) for more details on use in renderer.



\page data_ambient_occlusion Ambient occlusion

 \section da1 [Direct] ambient occlusion

  Ambient occlusion on <a href="http://en.wikipedia.org/wiki/Ambient_occlusion">Wikipedia</a>

  [Direct] ambient occlusion is a function of a surface point and a surrounding geometry,
  with return value in 0..1 space,
  0 for surface point fully occluded by surrounding geometry
  and 1 for completely unoccluded point.

  [Direct] ambient occlusion is a result of direct illumination
  in a uniform white environment.

 \section da2 Global ambient occlusion

  Sometimes ambient occlusion is desired to include effect of
  multiple light bounces and color bleeding.
  Let's call it global ambient occlusion.
  \n
  Global ambient occlusion is a function with return value in 0..inf space,
  but with typical values inside 0..1 range.
  \n
  Lightsprint supports global AO equally well as direct AO,
  so all that we say about AO matters for both direct and global AO.

 \section da3 Directional ambient occlusion

  Information about direction of incoming light can be precomputed and used
  in the same way as in case of classical lightmaps.
  See \ref di1 for more details.

 \section da3 Data structures

  Lightsprint can store object's ambient occlusion and global ambient occlusion in

  - <b> \ref data_vertex_buffer </b>

  - <b> \ref data_pixel_buffer </b>

 \section da4 Calculation

  Calculation of ambient occlusion is non-realtime process.
  To calculate ambient occlusion,
  - Create RRDynamicSolver
  - Set geometry with RRDynamicSolver::setStaticObjects().
    Set single object here for single object ambient occlusion.
    If you set scene with multiple objects here, each object will be
    occluded by all other objects.
  - Set uniform white environment with RRDynamicSolver::setEnvironment(RRBuffer::createSky())
  - Call RRDynamicSolver::updateLightmaps() with
    \n paramsDirect.applyCurrentSolution=false
    \n paramsDirect.applyLights=false
    \n paramsDirect.applyEnvironment=true
    \n and paramsIndirect=NULL
    \n To calculate global ambient occlusion,
       set paramsIndirect equally to paramsDirect.

  See data structures (links above) for more details on calculation.

 \section da5 Use in renderer

   See data structures (links above) for more details on use in renderer.



\page data_bent_normals Bent normals

 \section db1 Bent normals

  Bent normals on <a href="http://en.wikipedia.org/wiki/Ambient_occlusion">Wikipedia</a>

  Bent normals store negation of incoming light direction,
  in world space.
  Light may come to surface point form many directions
  in different intensities, so bent normals average all directions,
  taking light intensity into account.
  \n
  Bent normals are normalized.

 \section db2 Data structures

  Lightsprint can store object's bent normals in

  - <b> \ref data_vertex_buffer </b>

  - <b> \ref data_pixel_buffer </b>

  Bent normals stored in pixel buffer
  are automatically transformed from -1..1 space to 0..1 space to support
  save to unsigned RGB textures.
  When reading bent normal from such texture,
  get original world space normal as bn*2-1.

 \section db3 Calculation

  Calculation of bent normals is non-realtime process.
  To calculate bent normals, use RRDynamicSolver::updateLightmaps()
  and set bent normal layer accordingly.

  Bent normals are intentionally stored in different layer than ilumination,
  so you can reuse single bent normal layer with multiple illumination layers
  to save memory or storage space (at cost of slightly reduced precision).

  See data structures (links above) for more details on calculation.

 \section db4 Use in renderer

  Bent normals are optional enhancement of precomputed illumination.
  They are used in rendering to make specular
  reflections and normal maps look more realistically,
  even with lighting precomputed in lightmaps.

  See data structures (links above) for more details on rendering.



\page data_vertex_buffer Vertex buffer

 Vertex buffer is designed for storage of per-vertex data for single object.

 \section d11 Suitable for
   <table>
    <tr><th></th>                                 <th>global or direct or indirect illumination</th> <th>ambient occlusion</th> <th>bent normals</th> </tr>
    <tr><th>static objects</th>                   <td>YES</td> <td>YES</td> <td>YES</td> </tr>
    <tr><th>dynamic objects</th>                  <td>NO </td> <td>YES</td> <td>YES</td> </tr>
    <tr><th>realtime calculated illumination</th> <td>YES</td> <td>NO </td> <td>NO </td> </tr>
    <tr><th>precalculated illumination</th>       <td>YES</td> <td>YES</td> <td>YES</td> </tr>
   </table>

 \section d12 Advantages
   - Compact representation. It requires only few bytes per vertex.
     Samples store illumination as 3 floats, but it can be switched to 4 bytes,
     arbitrary compression can be added.
   - Fast rendering.
     No sampler resources are consumed.
     It can be arbitrarily postprocessed in vertex shader.
     You can have multiple layers of precalculated indirect illumination 
     and mix them at no cost in vertex shader according to changes in scene.
   - There is no need to change your lightning equation,
     simply use our ambient data instead of constant ambient.
   - If you don't precompute bent normals, ambient lighting values
     don't depend on view angle, so rendering is very fast.
   - If you do precompute bent normals, normal maps work great even in shadows,
     knowing direction of incoming indirect light.

 \section d13 Disadvantages
   - Details are missing in areas without vertices.
     For good results, you have to add vertices to places where you miss details.
   - Seams around T vertices and other degenerated geometries.
     You have to make your meshes clean, avoid degeneracies.
   - Long narrow triangles (needles) often create visible artifacts.
     This is often problem also for physical engine,
     so your 3d artisis probably know they should avoid needles.

 \section d15 Interface
   - RRBuffer

 \section d14 Instances
   - stored in: RRDynamicSolver::getIllumination()->getLayer()
   - created by: you
   - updated by: RRDynamicSolver::updateLightmaps()
     or RRDynamicSolver::updateLightmap().

 \section d16 Rendering with
   - Stream data from vertex buffer into vertex shader, interpret them
     in shader appropriately as light level, ambient occlusion or bent normal.

 \section d17 Examples
   - Generic example:
     \n Creating vertex buffer.
     \code
	vertexBuffer = rr::RRBuffer::create(rr::BT_VERTEX_BUFFER,numVertices,1,1,rr::BF_RGBF,NULL);
     \endcode
   - OpenGL example:
     \n Rendering with per vertex ambient.
     \code
	rr::RRDynamicSolver* dynamicSolver;
	GLuint program;
	...
	// set program created from shaders below
	glUseProgram(program);
	// get vertex buffer with indirect illumination
	rr::RRBuffer* vertexBuffer = dynamicSolver->
		getIllumination(numberOfObject)->getLayer(0);
	// enable stream with color values
	glEnableClientState(GL_COLOR_ARRAY);
	// set pointer to color data for first vertex
	glColorPointer(3, GL_FLOAT, 0, vertexBuffer->lock(rr::BL_READ));
	// render primitives
	glDrawElements...
	// cleanup
	vertexBuffer->unlock();
	glDisableClientState(GL_COLOR_ARRAY);
     \endcode
     Using ambient value in GLSL vertex shader:
     \code
	varying vec3 ambientLight;
	void vertexShader()
	{
		...
		ambientLight = gl_Color;
	}
     \endcode
     Using ambient value in GLSL fragment shader:
     \code
	varying vec3 ambientLight;
	void fragmentShader()
	{
		...
		gl_FragColor = ... + materialColor * vec4(ambientLight.xyz,0.0);
	}
     \endcode
   - Direct3D 9 example:
     \n Rendering with per vertex ambient.
     \code
	IDirect3DDevice9* device;
	IDirect3DPixelShader9* vertexShader;
	IDirect3DPixelShader9* pixelShader;
	// adapt your vertex declaration, let your mesh read data from stream 0
	// and add e.g. COLOR1 read from stream 1
	IDirect3DVertexDeclaration9* vertexDeclaration;
	device->CreateVertexDeclaration(description, &vertexDeclaration);
	...
	// create d3d vertex buffer and fill it with vertexBuffer->lock() data
	rr::RRBuffer* vertexBuffer = dynamicSolver->
		getIllumination(numberOfObject)->getLayer(0);
	IDirect3DVertexBuffer9* d3dBuffer = ...;
	// to prevent data duplication and copying, implement RRBuffer
	//  that stores vertex data directly into d3d vertex buffer
	...
	// set rendering pipeline to use shaders below
	device->SetPixelShader(vertexShader);
	device->SetPixelShader(pixelShader);
	// activate previously created vertex declaration
	device->SetVertexDeclaration(vertexDeclaration);
	// set pointer to your mesh (vertices, possibly normals etc.) in stream 0
	device->SetStreamSource(0, ...);
	// set pointer to vertex illumination data in stream 1
	device->SetStreamSource(1, d3dBuffer, ...);
	// render primitives
	device->DrawPrimitive...
	// cleanup
	device->SetStreamSource(1, NULL, 0, 0);
	device->SetStreamSource(0, NULL, 0, 0);
     \endcode
     Using ambient value in HLSL vertex shader:
     \code
	void vertexShader(in float3 iAmbientLight: COLOR1,
		..., out float3 oAmbientLight: COLOR1)
	{
		...
		oAmbientLight = iAmbientLight;
	}
     \endcode
     Using ambient value in HLSL pixel shader:
     \code
	void pixelShader(in float3 iAmbientLight: COLOR1,
		..., out float4 oColor: COLOR)
	{
		...
		oColor = ... + materialColor * float4(iAmbientLight,0);
	}
     \endcode
   - Alternatively, applying colors from vertex buffer could be done in fixed pipeline,
     without shaders, but it is beyond scope of this documentation.
   - See Direct3D, OpenGL or your engine documentation for more details
     on streaming per vertex data to vertex shader and rendering with ambient light,
     ambient occlusion or bent normals.



\page data_pixel_buffer Pixel buffer

 Pixel buffer (2d texture) is designed for storage of per-pixel data 
 for single object (Light map, Ambient occlusion map, Bent normal map).

 \section d21 Suitable for
   <table>
    <tr><th></th>                                 <th>global or direct or indirect illumination</th> <th>ambient occlusion</th> <th>bent normals</th> </tr>
    <tr><th>static objects</th>                   <td>YES</td> <td>YES</td> <td>YES</td> </tr>
    <tr><th>dynamic objects</th>                  <td>NO </td> <td>YES</td> <td>YES</td> </tr>
    <tr><th>realtime calculated illumination</th> <td>NO </td> <td>NO </td> <td>NO </td> </tr>
    <tr><th>precalculated illumination</th>       <td>YES</td> <td>YES</td> <td>YES</td> </tr>
   </table>

 \section d22 Advantages
   - High precision and detail without additional vertices.
   - No need for good triangulation.
   - Very low resolution is sufficient (with good unwrap) for ambient maps
     (lightmaps with indirect illumination).
     Ambient maps contain mostly low frequencies, no sharp edges.
   - If you don't precompute bent normals, ambient lighting values
     don't depend on view angle, so rendering is very fast.
   - If you do precompute bent normals, normal maps work great even in shadows,
     knowing direction of incoming indirect light.

 \section d23 Disadvantages
   - You need additional uv channel with object's unwrap (for lightmap mapping).
     If you don't have it, ask your 3d artists
     to bake unwrap into meshes as an additional uv channel.
     Unwraps are often genrated automatically, using existing free or commercial tools.

 \section d25 Interface, implementations
   - RRBuffer

 \section d24 Instances
   - stored in: RRDynamicSolver::getIllumination()->getLayer()
     or your arbitrary location.
   - created by: you
   - updated by: RRDynamicSolver::updateLightmaps()
     or RRDynamicSolver::updateLightmap().

 \section d26 Rendering
   - Map pixel buffer to your object using your uv channel with object's unwrap,
     read per-pixel value from texture in pixel shader
     and interpret it appropriately as light level, ambient occlusion or bent normal.

 \section d27 Examples
   - Generic example:
     \n Providing access to unwrap in your implementation of rr::RRMesh interface.
     \code
	// access to uv channel with object's unwrap
	void YourImplementationOfRRMesh::getTriangleMapping(
		unsigned t, TriangleMapping& out) const
	{
		for(unsigned v=0;v<2;v++)
		{
			// copy uv baked with your mesh
			// for vertex v (v=0..2) in triangle t
			out.uv[v][0] = ...; // u coordinate
			out.uv[v][1] = ...; // v coordinate
		}
	}
     \endcode
     \n Creating lightmap.
     \code
	lightmap = rr::RRBuffer::create(rr::BT_2D_TEXTURE,256,256,1,rr::BF_RGBF,NULL);
     \endcode
   - OpenGL example:
     Rendering with lightmap.
     \code
	rr::RRDynamicSolver* dynamicSolver;
	GLuint program;
	...
	// set program created from shaders below
	glUseProgram(program);
	// bind lightmap to texture0
	glActiveTexture(GL_TEXTURE0);
	getTexture(dynamicSolver->getIllumination(numberOfObject)->
		getLayer(0))->bindTexture();
	// set sampler to use texture0
	glUniform1i(glGetUniformLocation(program,"lightmap"),0);
	// enable stream with texture coordinates
	glEnableClientState(GL_TEXTURE_COORD_ARRAY);
	// set pointer to texture coordinates
	glColorPointer(2, GL_FLOAT, 0, array with uv values of unwrap);
	// render primitives
	glDrawElements...
	// cleanup
	glDisableClientState(GL_TEXTURE_COORD_ARRAY);
     \endcode
     Using uv coordinates in GLSL vertex shader:
     \code
	varying vec2 lightmapCoord;
	void vertexShader()
	{
		...
		lightmapCoord = gl_TexCoord.xy;
	}
     \endcode
     Sampling and using illumination value in GLSL fragment shader:
     \code
	uniform sampler2D lightmap;
	varying vec2 lightmapCoord;
	void fragmentShader()
	{
		vec4 light = texture2D(lightmap, lightmapCoord);
		...
		gl_FragColor = ... + materialColor * light;
	}
     \endcode
   - Direct3D 9 example:
     Rendering with lightmap.
     \code
	IDirect3DDevice9* device;
	IDirect3DPixelShader9* vertexShader;
	IDirect3DPixelShader9* pixelShader;
	// create vertex declaration that includes lightmap uv channel as TEXCOORD0
	IDirect3DVertexDeclaration9* vertexDeclaration;
	device->CreateVertexDeclaration(description, &vertexDeclaration);
	rr::RRDynamicSolver* dynamicSolver;
	...
	// set rendering pipeline to use shaders below
	device->SetPixelShader(vertexShader);
	device->SetPixelShader(pixelShader);
	// set sampler to use lightmap
	rr::RRBuffer* lightmap = dynamicSolver->
		getIllumination(numberOfObject)->getLayer(0);
	...
	// set vertex declaration for your mesh data,
	//  including uv channel with unwrap
	device->SetVertexDeclaration(vertexDeclaration);
	// set pointer to your mesh in stream 0
	//  (vertices, uv channel, possibly normals etc.)
	device->SetStreamSource(0, ...);
	// render primitives
	device->DrawPrimitive...
	// cleanup
	device->SetStreamSource(0, NULL, 0, 0);
     \endcode
     Using uv coordinates in HLSL vertex shader:
     \code
	void vertexShader(in float2 iLightmapCoord: TEXCOORD0,
		..., out float2 oLightmapCoord: TEXCOORD0)
	{
		...
		oLightmapCoord = iLightmapCoord;
	}
     \endcode
     Sampling and using illumination value in HLSL pixel shader:
     \code
	sampler lightmap;
	void pixelShader(in float2 iLightmapCoord: TEXCOORD0,
		..., out float4 oColor: COLOR)
	{
		float4 light = tex2D(lightmap, iLightmapCoord);
		...
		oColor = ... + materialColor * light;
	}
     \endcode
   - Alternatively, texturing could be done in fixed pipeline,
     without shaders, but it is beyond scope of this documentation.
   - See Direct3D, OpenGL or your engine documentation for more details
     on texturing and rendering with lightmap.
  


\page data_environment_map Environment map

 Environment map (cube texture) is designed for global illumination of single object.

 \section d31 Suitable for
   - static objects: YES
   - dynamic objects: YES
   - realtime calculated illumination: YES
   - precalculated illumination: YES

 \section d32 Advantages
   - offers global illumination with both specular and diffuse reflections
   - object doesn't have to be part of static scene, no RRObject adapter is required
   - calculation is independent to object complexity, quick even for extremely complex objects

 \section d33 Disadvantages
   - precision decreases with size of object, suitable for characters and items, not for buildings
   - complexity of objects doesn't matter, but count of environment map updates does,
     so if you need large clouds/crowds of dynamic objects visible all at once,
     share one environment map for several close objects and update it only once
     to save time

 \section d35 Interface, implementations
   - RRBuffer

 \section d34 Instances
   - stored in: RRObjectIllumination::diffuseEnvMap and RRObjectIllumination::specularEnvMap or your arbitrary location
   - created by: you
   - updated by: RRDynamicSolver::updateEnvironmentMap()

 \section d36 Rendering
   - Many rendering techniques are based on faked precomputed environment maps.
     Here you get realtime computed environment maps, and you are free to use them
     for any purpose.
   - Request environment (cube) map to be generated in center of your object.
     Environment map may be later used by GPU to add global illumination 
     to diffuse and specular surfaces close to given point in space.
   - We propose you several techniques:
     \n
     For rough surface with mostly <b>diffuse</b> reflection,
     read value from diffuse environment map, using 'surface normal' as a coordinate.
     This single instruction gives you global illumination of pixel.
     Multiply it by material diffuse color to get final color.
     Size 4 of environment map is sufficient for close objects and 2 for distant ones.
     \n
     For smooth surface with <b>specular</b> reflection,
     read value from specular environment map, using
     'eye direction reflected by surface' as a coordinate.
     These few instructions give you global illumination of pixel.
     Don't modulate it by material color unless you want to render
     exotic materials, you already have final color.
     Size 16 of environment map simulates smooth surfaces, size 4 simulates rough
     surface.
     \n
     You can use <b>specular map</b> to select per pixel which one
     of two techniques to use or how to mix both together.
     \n
     You can use <b>normal map</b> to modulate surface normal.
     Both diffuse and specular surfaces respond well to normal maps.
     \n
     LightsprintGL implements all of these techniques.
   - Global illumination can be further improved if you use <b>ambient occlusion map</b>
     for your dynamic object. Multiply global illumination read from environment map
     by ambient occlusion read from ambient occlusion map to get more precise result.
     Ambient occlusion maps are computed for example by AmbientOcclusion sample.

 \section d37 Examples
   - OpenGL example:
     \n Rendering with environment maps.
     \code
	rr::RRDynamicSolver* solver;
	rr::RRObjectIllumination* illumination;
	GLuint program;
	...
	// update environment maps
	solver->updateEnvironmentMap(illumination);
	// set program created from shader below
	glUseProgram(program);
	// bind diffuse environment map to texture0
	// it calls glBindTexture(GL_TEXTURE_2D,map);
	glActiveTexture(GL_TEXTURE0);
	rr_gl::getTexture(illumination->diffuseEnvMap)->bindTexture();
	// set sampler to use texture0
	glUniform1i(glGetUniformLocation(program,"diffuseEnvironmentMap"),0);
	// bind specular environment map to texture1
	glActiveTexture(GL_TEXTURE1);
	rr_gl::getTexture(illumination->specularEnvMap)->bindTexture();
	// set sampler to use texture1
	glUniform1i(glGetUniformLocation(program,"specularEnvironmentMap"),1);
	// render primitives
	glDrawElements...
     \endcode
     Applying environment maps in GLSL fragment shader:
     \code
	uniform samplerCube specularEnvironmentMap;
	uniform samplerCube diffuseEnvironmentMap;
	void fragmentShader()
	{
		// normal in world space, you may apply normal map here
		vec3 worldNormal = ...;
		// view vector in world space = position of fragment - position of camera
		vec3 worldView = ...;
		// reflected view vector in world space
		vec3 worldViewReflected = reflect(worldView,worldNormal);
		...
		gl_FragColor = ...
			// diffuse reflection
			+ materialDiffuseReflectance *
			  textureCube(diffuseEnvironmentMap, worldNormal)
			// specular reflection
			+ materialSpecularReflectance *
			  textureCube(specularEnvironmentMap, worldViewReflected);
	}
     \endcode
   - Direct3D 9 example:
     \n Rendering with environment maps.
     \code
	IDirect3DDevice9* device;
	IDirect3DPixelShader9* pixelShader;
	rr::RRDynamicSolver* solver;
	rr::RRObjectIllumination* illumination;
	...
	// update environment maps
	solver->updateEnvironmentMap(illumination);
	// set rendering pipeline to use shader below
	device->SetPixelShader(pixelShader);
	// set samplers to use environment maps
	...
	// render primitives
	device->DrawPrimitive...
     \endcode
     Applying environment maps in HLSL pixel shader:
     \code
	samplerCUBE specularEnvironmentMap;
	samplerCUBE diffuseEnvironmentMap;
	void pixelShader(..., out float4 oColor: COLOR)
	{
		// normal in world space, you may apply normal map here
		float3 worldNormal = ...;
		// view vector in world space = position of fragment - position of camera
		float3 worldView = ...;
		// reflected view vector in world space
		float3 worldViewReflected = reflect(worldView,worldNormal);
		...
		oColor = ...
			// diffuse reflection
			+ materialDiffuseReflectance *
			  texCUBE(diffuseEnvironmentMap, worldNormal)
			// specular reflection
			+ materialSpecularReflectance *
			  texCUBE(specularEnvironmentMap, worldViewReflected);
	}
     \endcode
   - See Direct3D, OpenGL or your engine documentation for more details
     on texturemapping and applying environment maps.




\page data_triangle Triangle or Vertex

 Triangle or Vertex illumination query is designed for AI
 and other subsystems that need very fast access to single value
 (e.g. AI trying to find dark corner for hiding).

 \section d41 Suitable for
   - static objects: YES
   - dynamic objects: NO
   - realtime calculated illumination: YES
   - precalculated illumination: YES

 \section d42 Advantages
   - If you need information only for small subset of scene,
     querying single triangle is much faster
     than generating complete lightmap or vertex color buffer for whole object
     and reading value from it.
   - Even if you have lightmap or vertex buffer generated,
     it could be easier to use this query than searching
     individual value in vertex buffer/lightmap.

 \section d43 Disadvantages
   - Not demonstrated in samples yet.

 \section d44 Query
   - Call RRDynamicSolver::getTriangleMeasure with vertex=0,1,2 for triangle vertices
   - Call RRDynamicSolver::getTriangleMeasure with vertex>2 for whole triangle area
   - Reading illumination level from triangle is slightly faster than reading
     it from vertex, but both are very fast.

 \section d45 Returned value
   - RRVec3 with single illumination value
   - see \ref gunits




\page data_ray Ray

 Query for illumination at the end of ray is designed for AI
 and other subsystems that need very fast access to single value
 (e.g. AI trying to find dark corner for hiding).

 \section d51 Suitable for
   - static objects: YES
   - dynamic objects: NO
   - realtime calculated illumination: YES
   - precalculated illumination: YES

 \section d52 Advantages
   - Fast access to single value.

 \section d53 Disadvantages
   - Not demonstrated in samples yet.

 \section d54 Query
   - Call RRDynamicSolver::getMultiObjectCustom()->getCollider()->intersect()
     to find static triangle at the end of ray.
   - See \ref data_triangle for access to triangle's illumination.

 \section d55 Returned value
   - RRVec3 with single illumination value
   - see \ref gunits




\page calc_fireball Fireball

 \section fb_features Features
  Fireball is realtime global illumination solver, it produces realistic indirect lighting in dynamic scenes.
  It is recommended for use in games.

  If you don't start Fireball,
  \ref calc_realtime works without any precalculations (and \ref calc_offline work too).
  \n If you start Fireball, only realtime lighting works, but it is 
  - faster (1.2-5x higher fps in standard situations)
  - smaller (needs only 50% of memory for the same quality)
  - produces higher quality lighting
  - doesn't allocate/fragment memory

 \section fb_precalc Precalculations
  Fireball uses precalculation phase in which static scene is analyzed and one file is saved.
  This is usually done by developer at development time, final game only loads the file.

 \section fb_calculation Calculation
  Fireball uses the same API as the rest of Lightsprint SDK.
  Usually no changes in code are needed to start using Fireball,
  except for one additional call, see:
  - RRDynamicSolver::buildFireball()
  - RRDynamicSolver::loadFireball()

 \section fb_outputs Outputs
  Fireball calculates indirect illumination and stores it into 
  \ref data_vertex_buffer for static objects and
  \ref data_environment_map for dynamic objects.

 \section fb_sample Sample
  Fireball is demonstrated in RealtimeRadiosity sample.
  \n When Fireball file is not found, it is built automatically.
  In this sample, it takes approximately 3 seconds.



\page calc_realtime Realtime lighting

 \section rt_features Features
  Lightsprint uses the same API for both realtime and \ref calc_offline.
  Naturally only subset of functions is fast enough to be used in realtime.
  \n Features designed for realtime use include:
  - calculate global illumination in dynamic scenes
  - update \ref data_vertex_buffer with indirect lighting for static objects
  - update \ref data_environment_map with indirect lighting for dynamic objects

 \section rt_precalc Optional precalculations
  Realtime rendering with global illumination is available immediately after
  new scene is loaded, no preprocessing/precalculations are needed.

  However, better results are possible with \ref calc_fireball.
  It uses precalculation phase in which static scene is analyzed.
  It takes some time, but then rendering is faster and quality higher.

 \section rt_sample Sample
  Realtime lighting is demonstrated in RealtimeRadiosity sample.
  You can comment out block that enables \ref calc_fireball to compare both realtime solvers.


 
\page calc_offline Offline calculations

 \section of_features Features
  All Lightsprint SDK features documented in \ref main_data_access are available
  for offline calculations.

  Note that some offline featues are disabled if you load \ref calc_fireball for realtime lighting.

 \section of_sample Samples
  Offline calculations are demonstrated in CPULightmaps and AmbientOcclusion samples.
  CPULightmaps is purely console application,
  AmbientOcclusion displays results in simple interactive viewer.



\page main_platforms Supported platforms

 Platforms
 - Windows (XP, Vista, 32bit, 64bit)
 - Linux (32bit, 64bit)
 - Playstation 3
 - Xbox 360

 GPUs on PC
 - NVIDIA GeForce 5xxx, 6xxx, 7xxx, 8xxx, 9xxx, 2xx
 - AMD (ATI) Radeon 9500-9800, Xxxx, X1xxx, HD2xxx, HD3xxx, HD4xxx
 - mobile versions of GPUs above (GeForce Go, Mobility Radeon)
 - subset of workstation versions (Quadro, FireGL)
 - for offline rendering, GPU is not needed

 3D APIs
 - OpenGL 2 (examples included)
 - Direct3D 9/10 (create device with D3DCREATE_FPU_PRESERVE. no examples yet)
 - for offline rendering, 3D API is not needed

 Compilers
 - Visual C++ 2008 (32bit, 64bit)
 - Visual C++ 2005 SP1
 - Visual C++ 2003 SP1
 - gcc (32bit, 64bit)

 Library configurations
 - Release DLL/so
 - Debug DLL/so
 - Release Static (source code license only)
 - Debug Static (source code license only)




 
\page main_inputs Inputs

 \section inputs_structures Data structures
  - \subpage inputs_light_sources
  - \subpage inputs_geometry
  - \subpage inputs_materials

 \section inputs_files Files
  - 3D scenes in any of the following formats: Collada, 3DS, Quake 3, OBJ, MGF. See \ref api_io library documentation.
  - \subpage inputs_images

 \section inputs_engines Engines
  - \subpage inputs_unreal

\page inputs_light_sources Light sources

 Lightsprint supports multiple types of light sources.

 All light sources support
 - HDR, floating point intensities (inputs, outputs)
 - direct, indirect or global illumination with infinite light bounces (outputs)
 - directional information (output)

 \section llights RRLights
  - Point/spot/directional light source.
  - Data structure: RRLight
  - Data structure container: RRLights
  - Setup: RRDynamicSolver::setLights()
  - Supported in offline GI: yes
  - Supported in realtime GI: yes

  - Point, spot and directional lights are implemented in RRLight.
    You can create new type, see RRLight interface.
    However, light must be emited by single point; to simulate area light,
    use e.g. triangles with emissive material.

 \section lenv Environment / Sky
  - Area light source, emissive skybox or sphere surrounding whole scene.
  - Data structure: RRBuffer
  - Data structure container: none, only one environment in scene
  - Setup: RRDynamicSolver::setEnvironment()
  - Supported in offline GI: yes
  - Supported in realtime GI: no

 \section lemissive Emissive materials
  - Area light source, triangles covered by materials that emit light.
  - Data structure: RRObject with emissive materials returned by RRObject::getTriangleMaterial()
  - Data structure container: RRObjects
  - Setup: RRDynamicSolver::setStaticObjects()
  - Supported in offline GI: yes
  - Supported in realtime GI: yes

 \section lrealtime Custom lights
  - Per-triangle direct irradiances set by RRDynamicSolver::setDirectIllumination()
  - Supported in offline GI: yes
  - Supported in realtime GI: yes



\page inputs_geometry Geometry
 Scene geometry is specified by RRObjects - set of RRObject objects.
 \n Each object has its own transformation matrix and pointer to RRMesh triangle mesh,
 so object is an instance of mesh.
 \n Mesh specifies vertices, triangles, normals, unwrap and custom data.

\page inputs_materials Materials
 Materials are specified by RRMaterial.

 Objects provide two levels of material information.
 \n 1. Per-triangle, RRObject::getTriangleMaterial() returns average material properties of one triangle.
 \n 2. Per-pixel, RRObject::getPointMaterial() returns material properties of single point on object's surface.

 Calculations with per-triangle materials are faster, so solver uses per-pixel material only when
 its per-triangle version has sideBits[].pointDetails flag set (set by you).

 Materials must be physically valid. Use RRMaterial::validate() to validate your materials.
 

\page inputs_images Images (jpg, png, dds, hdr, gif, tga...), vertex buffers (vbu)
 Nearly all standard image formats are supported.
 \n Images with floating point colors are supported in .hdr format.
 Both 2d and cubemap images are supported.

 Source code of image loading/saving is in: src/LightsprintIO/ImportFreeImage.cpp.
 \n It loads/saves vertex buffers directly, textures using FreeImage library.

\page inputs_unreal Unreal Engine 3
 Unreal Engine 3 is one of the most acclaimed game engines.

 Source code of adapter that accesses UE3 scene in memory
 is in: samples/ImportUE3/*.*
 \n Scene is loaded by Unreal Engine 3.

 \ref main_ue3


\page main_ue3 Introduction for UE3 users

 Lightsprint SDK integrated with UE3 editor transparently makes
 "Lighting build" produce global illumination lightmaps.

 If you are UE3 licensee, please request integration files from Lightsprint.
 Then see samples/ImportUE3/instructions.txt and follow several simple steps to integrate Lightsprint with UE3.

 \image html unreal.png   

 When running out of memory, see \ref howto_bigscenes

 
\page main_conventions Conventions

 \section gobjects Terminology
   <b>Mesh</b> is set of triangles with fixed positions in local space.
   \n\n
   <b>Object</b> is an instance of mesh, with position, rotation, scale
   and material properties.
   <b>Static object</b> never moves, rotates, deforms or changes material properties.
   <b>Dynamic object</b> freely changes these properties.
   \n\n
   <b>Scene</b> is set of objects.
   \n\n
   <b>Lightmap</b> is texture with irradiance values (incoming light)
   of object's surface, not modulated by material color.
   \n Lightmap could contain direct, indirect or global (both) illumination.
   \n Lightmap with indirect illumination is sometimes called <b>ambient map</b>.
   \n Irradiance values are typically stored in custom scale to fit 
   in 8bit precision, but physical or other HDR scale could be used too.

 \section glinking Automatic library linking
   By default, including library header automatically links Lightsprint DLLs using \#pragma comment(lib,name).
   Debug library is linked to debug exe, Release library to release exe.
   \n \#define RR_STATIC / RR_GL_STATIC selects static library instead of DLL.
   \n \#define RR_MANUAL_LINK / RR_GL_MANUAL_LINK disables automatic library linking,
      so you can e.g. manually link release library with debug exe.
   \n (version with RR_ affects LightsprintCore, RR_GL_ affects LightsprintGL)

 \section gunits Illumination units (radiometry, photometry, screen)
   Lightsprint computes all in HDR.
   Whole documentation talks in radiometry terms like irradiance,
   and Lightsprint internally works in radiometry units.
   All illumination measure inputs and outputs are 32bit float per component values.
   \n\n
   However, it is possible to communicate in screen colors
   or other units. Everything you need is to setup appropriate
   convertor, see RRDynamicSolver::setScaler(). Scaler internally converts values from native
   physical radiometry scale to your custom scale and vice versa.
   \n\n
   In typical situations, it is most straightforward to think and communicate
   in screen colors. This means you can set nearly all inputs in screen colors
   (scaled to 0-1 range) and read all outputs in screen colors.
   To setup this mode, call RRDynamicSolver::setScaler(RRScaler::createRgbScaler()).
   RealtimeRadiosity sample demonstrates it.

 \section gunits2 Geometry units
   All sizes and positions in space are expressed in generic units,
   Lightsprint doesn't need to know if it's meter, inch or parsec.
   However, some functions have default parameter values calibrated for
   human-sized scenes specified in meters (feature sizes roughly between
   0.01 and 100 units), so using meters may give you advantage in typical scenes.
   \n\n
   If it's possible, existing scene adapters adapt your scene from custom
   units to meters. (Source code of adapters is in samples/Import*)

 \section gscale Scale
   Lightsprint libraries support scaled objects.
   \n\n
   RRMesh and RRCollider support all scaled objects: positively or negatively, uniformly or non-uniformly scaled.
   \n\n
   RRObject and RRDynamicSolver support typical scaled objects:
   positively or negatively, uniformly scaled.
   \n Negative scale is supported with both possible interpretations
   for singlesided faces:
   Singlesided box visible from outside transformed with scale -1
   can stay visible form the outside or become visible only from inside,
   see RRObject::createWorldSpaceObject().

 \section gowner Ownership
   Dynamically created objects (using new, create() etc) are never adopted, ownership never changes.
   \n This means that parameters that need to be destructed are never destructed inside called function,
   responsibility for object is never passed to someone else.
   When you create object, always delete it yourself when no longer needed.

 \section gref Reference counting
   There is no internal reference counting, so if you create collider out of mesh,
   you are not allowed to destroy mesh before destroying collider. This danger should be
   mentioned on all appropriate places.

 \section gfinite Finite numbers
   If not otherwise specified, all inputs must be finite numbers.
   With Inf or NaN on input, result of any operation is undefined.

 \section gflodoub Floats and doubles
   Library uses both floats and doubles.
   It is not allowed to break double arithmetics by modifying FPU states.
   If you use Direct3D, make sure you create device with D3DCREATE_FPU_PRESERVE
   flag, otherwise it forces single precision and 
   breaks double precision arithmetics in whole program including dlls.

 \section gnull NULL
   Although NULL is obsoleted by C++ and some discourage from using it,
   we continue using it to distinguish zeros for pointers from zeros for non-pointers.
   So if you see x=0, x is NOT a pointer.
   If you see x=NULL, x IS a pointer.

 \section gmatrices Matrices
   Lightsprint uses 3x4 matrices for description of object transformation.
   See RRMatrix3x4 for explanation why we found it optimal.

 \section gup Up vector
   Although there is no limitation on orientation of 'up' vector,
   all samples work with 'up' in positive Y (0,1,0) and all scene adapters
   adapt scenes to 'up' in positive Y.
   Source code of adapters is in samples/Import*, so you can easily change up.






\page main_api API overview

 Lightsprint API consists of following libraries:

 - <b> \subpage api_core "LIGHTSPRINT CORE" </b> -
  Calculates global illumination in dynamic scenes.
  Includes fast ray-scene intersections.
  Is OpenGL/Direct3D independent, file format independent.

 - <b> \subpage api_gl "LIGHTSPRINT GL" </b> -
  Optional integration with OpenGL 2.0,
  realtime rendering with penumbra shadows.

 - <b> \subpage api_io "LIGHTSPRINT IO" </b> -
  Optional access to scenes and images stored on disk.

 structured into core layer and extensions:

 \image html libraries.png

 See \ref main_samples for more details on samples.






\page api_core Lightsprint Core
 Lightsprint Core calculates global illumination in dynamic and static scenes.
 Subsystems include fast ray-scene intersections.
 It is OpenGL/Direct3D independent.

 Namespace: rr

 <hr>

 Header: Lightsprint/RRDynamicSolver.h

 - calculates global illumination in static or dynamic scenes, offline or realtime
 - gives you full control over speed/quality
 - calculated illumination is available in vertex buffers, lightmaps and environment maps
 - communicates completely in custom units, e.g. screen colors
 - purely CPU, extensions for realtime rendering on GPU implemented in rr_gl::RRDynamicSolverGL

 Samples RealtimeLights and RealtimeRadiosity show the result of integration,
 interactive Collada scene viewer with global illumination immediately responding
 to free movement of objects and lights.

 <hr>

 Headers: Lightsprint/RRIllumination.h

 - data structure (RRObjectIllumination): object's illumination and more

 <hr>

 Header: Lightsprint/RRBuffer.h

 - data structure (RRBuffer): texture, vertex buffer

 <hr>

 Header: Lightsprint/RRObject.h

 - 3d object properties: geometry, materials, position etc

 <hr>

 Header: Lightsprint/RRCollider.h

 - finds ray-mesh intersections
 - thread safe, you can calculate any number of intersections at the same time
 - you can select technique in range from maximal speed to zero memory allocated
 - up to 2^32 vertices and 2^30 triangles in mesh
 - builds helper-structures and stores them in cache on disk

 Sample HelloCollider shows the most simple usage scenario:
 -# Create RRMesh using your vertex/index buffers.
 -# Create RRCollider using your mesh.
 -# Create RRRay using your ray.
 -# Call RRCollider::intersect() to find intersections. Repeat for all rays.

 Sample BunnyBenchmark shows how to detect collisions on all available
 CPUs/cores at once.

 <hr>

 Header: Lightsprint/RRMesh.h

 - interface to 3d triangle mesh
 - knows tristrips, trilists, indexed or not (RRMesh::create, RRMesh::createIndexed)
 - can optimize:
   - vertex welding (RRMesh::createOptimizedVertices)
   - removes degenerated triangles (RRMesh::createOptimizedTriangles)
 - merges many small meshes into one big mesh without additional memory (RRMesh::createMultiMesh)
 - saves/loads to disk (RRMesh::save, RRMesh::load)
 - extensible, you can add new channels like texture coords (RRChanneledData)
 - allows for procedural meshes, requires no memory (implementing your RRMesh takes few minutes)
 - up to 2^32-2 vertices and 2^32-2 triangles in mesh
 - thread safe, you can use mesh in any number of threads at the same time

 Sample HelloMesh shows the most simple usage scenario,
 mesh is created out of existing array of vertices.

 <hr>

 Header: Lightsprint/RRMath.h

 - math classes used by whole Lightsprint SDK
 - RRReal holds one real number, which is single precision float
 - RRVec2 is vector of 2 real numbers
 - RRVec3 is vector of 3 real numbers
 - RRVec4 is vector of 4 real numbers

 <hr>

 Header: Lightsprint/RRDebug.h

 - debugging and reporting routines used by whole Lightsprint SDK
 - RRReporter processess all messages sent by Lightsprint SDK to you

 <hr>

 Header: Lightsprint/RRLight.h

 - RRLight interface for point/spot/dir lights

 <hr>

 Header: Lightsprint/RRVector.h

 - RRVector template, std::vector like container




\page api_gl LightsprintGL

 LightsprintGL implements realtime rendering on top of LightsprintCore.

 Features of LightsprintGL renderer
   - realtime global illumination
   - arbitrary number of realtime dynamic point, spot, directional lights
   - linear and area spotlights with realtime penumbra shadows
   - tone mapping
   - separately enabled/disabled light features:
     - color
     - projected texture
     - polynomial, exponential, none or physically correct distance attenuation models
     - shadows with variable softness, resolution, automatically cascaded in outdoor
   - separately enabled/disabled material features:
     - diffuse reflection: none, constant, per vertex, per pixel
     - specular reflection: none, constant, per vertex, per pixel
     - emission: none, constant, per pixel
     - transparency: none, constant, per pixel / blend or alpha keying
     - normal map
   - supports OpenGL 2.0 GPUs (GeForce 5xxx and higher, Radeon 9500 and higher etc)

 Namespace: rr_gl

 <hr>
 Header: Lightsprint/GL/SceneViewer.h

 - rr_gl::sceneViewer() is a single function scene viewer, with movable lights, realtime GI,
   calculating static GI, 2d viewer of lightmaps and mappings, debugging outputs.
   RRDynamicSolver is usually black box. This viewer shows what's inside solver.

 <hr>
 Header: Lightsprint/GL/RRDynamicSolverGL.h

 - rr_gl::RRDynamicSolverGL extends RRDynamicSolver for realtime rendering in OpenGL 2.0

 <hr>
 Header: Lightsprint/GL/RendererOfScene.h

 - rr_gl::RendererOfScene is a renderer of 3d scene in RRDynamicSolver
 - renders environment, HDR
 - renders scene objects with precomputed or realtime computed illumination
 - detects what data are available (lightmaps, vertex colors)

 <hr>
 Header: Lightsprint/GL/RendererOfRRObject.h

 - rr_gl::RendererOfRRObject is a renderer of 3d objects with Lightsprint's RRObject interface
 - renders object with precomputed or realtime computed illumination

 <hr>
 Other headers (independent to LightsprintCore):

 - rr_gl::Texture is OpenGL texture, extension of RRBuffer needed for realtime rendering
 - rr_gl::Program is GLSL program
 - rr_gl::UberProgram is GLSL program with preprocessor parameters changeable at runtime
 - rr_gl::UberProgramSetup is set of parameters for our ubershaders UberShader.vs and UberShader.fs
 - rr_gl::Camera is frustum suitable for camera or spotlight
 - rr_gl::RealtimeLight is an extension of RRLight, structures needed for realtime GI rendering
 - rr_gl::Renderer is generic renderer interface



\page api_io LightsprintIO

 LightsprintIO is an optional utility library that handles loading of 3D scenes from a variety
 of formats, namely:
  - Collada (.DAE) - open, flexible and well supported format for digital asset exchange.
  Adapter loads geometry, materials and lights and uses FCollada library. See comments at the
  beginning of source file "RRObjectCollada.cpp" for more details about features supported.
  - 3DS - very old but popular format, despite the fact that its specification was never
  officially released. It supports only one set of texture coordinates, therefore it is
  not suitable for static lightmaps (which typically require another mapping channel).
  Adapter loads geometry and materials and uses open source 3DS loader. Known limitations:
    - no support for lights
    - no support for less common material properties
    - skips non-baked matrices
  - Quake 3 (.BSP) - popular scene format used by Quake 3 engine. It supports only one set of
  texture coordinates so it is not suitable for scenarios where static lighting calculation
  into lightmaps is required (see 3DS). Adapter loads geometry and materials. Known limitations:
    - does not support lights
    - does not support script-based materials
    - does not support curved surfaces
  - OBJ - old, plain text based format popular mainly because of its simplicity. It is suitable
  for loading of single objects but not whole scenes, since it lacks support for lights.
  For details, see <a href="http://en.wikipedia.org/wiki/Obj">Wikipedia</a>. Known limitations:
    - no support for materials (only geometry is loaded)
    - no support for lights (the scene will likely appear black)
  - MGF - Materials and Geometry Format is an open but old and rarely used 3D format.
  For details, see <a href="http://radsite.lbl.gov/mgf/HOME.html">MGF homepage</a>.
  Adapter loads .MGF file using parts of the source code taken from mgflib (see the link above).
  Known limitations:
    - only convex polygons are triangulated properly

 The source code of individual adapters is located in their respective directories within
 "src/LightsprintIO".

 Namespace: rr_io

 <hr>
 Header: Lightsprint/IO/ImportScene.h

 - rr_io::ImportScene loads scene from disk



\page main_samples Samples

 \section samples_root Purpose

 - \subpage samples_gl
 - \subpage samples_core



\page samples_core LightsprintCore - precalculations, collisions

 Following projects use LightsprintCore library for lighting or collision calculations.
 \n They are located in samples directory in the SDK, binaries in bin.
 \n Results are usually displayed in text console or saved to data/export directory.

 <hr>
 <b>CPULightmaps</b>
  <table border=0 width=95%><tr align=top><td>
  \image html samples/CPULightmaps_1.jpg computed lightmap
  </td><td>
  \image html samples/CPULightmaps_2.jpg computed bent normal map
  </td></tr></table>
 - precalculates lightmaps/vertexcolors from all types of lights (point/spot/dir/skybox)
 - no rendering, only CPU is used, runs on GPU-less machines
 - loads Collada scene including all lights

 <hr>
 <b>AmbientOcclusion</b>
  <table border=0 width=95%><tr align=top><td>
  \image html samples/AmbientOcclusion_1.jpg computed global ambient occlusion map
  </td><td>
  \image html samples/AmbientOcclusion_2.jpg with materials applied
  </td></tr></table>
 - precalculates ambient occlusion maps/vertexcolors with infinite light bounces and color bleeding
 - optional viewer of results (screenshots) is not important for calculation
 - loads Collada scene

 <hr>
 <b>BunnyBenchmark</b>
 - measures Collider performance for comparison with other engines
 - uses OpenMP to employ all available CPUs/cores
 - Collider results are up to 200x better than commercial physical engines

 <hr>
 <b>MultiMeshCollider</b>
 - ray-multimesh collision test, for static scenes with multiple meshes

 <hr>
 <b>HelloCollider</b>
 - the most simple case of ray-mesh collision test

 <hr>
 <b>HelloMesh</b>
 - the most simple case of mesh creation



\page samples_gl LightsprintGL - realtime rendering

 Following projects use LightsprintGL library for rendering
 and LightsprintCore for lighting calculations.
 \n They are located in samples directory in the SDK, binaries in bin.

 <hr>
 <b>Lightsmark 2007</b>
  <table border=0 width=95%><tr align=top><td>
  \image html samples/Lightsmark2.jpg
  </td><td>
  \image html samples/Lightsmark3.jpg
  </td></tr></table>
 - realtime GI in scene from real game (World of Padman)
 - original scene without any modifications is loaded to show engine robustness
 - complete Lightsmark 2007 is not part of SDK,
   but you can <a href="http://dee.cz/lightsmark">download it here</a>,
   source code on request

 <hr>
 <b>MovingSun</b>
  <table border=0 width=95%><tr align=top><td>
  \image html samples/MovingSun_1.jpg dynamic Sun
  </td><td>
  \image html samples/MovingSun_2.jpg dynamic objects
  </td></tr></table>
 - GI, tone mapping, dynamic objects lit by dynamic Sun and skybox
 - loads collada scene, drag&drop to open custom scene
 - when opened for first time, runs precalculations

 <hr>
 <b>SceneViewer</b>
  <table border=0 width=95%><tr align=top><td>
  \image html samples/SceneViewer_1.jpg move lights, compare realtime/offline GI
  </td><td>
  \image html samples/SceneViewer_2.jpg made for testing, debugging
  </td></tr></table>
 - single function call: sceneViewer(), you can run it from your code to visualize data
 - realtime GI: freely move all lights, no precalculations
 - precomputed GI: test build/load/save lightmaps
 - debugging: add/remove lights, see rays shot from individual triangles or texels
 - loads collada, 3ds, quake3, obj, mgf scenes

 <hr>
 <b>RealtimeLights</b>
  <table border=0 width=95%><tr align=top><td>
  \image html samples/RealtimeLights_1.jpg freely move lights and objects
  </td><td>
  \image html samples/RealtimeLights_2.jpg occluded light, GI changes in realtime
  </td></tr></table>
 - realtime GI, color bleeding
 - all lights and objects movable
 - no precalculations -> for scene viewers, designers
 - loads collada scene including all lights, loads 3ds dynamic objects
 - uses internal renderer

 <hr>
 <b>RealtimeRadiosity</b>
  <table border=0 width=95%><tr align=top><td>
  \image html samples/RealtimeRadiosity_2.jpg freely move light, objects
  </td><td>
  \image html samples/RealtimeRadiosity_1.jpg global illumination changes in realtime
  </td></tr></table>
 - realtime GI, color bleeding, penumbra shadows
 - all lights and objects movable
 - optional precalculations -> for games
 - loads 3ds scene and 3ds dynamic objects, uses 1 custom area light rather than lights from file
 - shows that lighting works equally well for animated object
 - shows feeding external 3ds renderer with Lightsprint computed illumination

 <hr>
 <b>Lightmaps</b>
  <table border=0 width=95%><tr align=top><td>
  \image html samples/Lightmaps_1.jpg realtime GI = fully dynamic
  </td><td>
  \image html samples/Lightmaps_2.jpg lightmaps + lightfield = faster
  </td></tr></table>
 - demonstrates differences between realtime and precomputed lighting
 - starts with fully realtime GI (both lights and objects dynamic)
 - after pressing 'p', switches to lightmaps+lightfield (faster, but light is static)

 <hr>
 <b>PenumbraShadows</b>
  <table border=0 width=95%><tr align=top><td>
  \image html samples/PenumbraShadows_1.jpg penumbra shadows
  </td><td>
  \image html samples/PenumbraShadows_2.jpg penumbra shadows
  </td></tr></table>
 - renders realtime direct illumination in scene with dynamic objects and area light
 - penumbra shadows
 - simple, no global illumination, only constant ambient




\page main_howto How to...

  Please report us problems you encounter. Your feedback is very important.

 \section howto_bigscenes How to process even bigger scenes

  Use 64bit code (fully supported by Lightsprint) whenever possible.
  With 64bit code, you can process scenes of all sizes.

  RAM is cheap these days, however if you must use 32bit code, you won't be able to use all physical memory,
  your address space is limited by operating system.

  If you must use 32bit code, run it in 64bit operating system, this gives you 4GB of address space per-process.
  It is good enough for nearly all game developers today.

  If you must use 32bit Windows, use /3GB parameter in boot.ini, this gives you 3GB of address space per-process.

  Using 32bit Windows without /3GB parameter is worst case scenario, process has only 2GB address space,
  so tasks like lightmap building can't process huge scenes.
 
*/

};
